<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Computer Organization and Architecture - 标签 - Jungle&#39;s Blog</title>
        <link>https://Jungle430.github.io/tags/computer-organization-and-architecture/</link>
        <description>Computer Organization and Architecture - 标签 - Jungle&#39;s Blog</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>1239946358@qq.com (Jungle)</managingEditor>
            <webMaster>1239946358@qq.com (Jungle)</webMaster><lastBuildDate>Wed, 01 Feb 2023 01:31:38 &#43;0800</lastBuildDate><atom:link href="https://Jungle430.github.io/tags/computer-organization-and-architecture/" rel="self" type="application/rss+xml" /><item>
    <title>Computer Organization and Architecture Parallel Process &amp; Multicore Computers</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-parallel-process-multicore-computers/</link>
    <pubDate>Wed, 01 Feb 2023 01:31:38 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-parallel-process-multicore-computers/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="parallel-process--multicore-computers">Parallel Process &amp; Multicore Computers</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>Parallel Processing</p>
<ul>
<li>Multiple Processor Organizations</li>
<li>Symmetric Multiprocessors</li>
<li>Clusters</li>
<li>Nonuniform Memory Access</li>
<li>Vector Computation</li>
</ul>
</li>
<li>
<p>Multicore Computers</p>
</li>
</ul>
<h3 id="multiple-processor-organizations">Multiple Processor Organizations</h3>
<h4 id="types-of-multiple-processor">Types of multiple processor</h4>
<ul>
<li>
<p>Single instruction, single data stream – <code>SISD</code></p>
</li>
<li>
<p>Single instruction, multiple data stream – <code>SIMD</code></p>
</li>
<li>
<p>Multiple instruction, single data stream – <code>MISD</code></p>
</li>
<li>
<p>Multiple instruction, multiple data stream - <code>MIMD</code></p>
</li>
</ul>
<h4 id="sisd-organizations">SISD Organizations</h4>
<div class="mermaid" id="id-1"></div>
<ul>
<li>
<p>SISD的结构中包含1个CU控制单元，1个PU处理单元，以及1个MU存储单元</p>
</li>
<li>
<p>CU向PU发送指令流，MU向PU发送数据流</p>
</li>
<li>
<p>PU根据CU发送的指令流，对来自MU的数据流进行操作，并产生结果。</p>
</li>
<li>
<p>SISD并没有并行的能力，PU按照CU提供的指令流，进行相应的操作</p>
</li>
</ul>
<div class="mermaid" id="id-2"></div>
<ul>
<li>
<p>SIMD，单指令多数据流，结构中包含1个控制单元，多个处理单元。每个处理单元有自己的存储器</p>
</li>
<li>
<p>控制单元将指令流发送给多个处理单元进行同步处理，同步处理采用的是锁步方式</p>
</li>
<li>
<p>不同的处理器在不同的数据集上执行相同的指令，产生不同的处理结果</p>
</li>
<li>
<p>实质是对不同的数据集进行相同的处理，通过并行得到一组结果，并行处理提高效率</p>
</li>
<li>
<p>矢量和阵列处理器属于SIMD类型</p>
</li>
</ul>
<h4 id="misd">MISD</h4>
<ul>
<li>
<p>Sequence of data</p>
</li>
<li>
<p>Transmitted to set of processors</p>
</li>
<li>
<p>Each processor executes different instruction sequence</p>
</li>
<li>
<p>Never been implemented</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter17-1.png" title="/img/Computer Organization and Architecture/chapter17-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter17-1.png" data-sub-html="<h2>MIMD Organizations</h2>">
        
    </a><figcaption class="image-caption"><code>MIMD Organizations</code></figcaption>
    </figure>
<ul>
<li>
<p>MIMD，多指令多数据流架构，多个控制单元CU，多个处理单元PU。存储方面，有两种结构</p>
<ul>
<li>
<p>共享存储器：所有的PU共享一个存储器，数据都存储在共享存储器中</p>
</li>
<li>
<p>分布式存储：每个PU都有自己的LM，这些机器通过互联网连接在一起</p>
</li>
</ul>
</li>
<li>
<p>一组处理器，能够同时执行不同的指令序列。每个处理器都有自己的数据集。</p>
</li>
<li>
<p>对称多处理SMP，集群，非均匀存储器访问NUMA等，都属于MIMD架构</p>
</li>
</ul>
<h3 id="symmetric-multiprocessors">Symmetric Multiprocessors</h3>
<h4 id="smp">SMP</h4>
<ul>
<li>
<p>Tightly Coupled</p>
</li>
<li>
<p>Processors share memory and I/O</p>
<ul>
<li>
<p>Share single memory or pool</p>
</li>
<li>
<p>Shared bus to access memory</p>
</li>
<li>
<p>Public area set in shared storage stores status information to achieve communication between processors</p>
</li>
<li>
<p>Memory access time to given area of memory is approximately the same for each processor</p>
</li>
</ul>
</li>
</ul>
<h4 id="characteristic-of-smp">Characteristic of SMP</h4>
<ul>
<li>
<p>Two or more processors with similar function</p>
<ul>
<li>
<p>All processors share memory and I/O</p>
</li>
<li>
<p>All processors share access to I/O</p>
</li>
<li>
<p>Perform the same function</p>
</li>
</ul>
</li>
<li>
<p>Controlled by a centralized operating system</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter17-2.png" title="/img/Computer Organization and Architecture/chapter17-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter17-2.png" data-sub-html="<h2>Symmetric Multiprocessor Organization</h2>">
        
    </a><figcaption class="image-caption"><code>Symmetric Multiprocessor Organization</code></figcaption>
    </figure>
<ul>
<li>
<p>每个处理器有自己的$L1\ cache$，也可能会配置各自的$L2\ cache\newline$</p>
</li>
<li>
<p>处理器都挂在共享的系统总线上，共享对主存储器的访问</p>
</li>
<li>
<p>I/O系统也挂在系统总线上，各个处理器对I/O系统进行共享访问</p>
</li>
</ul>
<h4 id="smp-advantages">SMP Advantages</h4>
<ul>
<li>
<p>High performance</p>
<ul>
<li>Greatly improved performance if some work can be done in parallel</li>
</ul>
</li>
<li>
<p>High availability</p>
<ul>
<li>
<p>All processors can perform the same functions</p>
</li>
<li>
<p>Failure of a single processor does not halt the system</p>
</li>
</ul>
</li>
<li>
<p>Incremental growth</p>
<ul>
<li>
<p>Flexible system expansion</p>
</li>
<li>
<p>User can enhance performance by adding additional processors</p>
</li>
</ul>
</li>
<li>
<p>Scaling</p>
<ul>
<li>
<p>Vendors can offer range of products based on number of processors</p>
</li>
<li>
<p>Different products have different prices and performance, which can give users more choices</p>
</li>
</ul>
</li>
</ul>
<h4 id="design-issues">Design issues</h4>
<ul>
<li>
<p>SMP system is managed by a unified operating system</p>
</li>
<li>
<p>Operating system is responsible for scheduling processes and resources</p>
</li>
<li>
<p>Operating system needs to complete</p>
<ul>
<li>
<p>Simultaneous concurrent processes</p>
</li>
<li>
<p>Scheduling</p>
</li>
<li>
<p>Synchronization</p>
</li>
<li>
<p>Memory management</p>
</li>
<li>
<p>Reliability and fault tolerance</p>
</li>
</ul>
</li>
<li>
<p>Simultaneous concurrent processes</p>
<ul>
<li>
<p>Allow multiple processors to execute the same piece of OS code at the same time</p>
</li>
<li>
<p>Manage OS tables and other structures to avoid deadlocks</p>
</li>
</ul>
</li>
<li>
<p>Scheduling</p>
<ul>
<li>Reasonably schedule the processor execution process</li>
</ul>
</li>
<li>
<p>Synchronization</p>
<ul>
<li>Provide synchronization mechanism to ensure mutual exclusion and order of memory and I/O access</li>
</ul>
</li>
<li>
<p>Memory management</p>
<ul>
<li>Solve concurrency and consistency problems</li>
<li>Ensure the performance and correctness under multiprocessors</li>
</ul>
</li>
<li>
<p>Reliability and fault tolerance</p>
<ul>
<li>For a processor failure, the operating system shall be able to reconstruct the system so that the system can be degraded for use</li>
</ul>
</li>
</ul>
<h3 id="clusters">Clusters</h3>
<ul>
<li>
<p>Loosely Coupled</p>
</li>
<li>
<p>Collection of independent uniprocessors or <code>SMPs</code></p>
</li>
<li>
<p>Interconnected to form a cluster</p>
</li>
<li>
<p>Communication via fixed path or network connections</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Composition of cluster</p>
<ul>
<li>
<p>A group of interconnected whole computers</p>
</li>
<li>
<p>Working together as unified resource</p>
</li>
<li>
<p>Illusion of being one machine</p>
</li>
<li>
<p>Each computer called a node</p>
</li>
</ul>
</li>
<li>
<p>Characteristics</p>
<ul>
<li>
<p>High performance</p>
</li>
<li>
<p>High availability</p>
</li>
<li>
<p>Alternative to SMP</p>
</li>
</ul>
</li>
<li>
<p>Server applications</p>
</li>
</ul>
<h4 id="cluster-benefits">Cluster Benefits</h4>
<ul>
<li>
<p>Absolute scalability</p>
<ul>
<li>
<p>Build hundreds of thousands of independent computers into a large cluster system, and the processing capacity may far exceed that of the largest independent computer</p>
</li>
<li>
<p>Each machine in the cluster can be a single processing system or a multiprocessor architecture</p>
</li>
</ul>
</li>
<li>
<p>Incremental scalability</p>
<ul>
<li>
<p>New nodes can be added to the cluster system step by step to improve processing capacity and gradually expand</p>
</li>
<li>
<p>Very flexible capacity expansion</p>
</li>
</ul>
</li>
<li>
<p>High availability</p>
<ul>
<li>
<p>Each node is an independent computer</p>
</li>
<li>
<p>The failure of one or more nodes will not affect the use of the cluster system</p>
</li>
<li>
<p>Node fault diagnosis and fault tolerance are automatically completed by the system</p>
</li>
</ul>
</li>
<li>
<p>Superior price/performance</p>
<ul>
<li>
<p>Combine mature commercial computers into a cluster</p>
</li>
<li>
<p>The system performance is far greater than that of a single large server</p>
</li>
<li>
<p>High cost performance</p>
</li>
</ul>
</li>
</ul>
<h4 id="blade-servers">Blade Servers</h4>
<ul>
<li>
<p><strong>Common implementation of cluster</strong></p>
</li>
<li>
<p>Server houses multiple server modules (blades) in single chassis</p>
<ul>
<li>
<p>Save space</p>
</li>
<li>
<p>Improve system management</p>
</li>
<li>
<p>Chassis provides power supply</p>
</li>
<li>
<p>Each blade has processor, memory, disk</p>
</li>
</ul>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter17-3.png" title="/img/Computer Organization and Architecture/chapter17-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter17-3.png" data-sub-html="<h2>Blade Servers</h2>">
        
    </a><figcaption class="image-caption"><code>Blade Servers</code></figcaption>
    </figure>
<h4 id="cluster-v-smp">Cluster v. SMP</h4>
<ul>
<li>
<p>Both provide multiprocessor support to high demand applications</p>
</li>
<li>
<p>Both available commercially</p>
</li>
<li>
<p>SMP for longer</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><code>SMP</code></p>
<ul>
<li>
<p>Easier to manage and control</p>
</li>
<li>
<p>Closer to single processor systems</p>
</li>
<li>
<p>Scheduling is important</p>
</li>
<li>
<p>Less physical space</p>
</li>
<li>
<p>Lower power consumption</p>
</li>
</ul>
</li>
<li>
<p>Clustering</p>
<ul>
<li>
<p>Superior incremental &amp; absolute scalability</p>
</li>
<li>
<p>Superior availability</p>
<ul>
<li>Redundancy</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="nonuniform-memory-access">Nonuniform Memory Access</h3>
<h4 id="numa">NUMA</h4>
<ul>
<li>
<p>Tightly Coupled</p>
</li>
<li>
<p>Nonuniform memory access</p>
<ul>
<li>Access times to different regions of memory may differ</li>
</ul>
</li>
<li>
<p>Main object</p>
<ul>
<li>
<p>Overcoming the limitation on the number of processors in SMP</p>
</li>
<li>
<p>It solves the problem caused by the independent memory used by each node in the cluster system</p>
</li>
</ul>
</li>
<li>
<p>Alternative to SMP &amp; clustering</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Uniform memory access</p>
<ul>
<li>
<p>All processors have access to all parts of memory</p>
</li>
<li>
<p>Using load &amp; store</p>
</li>
<li>
<p>Access time to all regions of memory is the same</p>
</li>
<li>
<p>Access time to memory for different processors same</p>
</li>
<li>
<p>As used by SMP</p>
</li>
</ul>
</li>
</ul>
<h4 id="nonuniform-memory-access-1">Nonuniform Memory Access</h4>
<ul>
<li>
<p>All processors have access to all parts of memory</p>
</li>
<li>
<p>Using load &amp; store</p>
</li>
<li>
<p>Access time of processor differs depending on region of memory</p>
</li>
<li>
<p>Different processors access different regions of memory at different speeds</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Cache coherent NUMA(<code>CC-NUMA</code>)</p>
<ul>
<li>
<p>Cache coherence is maintained among the caches of the various processors</p>
</li>
<li>
<p>For a system without cache consistency maintenance, it is similar to a cluster system</p>
</li>
<li>
<p><code>CC-NUMA</code> is discussed here</p>
</li>
<li>
<p>Significantly different from SMP and clusters</p>
</li>
</ul>
</li>
</ul>
<h4 id="motivation">Motivation</h4>
<ul>
<li>
<p>SMP has practical limit to number of processors</p>
<ul>
<li>Bus traffic limits to between 16 and 64 processors</li>
</ul>
</li>
<li>
<p>In cluster，each node has own memory</p>
<ul>
<li>Apps do not see large global memory</li>
<li>Coherence maintained by software not hardware</li>
</ul>
</li>
<li>
<p>NUMA retains SMP flavour while giving large scale multiprocessing</p>
<ul>
<li>e.g. Silicon Graphics Origin NUMA 1024 MIPS R10000 processors</li>
</ul>
</li>
<li>
<p>Objective</p>
<ul>
<li>
<p>maintain transparent system wide memory while permitting multiprocessor nodes</p>
</li>
<li>
<p>each with own bus or internal interconnection system</p>
</li>
</ul>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter17-4.png" title="/img/Computer Organization and Architecture/chapter17-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter17-4.png" data-sub-html="<h2>CC-NUMA Organization</h2>">
        
    </a><figcaption class="image-caption"><code>CC-NUMA Organization</code></figcaption>
    </figure>
<ul>
<li>
<p>NUMA系统由多个结点组成。每个节点包含有若干个处理器，每个处理器有自己的L1 cache和L2 cache，有自己的内部总线，并且有自己的主存和I/O</p>
</li>
<li>
<p>处理器访问存储器的时候，首先看是否在cache中，如果不在，cache会去访问本地存储器。如果在的话，就通过内部总线取过来。如果不在本地存储器中，cache会发出一个请求，通过互联网络从远端取过来，放到总线上，发出请求的cache从总线上读取。这些动作都是自动的，对处理器和cache都是透明的。</p>
</li>
</ul>
<h3 id="vector-computation">Vector Computation</h3>
<ul>
<li>
<p>Maths problems involving physical processes present different difficulties for computation</p>
<ul>
<li>
<p>Aerodynamics, seismology, meteorology</p>
</li>
<li>
<p>Continuous field simulation</p>
</li>
</ul>
</li>
<li>
<p>Requirement</p>
<ul>
<li>
<p>High precision</p>
</li>
<li>
<p>Repeated floating point calculations on large arrays of numbers</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Solution 1: supercomputer</p>
<ul>
<li>
<p>Hundreds of millions of float</p>
</li>
<li>
<p>Optimized for Vector Computation</p>
</li>
<li>
<p>$10-15 million</p>
</li>
<li>
<p>Limited market</p>
</li>
<li>
<p>Research, government agencies, meteorology</p>
</li>
</ul>
</li>
<li>
<p>Solution 2:  Array processor</p>
<ul>
<li>
<p>Alternative to supercomputer</p>
</li>
<li>
<p>Configured as peripherals to mainframe &amp; mini</p>
</li>
<li>
<p>Just run vector portion of problems</p>
</li>
</ul>
</li>
</ul>
<h3 id="multicore-computers">Multicore Computers</h3>
<h4 id="what-is-multicore-computers">What is Multicore Computers?</h4>
<ul>
<li>
<p>Also known as single chip multiprocessor</p>
</li>
<li>
<p>Two or more processors are integrated on a single chip, and each processor is called a core</p>
</li>
<li>
<p>Each core consists of all components of an independent processor, including register set, ALU, pipeline hardware, control unit, and L1 data and instruction cache</p>
</li>
<li>
<p>Some multicore processors also include L2 cache and L3 cache on the chip</p>
</li>
</ul>
<h3 id="hardware-performance-issues">Hardware Performance Issues</h3>
<ul>
<li>
<p>Microprocessors have seen an exponential increase in performance</p>
<ul>
<li>
<p>Improved organization</p>
</li>
<li>
<p>Increased clock frequency</p>
</li>
</ul>
</li>
<li>
<p>Increase in Parallelism</p>
<ul>
<li>
<p>Pipelining</p>
</li>
<li>
<p>Superscalar</p>
</li>
<li>
<p>Simultaneous multithreading</p>
</li>
</ul>
</li>
</ul>
<h4 id="simultaneous-multithreading">Simultaneous multithreading</h4>
<ul>
<li>
<p>同步多线程能够从多个线程中取出指令来运行，它能够同时执行不同线程的指令</p>
</li>
<li>
<p>同步多线程架构中，配置了多个PC和多个寄存器组，底层共享指令cache和数据cache。这样可以在多个线程之间共享流水线资源</p>
</li>
<li>
<p>通过同步多线程技术，系统能够动态调整系统环境，如有可能同时执行不同线程的指令。当一个线程遇到长延迟事件时，允许另一个线程使用所有的处理单元</p>
</li>
</ul>
<h4 id="hardware-performance-issues-1">Hardware Performance Issues</h4>
<ul>
<li>
<p>Processor performance continues to improve</p>
<ul>
<li>
<p>Adjustment of chip architecture</p>
</li>
<li>
<p>Improvement of main frequency</p>
</li>
</ul>
</li>
<li>
<p>Diminishing returns</p>
<ul>
<li>
<p>More complexity requires more logic</p>
</li>
<li>
<p>Need more chip area for coordinating and signal transfer logic</p>
</li>
<li>
<p>Harder to design, make and debug</p>
</li>
<li>
<p>Hardware performance reaches the bottleneck, which is very difficult to improve</p>
</li>
</ul>
</li>
</ul>
<h4 id="power-consumption">Power consumption</h4>
<ul>
<li>
<p>Power requirements grow exponentially with chip density and clock frequency</p>
</li>
<li>
<p>Increased power consumption causes CPU cooling problems</p>
</li>
<li>
<p>It is increasingly difficult to improve performance by improving chip integration</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>One solution is use more chip area for cache</p>
<ul>
<li>
<p>Storage transistors require low power consumption</p>
</li>
<li>
<p>Cache is close to CPU and fast</p>
</li>
<li>
<p>By 2015，100 billion transistors on 300mm2 ，Cache of 100MB ，1 billion transistors for logic</p>
</li>
</ul>
</li>
<li>
<p>Large capacity cache provides basic resources for multi-core processors</p>
</li>
</ul>
<h4 id="pollacks-rule">Pollack’s rule</h4>
<ul>
<li>
<p>Pollack’s rule</p>
<ul>
<li>
<p>Performance is roughly proportional to square root of increase in complexity</p>
</li>
<li>
<p>Double complexity gives 40% more performance</p>
</li>
</ul>
</li>
<li>
<p>So,integrating multiple processor cores on one chip becomes a better solution</p>
<ul>
<li>
<p>Multicore makes performance close to linear improvement</p>
</li>
<li>
<p>Unlikely that one core can use all cache effectively</p>
</li>
</ul>
</li>
</ul>
<h3 id="software-performance-issues">Software Performance Issues</h3>
<ul>
<li>
<p>Performance benefits dependent on effective exploitation of parallel resources</p>
<ul>
<li>
<p>Amdahl’s Law</p>
</li>
<li>
<p>Even small amounts of serial code impact performance</p>
</li>
<li>
<p>10% inherently serial on 8 processor system gives only 4.7 times performance</p>
</li>
</ul>
</li>
<li>
<p>Other factors affecting performance: communication, distribution of work and cache coherence overheads</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter17-5.png" title="/img/Computer Organization and Architecture/chapter17-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter17-5.png" data-sub-html="<h2>Performance Effect of Multiple Cores</h2>">
        
    </a><figcaption class="image-caption"><code>Performance Effect of Multiple Cores</code></figcaption>
    </figure>
<ul>
<li>
<p>图（a）给出了串行代码比例对加速比的影响。如果没有串行代码，理论上加速比和性能的提升成正比。但是，由于串行处理的问题，导致加速比比理论值小了很多。</p>
</li>
<li>
<p>图（b）指出管理开销对加速比的影响。可以看到，在5个处理器的时候，加速比最大，随着核数的增加，管理开销会导致性能收益递减</p>
</li>
</ul>
<h4 id="effective-applications">Effective Applications</h4>
<ul>
<li>
<p>Some applications effectively exploit multicore processors</p>
<ul>
<li>
<p>Database</p>
</li>
<li>
<p>Servers handling independent transactions</p>
</li>
<li>
<p>Multi-threaded native applications，such as Lotus Domino, Siebel CRM</p>
</li>
<li>
<p>Multi-process applications, such as Oracle, SAP, PeopleSoft</p>
</li>
</ul>
</li>
<li>
<p>Java applications</p>
<ul>
<li>
<p><code>JVM</code> is multi-thread with scheduling and memory management</p>
</li>
<li>
<p>Sun’s Java Application Server, BEA’s Weblogic, IBM Websphere, Tomcat</p>
</li>
</ul>
</li>
<li>
<p>Multi-instance applications</p>
<ul>
<li>One application running multiple times</li>
</ul>
</li>
<li>
<p>Game Software</p>
</li>
</ul>
<h3 id="multicore-organization">Multicore Organization</h3>
<ul>
<li>
<p>Number of core processors on chip</p>
</li>
<li>
<p>Number of levels of cache on chip</p>
</li>
<li>
<p>Amount of shared cache</p>
</li>
<li>
<p>Next slide examples of each organization</p>
<ul>
<li>
<p>(a) ARM11 MPCore</p>
</li>
<li>
<p>(b) AMD Opteron</p>
</li>
<li>
<p>(c) Intel Core Duo</p>
</li>
<li>
<p>(d) Intel Core i7</p>
</li>
</ul>
</li>
</ul>
<h4 id="individual-core-architecture">Individual Core Architecture</h4>
<ul>
<li>
<p>Intel Core Duo uses superscalar cores</p>
</li>
<li>
<p>Intel Core i7 uses simultaneous multi-threading (SMT)</p>
<ul>
<li>Scales up number of threads supported</li>
<li>4 SMT cores, each supporting 4 threads appears as 16 core</li>
</ul>
</li>
</ul>
<h3 id="intel-x86-multicore-organization">Intel x86 Multicore Organization</h3>
<p>Example: Core Duo and Core i7</p>
<h3 id="arm11-mpcore">ARM11 MPCore</h3>
<ul>
<li>
<p>Up to 4 processors each with own L1 instruction and data cache</p>
</li>
<li>
<p>Distributed interrupt controller</p>
</li>
<li>
<p>Timer per CPU</p>
</li>
<li>
<p>Watchdog</p>
<ul>
<li>Warning alerts for software failures</li>
<li>Counts down from predetermined values</li>
<li>Issues warning at zero</li>
</ul>
</li>
<li>
<p>CPU interface</p>
<ul>
<li>Interrupt acknowledgement, masking and completion acknowledgement</li>
</ul>
</li>
<li>
<p>CPU</p>
<ul>
<li>Single ARM11 called MP11</li>
</ul>
</li>
<li>
<p>Vector floating-point unit</p>
<ul>
<li>FP co-processor</li>
</ul>
</li>
<li>
<p>L1 cache</p>
</li>
<li>
<p>Snoop control unit</p>
<ul>
<li>Maintain L1 cache coherency</li>
</ul>
</li>
</ul>
<h4 id="summary-of-parallel">Summary of parallel</h4>
<ul>
<li>
<p>Internal of CPU</p>
<ul>
<li>
<p>Pipeline</p>
</li>
<li>
<p>Superscalar</p>
</li>
<li>
<p>simultaneous multi-threading(SMT)</p>
</li>
</ul>
</li>
<li>
<p>On chip</p>
<ul>
<li>Multicore</li>
</ul>
</li>
<li>
<p>Internal of machine</p>
<ul>
<li>
<p>SMP</p>
</li>
<li>
<p>NUMA</p>
</li>
<li>
<p>Array processor</p>
</li>
</ul>
</li>
<li>
<p>Multi-machine</p>
<ul>
<li>Cluster</li>
</ul>
</li>
</ul>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Control Unit Operation &amp; Microprogrammed Control</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-control-unit-operation-microprogrammed-control/</link>
    <pubDate>Tue, 31 Jan 2023 15:20:52 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-control-unit-operation-microprogrammed-control/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="control-unit-operation--microprogrammed-control">Control Unit Operation &amp; Microprogrammed Control</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>Control Unit Operation</p>
<ul>
<li>
<p>Micro-Operations</p>
</li>
<li>
<p>Control of the Processor</p>
</li>
<li>
<p>Hardwired Implementation</p>
</li>
</ul>
</li>
<li>
<p>Microprogrammed Control</p>
<ul>
<li>Basic Concepts</li>
<li>Microinstruction Sequencing</li>
<li>Microinstruction Execution</li>
</ul>
</li>
</ul>
<h3 id="control-unit-operation">Control Unit Operation</h3>
<h4 id="the-function-of-a-processor">The function of a processor</h4>
<ul>
<li>
<p>Instruction Fetch and Execute</p>
<ul>
<li>Execute program</li>
</ul>
</li>
<li>
<p>Interrupts</p>
<ul>
<li>Handling performance differences between CPU and other components</li>
</ul>
</li>
<li>
<p>I/O Function</p>
<ul>
<li>Inter-working with peripherals</li>
</ul>
</li>
</ul>
<h4 id="composition-of-instructions">Composition of instructions</h4>
<ul>
<li>
<p>Instructions include opcodes and operands</p>
</li>
<li>
<p>Opcodes</p>
<ul>
<li>Determines what type of operation the instruction does</li>
</ul>
</li>
<li>
<p>Operands</p>
<ul>
<li>
<p>Determine the object of instruction operation</p>
</li>
<li>
<p>Operands may be in registers, memory, I/O, or immediate</p>
</li>
<li>
<p>Finding operands through addressing mode</p>
</li>
</ul>
</li>
</ul>
<h4 id="micro-operations">Micro-operations</h4>
<ul>
<li>
<p>A computer executes a program to complete user specified functions</p>
<ul>
<li>
<p>Program contains many instructions</p>
</li>
<li>
<p>Instruction execution includes several cycles, such as fetch cycle, execution cycle, indirect cycle, etc</p>
</li>
</ul>
</li>
<li>
<p><strong>Each cycle has a number of steps</strong></p>
<ul>
<li>
<p><strong>Called micro-operations</strong></p>
</li>
<li>
<p><strong>Each step does very little</strong></p>
</li>
<li>
<p><strong>Atomic operation of CPU</strong></p>
</li>
</ul>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-1.png" title="/img/Computer Organization and Architecture/chapter15-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-1.png" data-sub-html="<h2>Constituent of program</h2>">
        
    </a><figcaption class="image-caption"><code>Constituent of program</code></figcaption>
    </figure>
<ul>
<li>
<p><strong>程序的执行是由若干个指令执行组成的</strong></p>
</li>
<li>
<p><strong>每个指令的执行就是一个指令周期</strong></p>
</li>
<li>
<p><strong>指令周期由若干个子周期组成，比如取指周期、执行周期等</strong></p>
</li>
<li>
<p><strong>每个子周期包含若干个更小的操作，这些操作称为微操作</strong></p>
</li>
</ul>
<h5 id="fetch">Fetch</h5>
<ul>
<li>
<p>Program Counter (PC)</p>
<ul>
<li>Holds address of next instruction to be fetched</li>
</ul>
</li>
<li>
<p>Memory Address Register (MAR)</p>
<ul>
<li>
<p>Connected to address bus</p>
</li>
<li>
<p>Specifies address for read or write op</p>
</li>
</ul>
</li>
<li>
<p>Memory Buffer Register (MBR)</p>
<ul>
<li>
<p>Connected to data bus</p>
</li>
<li>
<p>Holds data to write or last data read</p>
</li>
</ul>
</li>
<li>
<p>Instruction Register (IR)</p>
<ul>
<li>Holds last instruction fetched</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Step1</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-2.png" title="/img/Computer Organization and Architecture/chapter15-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-2.png">
        
    </a>
<ul>
<li>
<p><strong>下一个指令的地址是放在PC里</strong></p>
</li>
<li>
<p><strong>MAR是与地址总线连接的唯一寄存器</strong></p>
</li>
<li>
<p><strong>取指的第一步是PC把下一个指令的地址给MAR</strong></p>
</li>
<li>
<p><strong>经过第一步之后，PC寄存器的内容复制到MAR寄存器中</strong></p>
</li>
</ul>
<hr>
<p><strong>Step2</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-3.png" title="/img/Computer Organization and Architecture/chapter15-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-3.png">
        
    </a>
<ul>
<li>
<p>MAR收到地址后，把地址放到地址总线上</p>
</li>
<li>
<p>控制单元发一个读命令到控制总线上</p>
</li>
<li>
<p>存储器收到读命令后，根据地址读出指令内容，并放到数据总线</p>
</li>
<li>
<p>数据总线上的数据读到MBR</p>
</li>
<li>
<p>PC中还需要递增一个指令长度，以得到下一个指令的地址</p>
</li>
</ul>
<hr>
<p><strong>Step3</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-4.png" title="/img/Computer Organization and Architecture/chapter15-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-4.png">
        
    </a>
<ul>
<li>
<p>MBR的内容传送给IR</p>
</li>
<li>
<p>传送完成后，MBR就可以释放，用于下一步操作</p>
</li>
<li>
<p>IR中保存的就是下一个需要执行的指令</p>
</li>
<li>
<p>通过这几个微操作，完成了取指</p>
</li>
</ul>
<hr>
<p><strong>Fetch sequence</strong></p>
<ul>
<li>
<p>取指周期实际上由三步、四个微操作组成。每个微操作都涉及到数据在寄存器之间的流动</p>
</li>
<li>
<p>如果数据的流动是独立的，这些操作可以在同一个时钟周期内完成</p>
</li>
<li>
<p>PC递增微操作，既可以在t2完成，也可以在t3完成</p>
</li>
</ul>
<hr>
<p><strong>Rules for Micro-operations grouping</strong></p>
<ul>
<li>
<p>Proper sequence must be followed</p>
<ul>
<li>MAR &lt;- (PC) must precede MBR &lt;- (memory)</li>
</ul>
</li>
<li>
<p>Conflicts must be avoided</p>
<ul>
<li>
<p>Must not read &amp; write same register at same time</p>
</li>
<li>
<p>MBR &lt;- (memory) &amp; IR &lt;- (MBR) must not be in same cycle</p>
</li>
</ul>
</li>
<li>
<p>Also: PC &lt;- (PC) +1 involves addition</p>
<ul>
<li>
<p>Use ALU</p>
</li>
<li>
<p>May need additional micro-operations</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Indirect cycle</strong></p>
<ul>
<li>In indirect addressing, it is necessary to get the address of the operand from the memory first. This process is called indirect cycle</li>
</ul>
<hr>
<p><strong>Interrupt cycle</strong></p>
<ul>
<li>
<p>After instruction processing is completed, check whether there is an interrupt</p>
</li>
<li>
<p>Interrupt cycle needs to complete these operations</p>
<ul>
<li>
<p>The instruction address before the interrupt needs to be saved</p>
</li>
<li>
<p>Get the instruction address of the start of the interrupt handler to the PC</p>
</li>
</ul>
</li>
<li>
<p>After the PC gets the interrupt processing address, it enters the index retrieval cycle</p>
</li>
</ul>
<hr>
<p><strong>Execute cycle</strong></p>
<ul>
<li>
<p>Fetching, indirect and interruption cycle can be determined in advance</p>
<ul>
<li>Each cycle contains a fixed sequence of micro operations</li>
</ul>
</li>
<li>
<p>For execution cycle</p>
<ul>
<li>
<p>Different operation codes correspond to different operations</p>
</li>
<li>
<p>Each operation has a specific micro operation sequence</p>
</li>
</ul>
</li>
</ul>
<h4 id="flowchart-for-instruction-cycle">Flowchart for instruction cycle</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-5.png" title="/img/Computer Organization and Architecture/chapter15-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-5.png">
        
    </a>
<ul>
<li>
<p>取指周期后，看是否是间接寻址。如果是间接寻址，进入01间接周期，如果不是，进入执行周期。</p>
</li>
<li>
<p>间接周期后，读取地址，然后进入10执行周期</p>
</li>
<li>
<p>执行周期，根据操作码来确定做什么操作。然后判断是否有中断。如果有中断，进入11中断周期。如果没有，进入00取指周期。</p>
</li>
<li>
<p>中断周期，设置中断，然后进入中断处理程序的取指周期，继续取指</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Control of the Processor</p>
<ul>
<li>
<p>Functional Requirements</p>
</li>
<li>
<p>Control Signals</p>
</li>
<li>
<p>A Control Signals Example</p>
</li>
<li>
<p>Internal Processor Organization</p>
</li>
</ul>
</li>
</ul>
<h4 id="functional-requirement">Functional requirement</h4>
<ul>
<li>
<p>Micro-operations are the most basic function of the processor</p>
</li>
<li>
<p>Three elements of the controller include</p>
<ul>
<li>
<p>Basic elements of processor</p>
</li>
<li>
<p>Micro-operations that processor performs</p>
</li>
<li>
<p>How to control</p>
</li>
<li>
<p>ALU</p>
</li>
<li>
<p>Registers</p>
</li>
<li>
<p>Internal data paths</p>
</li>
<li>
<p>External data paths</p>
</li>
<li>
<p>Control Unit</p>
</li>
</ul>
</li>
</ul>
<h4 id="types-of-micro-operation">Types of micro-operation</h4>
<ul>
<li>
<p>Micro-operations can be divided into the following four categories</p>
<ul>
<li>
<p>Transfer data between registers</p>
</li>
<li>
<p>Transfer data from register to external</p>
</li>
<li>
<p>Transfer data from external to register</p>
</li>
<li>
<p>Perform arithmetic or logical ops</p>
</li>
</ul>
</li>
</ul>
<h4 id="functions-of-control-unit">Functions of control unit</h4>
<ul>
<li>
<p>Operation object and operation type have been determined</p>
</li>
<li>
<p>Function of the controller is to determine how to do it</p>
<ul>
<li>
<p>Sequencing</p>
</li>
<li>
<p>Execution</p>
</li>
<li>
<p>This is done using Control Signals</p>
</li>
</ul>
</li>
</ul>
<h4 id="model-of-control-unit">Model of control unit</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-6.png" title="/img/Computer Organization and Architecture/chapter15-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-6.png">
        
    </a>
<ul>
<li>
<p>控制器的输入包括：时钟信号，各种标志，指令寄存器中的指令，来自控制总线的控制信号(中断)</p>
</li>
<li>
<p>控制器的输出包括：CPU内部的控制信号，到控制总线的控制信号</p>
</li>
<li>
<p><strong>控制器内部就是如何根据输入，来生成控制信号</strong></p>
</li>
</ul>
<hr>
<p><strong>Control signals</strong></p>
<ul>
<li>
<p>Clock</p>
<ul>
<li>Provide clock signal for timing of controller</li>
<li>One micro-instruction (or set of parallel micro-instructions) per clock cycle</li>
</ul>
</li>
<li>
<p>Instruction register</p>
<ul>
<li>
<p>Op-code for current instruction</p>
</li>
<li>
<p>Addressing mode</p>
</li>
<li>
<p>Determines which micro-instructions are performed</p>
</li>
</ul>
</li>
<li>
<p>Flags</p>
<ul>
<li>
<p>State of CPU</p>
</li>
<li>
<p>Results of previous operations</p>
</li>
</ul>
</li>
<li>
<p>Control signal from control bus</p>
<ul>
<li>
<p>Interrupts</p>
</li>
<li>
<p>Acknowledgements</p>
</li>
</ul>
</li>
<li>
<p>output</p>
<ul>
<li>
<p>Within CPU</p>
<ul>
<li>
<p>Cause data movement</p>
</li>
<li>
<p>Activate specific functions</p>
</li>
</ul>
</li>
<li>
<p>Via control bus</p>
<ul>
<li>
<p>To memory，control read or write</p>
</li>
<li>
<p>To I/O modules</p>
</li>
</ul>
</li>
<li>
<p><strong>It generates three types of output control signals</strong></p>
<ul>
<li>
<p>Data paths: the signals control the internal flow of data</p>
</li>
<li>
<p>ALU: the signals control the operation of the ALU</p>
</li>
<li>
<p>System bus: the control unit sends these signals to the control lines of the system bus</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="internal-organization">Internal organization</h4>
<ul>
<li>
<p>CPU adopts single bus structure</p>
<ul>
<li>
<p>All components, including ALU and registers, are connected to the bus</p>
</li>
<li>
<p>A gate is set between each component and the bus to control the data transmission between the component and the bus</p>
</li>
</ul>
</li>
<li>
<p>Data transfer to and from external systems bus is controlled by the control signal</p>
</li>
<li>
<p>Temporary registers needed for proper operation of ALU</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-7.png" title="/img/Computer Organization and Architecture/chapter15-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-7.png" data-sub-html="<h2>Internal processor organization</h2>">
        
    </a><figcaption class="image-caption"><code>Internal processor organization</code></figcaption>
    </figure>
<ul>
<li>
<p>各个寄存器都链接到内部总线上。寄存器和内部总线之间有个逻辑门，用于寄存器和内部总线的连接控制</p>
</li>
<li>
<p>ALU没有内部存储部件。如果ALU的操作涉及2个操作数的话，一个由内部总线得到，另一个必须通过其他的数据源来得到，不能都在内部总线上。需要增加一个Y寄存器，用于临时保存源操作数</p>
</li>
<li>
<p>ALU还需要有一个寄存器，来临时保存输出结果。这个结果不能总线上，因为如果放总线上的话，它又会当作ALU的输入</p>
</li>
</ul>
<h4 id="implementation-of-control-unit">Implementation of control unit</h4>
<ul>
<li>
<p>The control unit implementation can be done by two methods</p>
<ul>
<li>
<p>Hardwired implementation</p>
</li>
<li>
<p>Microprogrammed implementation</p>
</li>
</ul>
</li>
<li>
<p>Hardwired implementation: the control unit is a combinational circuit</p>
<ul>
<li>The input signals are transferred into a set of output control signals</li>
</ul>
</li>
<li>
<p>时钟发生器：产生时钟信号，并提供计数器</p>
</li>
<li>
<p>译码器：根据指令寄存器中的指令操作码，生成操作码对应的唯一输出，提供给输出控制单元</p>
</li>
<li>
<p>标志：为控制单元提供相关的标志信号</p>
</li>
<li>
<p>控制单元：是控制器的核心，负责产生控制信号</p>
</li>
</ul>
<h4 id="control-matrix">Control matrix</h4>
<ul>
<li>
<p>Programmable arrays may also be numerous</p>
</li>
<li>
<p>Large control matrices are implemented hierarchically for speed</p>
</li>
</ul>
<h4 id="problems-with-hard-wired">Problems With Hard Wired</h4>
<ul>
<li>
<p>Complex micro-operation logic</p>
</li>
<li>
<p>Difficult to design and test</p>
</li>
<li>
<p>Inflexible design</p>
</li>
<li>
<p>Difficult to add new instructions</p>
</li>
</ul>
<h4 id="summary">Summary</h4>
<ul>
<li>
<p>The instructions are divided into a sequence of stages</p>
</li>
<li>
<p>Fetch, indirect, execute, interrupt</p>
</li>
<li>
<p>Each stage is further divided into a sequence of microoperations</p>
<ul>
<li>T1, T2, T3, …</li>
</ul>
</li>
<li>
<p>Each micro-operation occupies one clock unit</p>
</li>
<li>
<p>The function of the control unit is to produce a sequence of timed control signals to control the data paths and ALU operations</p>
</li>
<li>
<p>The control unit is a combinational circuit that transfers inputs to a group of control signals</p>
<ul>
<li>
<p>Inputs: flags, instruction registers, clock, control signals from system bus</p>
</li>
<li>
<p>Outputs: control signals to system bus and within CPU</p>
</li>
</ul>
</li>
</ul>
<h3 id="microprogrammed-control">Microprogrammed Control</h3>
<h4 id="basic-concepts">Basic Concepts</h4>
<ul>
<li>
<p>Control unit can be implemented by a more flexible technique called microprogrammed control unit</p>
<ul>
<li>
<p>The logic of the control unit is specified by a microprogram</p>
</li>
<li>
<p>Each line in microprogram describes a group of micro-operations in one time，called microinstruction</p>
</li>
<li>
<p>Construct a control word corresponding to this microinstruction</p>
</li>
<li>
<p>The control word determines the opening or closing of all doors</p>
</li>
</ul>
</li>
<li>
<p>微指令中包括CPU内控制信号、系统总线控制信号、跳转条件、微指令地址</p>
</li>
<li>
<p>执行这条微指令的效果是，打开CPU内外所有为1的控制线，关闭所有为0的控制线</p>
</li>
<li>
<p>如果条件条件为假，自动执行下一个顺序的微指令</p>
</li>
<li>
<p>如果跳转条件为真，则执行“微指令地址”中对应的微指令</p>
</li>
</ul>
<p><strong>Micro-instruction Types</strong></p>
<ul>
<li>
<p><strong>horizontal microinstruction</strong></p>
<ul>
<li>
<p>水平微指令包括四个部分</p>
<ul>
<li>内部控制信号：CPU内的每一个控制线都有相应的1位</li>
<li>总线控制信号：每一个系统控制总线都有相应的1位</li>
<li>条件字段：指示转移发生条件的字段</li>
<li>微指令地址：转移的目标指令地址</li>
</ul>
</li>
<li>
<p>打开位值为1的控制线，关闭所有位值为0的控制线。执行一个或多个微操作</p>
</li>
<li>
<p>如果跳转条件为假，顺序执行下一个指令。如果跳转条件为真，执行“微指令地址” 指向的微指令</p>
</li>
<li>
<p><strong>Characteristic</strong></p>
<ul>
<li>
<p>Each control line inside the CPU and bus needs to have a separate control bit</p>
<ul>
<li>The width of the control word is very large</li>
</ul>
</li>
<li>
<p>Each line is a separate control bit</p>
<ul>
<li>Each control line can be controlled independently</li>
<li>More kinds of micro operations that can be supported</li>
</ul>
</li>
</ul>
</li>
<li>
<p>The control lines are controlled by one bit of the control word independently</p>
<ul>
<li>The coding of control signal is not compact</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>vertical microinstruction</strong></p>
<ul>
<li>
<p>垂直微指令也包括条件和跳转微指令地址，跟水平微指令类似</p>
</li>
<li>
<p>在控制方面，和水平微指令的每一位对应一个控制线不同，垂直微指令又做了一次编码</p>
</li>
<li>
<p>解决水平微指令的控制字太长的问题</p>
</li>
<li>
<p>编码后，由一个解码器再翻译成控制线的控制信号</p>
</li>
<li>
<p><strong>Characteristic</strong></p>
<ul>
<li>
<p>Width is narrow</p>
<ul>
<li>
<p>n control signals encoded into $\log_2 n$ bits($n \rightarrow 2^n$)</p>
</li>
<li>
<p>Limited number of micro operations supported</p>
</li>
</ul>
</li>
<li>
<p>Additional steps required</p>
<ul>
<li>External memory word decode is needed</li>
<li>Identify the exact control line being manipulated</li>
<li>Send control signal</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="micro-program-word-length">Micro-program Word Length</h4>
<ul>
<li>
<p><strong>Word length is an important factor in microprogram</strong></p>
</li>
<li>
<p><strong>Word length is determined by three factors</strong>\</p>
<ul>
<li>
<p><strong>Maximum number of simultaneous micro-operations supported</strong></p>
</li>
<li>
<p><strong>The way control information is represented or encoded</strong></p>
</li>
<li>
<p><strong>The way in which the next micro-instruction address is specified</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Compromise</strong></p>
<ul>
<li>
<p>Divide control signals into disjoint groups</p>
</li>
<li>
<p>Implement each group as separate field in memory word</p>
</li>
<li>
<p>Supports reasonable levels of parallelism without too much complexity</p>
</li>
</ul>
<h4 id="the-control-memory">The control memory</h4>
<ul>
<li>
<p>The control words are put into a special memory block called control memory, with each word having a unique address</p>
</li>
<li>
<p>The microinstructions are organized as different routines</p>
<ul>
<li>
<p>The microinstructions in each routine are executed sequentially</p>
</li>
<li>
<p>Each routine ends with a branch instruction points to the next routine</p>
</li>
</ul>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-8.png" title="/img/Computer Organization and Architecture/chapter15-8.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-8.png" data-sub-html="<h2>Control memory</h2>">
        
    </a><figcaption class="image-caption"><code>Control memory</code></figcaption>
    </figure>
<ul>
<li>
<p>存储控制器中存储了取指例程、间接例程、中断例程、执行例程等，这些例程规定了在每个周期内需要执行的微操作序列</p>
</li>
<li>
<p>例程中还规定了在执行结束后转移到下面哪一个例程，也就是指定了周期的执行顺序</p>
</li>
<li>
<p>例如，取指周期后，可能会到间接周期，也可能到执行周期，需要根据取指周期来确定</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter15-9.png" title="/img/Computer Organization and Architecture/chapter15-9.png" data-thumbnail="/img/Computer Organization and Architecture/chapter15-9.png" data-sub-html="<h2>Control Unit Microarchitecture</h2>">
        
    </a><figcaption class="image-caption"><code>Control Unit Microarchitecture</code></figcaption>
    </figure>
<ul>
<li>
<p><strong>Sequencing logic</strong></p>
</li>
<li>
<p><strong>Control address register</strong></p>
</li>
<li>
<p><strong>Control memory</strong></p>
</li>
<li>
<p><strong>Control buffer register</strong></p>
</li>
<li>
<p>控制存储器：存储微指令</p>
</li>
<li>
<p>控制地址寄存器：包含下一个将要被读取的微指令地址。类似于PC</p>
</li>
<li>
<p>控制缓冲寄存器：微指令由控制存储器读取之后，放到控制缓冲寄存器中。控制缓冲寄存器的左半部分直接和控制线连接，读取微指令直接生成控制信号，控制门的开或关</p>
</li>
<li>
<p>定序逻辑：负责为控制地址寄存器提供地址，并发出读命令</p>
</li>
</ul>
<h4 id="control-unit-function">Control Unit Function</h4>
<ul>
<li>
<p>Sequence logic unit issues read command</p>
<ul>
<li>
<p>Word specified in control address register is read into control buffer register</p>
</li>
<li>
<p>Control buffer register contents generates control signals and next address information</p>
</li>
</ul>
</li>
<li>
<p>Sequence logic loads new address into control address register based on next address information from control buffer register and ALU flags</p>
</li>
</ul>
<h4 id="next-address-decision">Next Address Decision</h4>
<ul>
<li>
<p>Sequencing logic needs to determine the next microinstruction</p>
<ul>
<li>At the end of each microinstruction, the next microinstruction address is loaded into the control address register</li>
</ul>
</li>
<li>
<p>Depending on ALU flags and control buffer register</p>
<ul>
<li>
<p>Next microinstruction in sequence</p>
</li>
<li>
<p>Jump to a new routine based on jump instructions</p>
</li>
<li>
<p>Jump to a machine instruction routine</p>
</li>
</ul>
</li>
</ul>
<h4 id="next-address">Next Address</h4>
<ul>
<li>
<p>Next microinstruction in sequence</p>
<ul>
<li>Add 1 to control address register</li>
</ul>
</li>
<li>
<p>Jump to new routine based on jump microinstruction</p>
<ul>
<li>Load address field of control buffer register into control address register</li>
</ul>
</li>
<li>
<p>Jump to machine instruction routine</p>
<ul>
<li>Load control address register based on opcode in IR</li>
</ul>
</li>
</ul>
<hr>
<ol>
<li>
<p>指令译码器是将指令寄存器中的操作码翻译成控制寄存器地址</p>
</li>
<li>
<p>控制地址寄存器到控制存储器中找到控制字，并放到控制缓冲寄存器中</p>
</li>
<li>
<p><strong>控制缓冲寄存器进行控制操作。如果是垂直微指令，则需要译码器进行译码后生成控制信号</strong></p>
</li>
<li>
<p>控制信号译码器用于垂直微指令，将控制字翻译成控制线的控制信号，发送到CPU内部和系统总线</p>
</li>
<li>
<p>对于垂直微指令，有一个附加逻辑和时间延迟</p>
</li>
<li>
<p>下一个微指令地址给定序逻辑，以确定执行哪一个微指令</p>
</li>
</ol>
<h4 id="simple-summary">Simple summary</h4>
<ul>
<li>
<p>All the control unit does is generate a set of control signals</p>
<ul>
<li>
<p>Control the opening and closing of each gate</p>
</li>
<li>
<p>Use one control bit to represent the control signal of a door</p>
</li>
<li>
<p>Control bits of all gates constitute control words</p>
</li>
</ul>
</li>
<li>
<p>Have a control word for each group of micro-operations in one time</p>
</li>
<li>
<p>The next microinstruction can be specified in the microinstruction and executed conditionally</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>For machine code instruction</p>
<ul>
<li>
<p>It is generally divided into multiple cycles, such as fetch cycle, execution cycle, etc</p>
</li>
<li>
<p>Multiple microoperations need to be completed</p>
</li>
<li>
<p>Each microoperation corresponds to one control word</p>
</li>
<li>
<p>A group of control words realizes the control function of a machine code</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Today’s large microprocessor</p>
<ul>
<li>
<p>Many instructions and associated register-level hardware</p>
</li>
<li>
<p>Many control points to be manipulated</p>
</li>
</ul>
</li>
<li>
<p>This results in control memory that</p>
<ul>
<li>
<p>Contains a large number of words，co-responding to the number of instructions to be executed</p>
</li>
<li>
<p>Has a wide word width，due to the large number of control points to be manipulated</p>
</li>
</ul>
</li>
</ul>
<h4 id="advantages-and-disadvantages">Advantages and Disadvantages</h4>
<ul>
<li>
<p>Advantages</p>
<ul>
<li>
<p>Simplifies design of control unit</p>
</li>
<li>
<p>Cheaper</p>
</li>
<li>
<p>Less error-prone</p>
</li>
</ul>
</li>
<li>
<p>Disadvantages</p>
<ul>
<li>
<p>Additional processing required</p>
</li>
<li>
<p>Slower</p>
</li>
</ul>
</li>
</ul>
<h4 id="microinstruction-sequencing">Microinstruction Sequencing</h4>
<ul>
<li>
<p>Microinstruction controller has two basic tasks</p>
<ul>
<li>
<p>Microinstruction sequencing： Get the next microinstruction from the control memory</p>
</li>
<li>
<p>Microinstruction execution : Through control word generates control signal for executing the micro instruction</p>
</li>
</ul>
</li>
<li>
<p>Must consider both together</p>
<ul>
<li>Affects instruction format and controller timing</li>
</ul>
</li>
</ul>
<h4 id="sequencing-techniques">Sequencing Techniques</h4>
<ul>
<li>
<p>Two problems must be considered</p>
<ul>
<li>
<p>Size of microinstructions</p>
</li>
<li>
<p>Address generation time</p>
</li>
</ul>
</li>
<li>
<p>Size of microinstructions</p>
<ul>
<li>The larger the microinstruction, the larger the control memory, and the more expensive</li>
<li>Size of microinstructions should be reduced</li>
</ul>
</li>
<li>
<p>Address generation time</p>
<ul>
<li>The requirement to execute microinstructions as quickly as possible</li>
</ul>
</li>
</ul>
<h5 id="address-generation-time">Address generation time</h5>
<ul>
<li>
<p>Determined by instruction register</p>
<ul>
<li>Once per cycle, after instruction is fetched</li>
</ul>
</li>
<li>
<p>Next sequential address</p>
<ul>
<li>Use in most cases</li>
</ul>
</li>
<li>
<p>Branch</p>
<ul>
<li>
<p>Both conditional and unconditional</p>
</li>
<li>
<p>Generally, there is a jump after 3-4 microinstructions</p>
</li>
<li>
<p>Very important</p>
</li>
</ul>
</li>
</ul>
<h5 id="sequencing-techniques-1">Sequencing Techniques</h5>
<ul>
<li>
<p>Based on current microinstruction, condition flags, contents of IR, generate control memory address of next microinstruction</p>
</li>
<li>
<p>The jump of microinstructions can be divided into three modes according to the address information format in the microinstructions</p>
<ul>
<li>
<p>Two address fields</p>
<ul>
<li>
<p>对于双地址字段模式，微指令中提供了2个地址字段</p>
</li>
<li>
<p>控制缓冲寄存器读取微指令后，第一部分产生控制信号，第二部分和第三部分是2个地址，这2个地址，加上指令寄存器的内容，连接到一个多路器中。多路器选择一个送到控制地址寄存器中</p>
</li>
<li>
<p>控制地址寄存器通过译码，产生下一个微指令的地址。地址选择的输入是由转移逻辑模块来完成的，它根据微指令中的控制部分，以及标志位，向多路器提供选择信号</p>
</li>
<li>
<p>双地址字段方式比较简单，微指令中有2个地址，需要更多的位</p>
</li>
</ul>
</li>
<li>
<p>Single address field</p>
<ul>
<li>
<p>单地址字段方式中，微指令中只有一个地址。下一个地址的选择方法是：</p>
<ul>
<li>
<p>地址字段中指定的地址</p>
</li>
<li>
<p>指令寄存器中的代码</p>
</li>
<li>
<p>下一个顺序地址</p>
</li>
</ul>
</li>
<li>
<p>下一个顺序地址是用上一次的控制地址寄存器中的地址+1来得到的</p>
</li>
</ul>
</li>
<li>
<p>Variable format</p>
<ul>
<li>
<p>可变格式提供两种不同格式的指令。用1位来标识当前是哪种格式。</p>
</li>
<li>
<p>在一种格式中，所有位都用于产生控制信号。所以，下一个微指令的地址，或者是下一顺序地址，或者是由指令寄存器来指定</p>
</li>
<li>
<p>另一种格式中，有一些位用于启动转移逻辑模块，其余的位来提供地址。这样就可以进行条件或者无条件转移</p>
</li>
<li>
<p>这种方法的缺点是转移微指令需要花费一个时钟周期</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="microinstruction-execution">Microinstruction Execution</h4>
<ul>
<li>
<p>Microinstruction execution is a periodic basic even</p>
</li>
<li>
<p>Each cycle is made up of two events</p>
<ul>
<li>
<p>Fetch</p>
</li>
<li>
<p>Execute</p>
</li>
</ul>
</li>
<li>
<p>Fetch</p>
<ul>
<li>Get the microinstruction from the control memory according to the generated microinstruction address</li>
</ul>
</li>
<li>
<p>Execute</p>
<ul>
<li>Execute microinstructions and generate control signals</li>
</ul>
</li>
</ul>
<h4 id="execution-effect">Execution effect</h4>
<ul>
<li>
<p>Effect is to generate control signals</p>
</li>
<li>
<p>Internal</p>
<ul>
<li>
<p>Control signals inside the processor</p>
</li>
<li>
<p>Control the internal components of the processor</p>
</li>
</ul>
</li>
<li>
<p>External</p>
<ul>
<li>
<p>Control signals to external control bus or other interface</p>
</li>
<li>
<p>Control disk read-write, I/O read-write etc</p>
</li>
</ul>
</li>
<li>
<p>With the function to generate next address</p>
</li>
</ul>
<h4 id="summary-1">Summary</h4>
<ul>
<li>
<p>A microprogrammed control unit is a relatively simple logic circuit that is capable of</p>
<ul>
<li>
<p>Sequencing through microinstructions</p>
</li>
<li>
<p>Generating control signals to execute each microinstruction</p>
</li>
</ul>
</li>
</ul>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Instruction Level Parallelism and Superscalar Processors</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-instruction-level-parallelism-and-superscalar-processors/</link>
    <pubDate>Mon, 30 Jan 2023 16:28:39 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-instruction-level-parallelism-and-superscalar-processors/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="instruction-level-parallelism-and-superscalar-processors">Instruction Level Parallelism and Superscalar Processors</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>Overview of Superscalar</p>
</li>
<li>
<p>Design Issues of Superscalar</p>
</li>
<li>
<p>Superscalar in Pentium</p>
</li>
<li>
<p>Superscalar in ARM CORTEX-A8</p>
</li>
</ul>
<h3 id="overview-of-superscalar">Overview of Superscalar</h3>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-1.png" title="/img/Computer Organization and Architecture/chapter14-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-1.png" data-sub-html="<h2>Ideal pipeline</h2>">
        
    </a><figcaption class="image-caption"><code>Ideal pipeline</code></figcaption>
    </figure>
<ul>
<li>
<p>理想的指令流水线的执行过程</p>
</li>
<li>
<p>指令执行分为6个阶段，且不共享资源</p>
</li>
<li>
<p>每个时间单位都会有1个指令完成执行</p>
</li>
<li>
<p>指令数量足够多时，执行效率为原来的6倍</p>
</li>
</ul>
<hr>
<p><strong>Actual pipeline</strong></p>
<ul>
<li>
<p>Not all instructions require the same steps</p>
<ul>
<li>Some pipeline stages are idle</li>
</ul>
</li>
<li>
<p>Running time of different pipeline stages is different</p>
<ul>
<li>running time of some pipeline stages is wasted</li>
</ul>
</li>
<li>
<p>Instructions are not independent of each other</p>
<ul>
<li>Poor operation of the pipeline</li>
</ul>
</li>
</ul>
<h4 id="problem-about-pipeline">Problem about pipeline</h4>
<ul>
<li>
<p>The pipeline pauses due to dependencies between instructions, which is called pipeline risk</p>
</li>
<li>
<p>There are three types of dependencies</p>
<ul>
<li>
<p>Data dependence</p>
</li>
<li>
<p>Control dependence</p>
</li>
<li>
<p>resource dependence</p>
</li>
</ul>
</li>
</ul>
<h4 id="question">Question</h4>
<ul>
<li>
<p>Is instruction pipelining truly parallel?</p>
<ul>
<li>
<p>Yes: There are indeed multiple instructions in the pipeline being processed at the same time</p>
</li>
<li>
<p>No: multiple instructions do not enter the pipeline at the same time</p>
</li>
</ul>
</li>
<li>
<p>How to further improve the execution efficiency of instructions?</p>
<ul>
<li>
<p>Optimize pipeline: super pipeline</p>
</li>
<li>
<p>True instruction level parallelism: superscalar pipelining</p>
</li>
</ul>
</li>
</ul>
<h4 id="superpipeline">Superpipeline</h4>
<ul>
<li>
<p>In an ordinary pipeline, each clock cycle can complete processing of one pipeline stage</p>
</li>
<li>
<p>Many pipeline stages need less than half a clock cycle</p>
</li>
<li>
<p>Superpipeline</p>
<ul>
<li>
<p>Double internal clock rate is adopted for instruction scheduling</p>
</li>
<li>
<p>Double internal clock speed gets two tasks per external clock cycle</p>
</li>
</ul>
</li>
<li>
<p>Get twice the instruction throughput</p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-2.png" title="/img/Computer Organization and Architecture/chapter14-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-2.png">
        
    </a>
<ul>
<li>
<p>四阶段流水线，指令划分为4个阶段</p>
</li>
<li>
<p>普通流水线中，每个阶段需要1个时钟周期来完成。最高能达到4倍的指令执行效率，每个时钟周期可以输出1个指令的执行结果</p>
</li>
<li>
<p>超级流水线。通过采用双倍内部时钟的方式，每0.5个外部时钟周期，就能完成1个指令阶段的执行。最高能达到8倍的执行效率</p>
</li>
</ul>
<h5 id="limit-of-superpipeline">Limit of Superpipeline</h5>
<ul>
<li>
<p>The effect is similar to that of increasing the main frequency</p>
</li>
<li>
<p><strong>It is still not really instruction level parallelism</strong></p>
</li>
<li>
<p>The overall performance is limited by the clock cycle and the length of time the instruction phase executes</p>
<ul>
<li>Long execution phases affect overall performance</li>
</ul>
</li>
<li>
<p><strong>Another technology-superscalar</strong></p>
</li>
</ul>
<h4 id="vector-and-scalar">Vector and Scalar</h4>
<ul>
<li>
<p>Scalar</p>
<ul>
<li>
<p>Also called “vector free”. Some physical quantities have only numerical value, but no direction. Some of them are positive or negative</p>
</li>
<li>
<p>A single number used to represent a single attribute of a thing</p>
</li>
<li>
<p>For example: temperature, length</p>
</li>
</ul>
</li>
<li>
<p>Vector</p>
<ul>
<li>
<p>Originally refers to a quantity with size and direction</p>
</li>
<li>
<p>A group of orderly arranged numbers used to demarcate the quantitative characteristics of things</p>
</li>
<li>
<p>For example: the position of a point in the plane coordinate system$ (x, y) $</p>
</li>
</ul>
</li>
</ul>
<h5 id="scalar-instruction">Scalar instruction</h5>
<ul>
<li>
<p>The instructions that do not have vector processing functions and only operate on a single quantity, namely a scalar quantity, are called scalar instructions</p>
</li>
<li>
<p>Most instructions are scalar</p>
</li>
</ul>
<h5 id="vector-instruction">Vector instruction</h5>
<ul>
<li>
<p>The basic operating object is a vector, that is, a group of numbers arranged in order</p>
</li>
<li>
<p>The instruction determines the address of the vector operand and directly or implicitly specifies vector parameters such as increment, vector length, etc</p>
</li>
<li>
<p>The vector instruction specifies that the processor processes vector according to the same operation, which can effectively improve the operation speed</p>
</li>
<li>
<p>Some mainframes are equipped with vector operation instruction systems with complete functions</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-3.png" title="/img/Computer Organization and Architecture/chapter14-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-3.png" data-sub-html="<h2>Superscalar</h2>">
        
    </a><figcaption class="image-caption"><code>Superscalar</code></figcaption>
    </figure>
<ul>
<li>
<p>超标量采用了2个独立的流水线</p>
</li>
<li>
<p>每个流水线都可以再进行指令的并行运行</p>
</li>
<li>
<p>能够并行执行每个阶段的2个指令</p>
</li>
<li>
<p>在稳定运行的状态下，可以达到8倍的执行效率</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-4.png" title="/img/Computer Organization and Architecture/chapter14-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-4.png" data-sub-html="<h2>Ceneral Superscalar organization</h2>">
        
    </a><figcaption class="image-caption"><code>Ceneral Superscalar organization</code></figcaption>
    </figure>
<ul>
<li>
<p>包含了2个整数运算单元，2个浮点数运算单元，一个存储单元</p>
</li>
<li>
<p>整数运算单元中，允许有2个指令并行执行，浮点数运算单元也允许2个浮点指令同时运行。与此同时，1个存储器操作也可以并行来执行</p>
</li>
<li>
<p>这个结构中，同时允许5个指令并行执行</p>
</li>
</ul>
<h4 id="key-problem-of-superscalar">Key problem of superscalar</h4>
<ul>
<li>
<p>Superscalar implementations raise a number of complex design issues related to the instruction pipeline</p>
<ul>
<li>
<p>First, the relevance of the pipeline itself still exists</p>
</li>
<li>
<p>Multiple pipelines bring more complex correlation problems</p>
</li>
</ul>
</li>
<li>
<p>The compiler is required to have more complex optimization techniques to achieve greater instruction level parallelism</p>
</li>
</ul>
<h5 id="application-of-superscalar">Application of superscalar</h5>
<ul>
<li>
<p><strong>Superscalar technology itself is proposed and developed with the development of RISC technology</strong></p>
</li>
<li>
<p>RISC processors also tend to use superscalar technology</p>
</li>
<li>
<p><strong>Although RISC machine lends itself readily to superscalar techniques, the superscalar approach can be used on either a RISC or CISC architecture</strong></p>
</li>
<li>
<p><strong>Superscalar approach has now become the standard method for implementing high-performance microprocessors</strong></p>
</li>
</ul>
<h4 id="factors-limiting-parallelism">Factors limiting parallelism</h4>
<ul>
<li>
<p>Instruction level parallelism</p>
<ul>
<li>The degree to which program instructions can be executed in parallel</li>
</ul>
</li>
<li>
<p>Compiler capabilities</p>
<ul>
<li>The compiler can maximize instruction level parallelism of programs</li>
</ul>
</li>
<li>
<p>Hardware techniques</p>
<ul>
<li>Hardware capability supports parallel operation of instructions</li>
</ul>
</li>
</ul>
<h4 id="limitations">Limitations</h4>
<ul>
<li>
<p>The most important reason for limiting instruction level parallelism is the correlation between instructions in the program</p>
</li>
<li>
<p>The dependencies between instructions include</p>
<ul>
<li>
<p>True data dependency</p>
</li>
<li>
<p>Output dependency</p>
</li>
<li>
<p>Anti-dependency</p>
</li>
<li>
<p>Procedural dependency</p>
</li>
<li>
<p>Resource conflicts</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>True Data Dependency</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-5.png" title="/img/Computer Organization and Architecture/chapter14-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-5.png">
        
    </a>
<ul>
<li>
<p>I0和i1能够同时进行取指和解码</p>
</li>
<li>
<p><strong>但是由于i1取的操作数是i0的结果，所以必须要等到i0执行完之后，i1才能进行取指</strong></p>
</li>
<li>
<p>第二条指令存在一个时钟周期的延迟</p>
</li>
<li>
<p><strong>先写后读，也称为“写后读相关性”</strong></p>
</li>
<li>
<p><strong>这种相关性和指令的执行顺序严格相关，是真实的相关性</strong></p>
</li>
</ul>
<hr>
<p><strong>Procedural dependency</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-6.png" title="/img/Computer Organization and Architecture/chapter14-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-6.png">
        
    </a>
<ul>
<li>
<p>分支前和分支后的指令不能并行执行</p>
</li>
<li>
<p>如果指令非定长，则必须对指令进行解码，才能确定取多长的指令</p>
</li>
<li>
<p><strong>如果使用的是变长指令，在取后续指令之前，前一个指令必须要部分译码，否则下一个指令不知道从内存的哪个位置去取，这阻止了同时取指的操作</strong></p>
</li>
<li>
<p>超标量更适合RISC架构的理由之一，因为RISC的指令都是定长的，不会有这种相关性</p>
</li>
</ul>
<hr>
<p><strong>Resource conflict</strong></p>
<ul>
<li>
<p>资源冲突，也称为资源相关性</p>
</li>
<li>
<p>指令i0和i1在执行过程中，都需要用到同一个功能单元，所以他们不能并行执行，只能串行处理。这里浪费了一个时钟周期</p>
</li>
<li>
<p>资源冲突和数据相关性的表现差不多，但是资源冲突可以通过复制资源来解决，例如在前面讲到的增加干衣机</p>
</li>
</ul>
<h3 id="design-issues-of-superscalar">Design Issues of Superscalar</h3>
<h4 id="parallelism">Parallelism</h4>
<ul>
<li>
<p><strong>Factors limiting parallelism</strong></p>
<ul>
<li>
<p><strong>Instruction level parallelism</strong></p>
</li>
<li>
<p><strong>Compiler capabilities</strong></p>
</li>
<li>
<p><strong>Hardware techniques</strong></p>
</li>
</ul>
</li>
<li>
<p>Instruction level parallelism</p>
<ul>
<li>
<p>Instructions have the characteristics of parallel execution</p>
</li>
<li>
<p>Instructions in a sequence are independent</p>
</li>
<li>
<p>Execution can be overlapped</p>
</li>
<li>
<p>Governed by data and procedural dependency</p>
</li>
</ul>
</li>
</ul>
<h5 id="machine-parallelism">Machine Parallelism</h5>
<ul>
<li>
<p>Machine Parallelism</p>
<ul>
<li>
<p>Ability to take advantage of instruction level parallelism</p>
</li>
<li>
<p>Governed by number of parallel pipelines</p>
</li>
<li>
<p>The ability to find independent instructions and obtain instruction level parallelism</p>
</li>
</ul>
</li>
<li>
<p>Instructions that can be executed in parallel</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Load R1 &lt;- R2(23)
</span></span><span class="line"><span class="cl">Add R3 &lt;- R3, &#34;1&#34;
</span></span><span class="line"><span class="cl">Add R4 &lt;- R4, R2
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>Instructions that cannot be executed in parallel</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Add R3 &lt;- R3, &#34;1&#34;
</span></span><span class="line"><span class="cl">Add R4 &lt;- R3, R2
</span></span><span class="line"><span class="cl">Store[R4] &lt;- R0
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="instruction-issue">Instruction issue</h4>
<ul>
<li>
<p><strong>Instruction issue： the process of starting instructions to be executed by the functional unit of the processor</strong></p>
<ul>
<li>Instruction issue occurs when instruction moves from the decode stage of the pipeline to the first execute stage of the pipeline</li>
</ul>
</li>
<li>
<p><strong>In order to improve the parallelism, it is necessary to use a reasonable issue order, instead of the original order</strong></p>
</li>
<li>
<p>In essence, instruction emission is a strategy to find instructions that can enter the pipeline and be executed</p>
</li>
</ul>
<h5 id="order-about-instruction-issue">Order about instruction issue</h5>
<ul>
<li>
<p>Three sequences are involved in the command sending process</p>
<ul>
<li>
<p>Order in which instructions are fetched</p>
</li>
<li>
<p>Order in which instructions are executed</p>
</li>
<li>
<p>Order in which instructions change registers and memory</p>
</li>
</ul>
</li>
<li>
<p>The one constraint on the processor is that the result must be correct</p>
</li>
<li>
<p>Instruction issue policy refers to the protocol used to start the execution of the command</p>
</li>
</ul>
<h5 id="instruction-issue-policy">Instruction issue policy</h5>
<ul>
<li>
<p><strong>The original instruction stream itself has dependencies</strong></p>
</li>
<li>
<p>To improve the parallelism of execution, the processor may change the order in which instructions are executed</p>
</li>
<li>
<p>The more sophisticated the processor, the less it is bound by a strict relationship between these orderings</p>
</li>
<li>
<p><strong>There are three issue policy</strong></p>
<ul>
<li>
<p><strong>In-order issue with in-order completion</strong></p>
</li>
<li>
<p><strong>In-order issue with out-of-order completion</strong></p>
</li>
<li>
<p><strong>Out-of order issue with out-of –order completion</strong></p>
</li>
</ul>
</li>
</ul>
<h6 id="in-order-issuein-order-completion">In-order issue/in-order completion</h6>
<ul>
<li>
<p>Issue instructions in the order they occur</p>
</li>
<li>
<p>Write the results in the same order to complete the execution of instructions</p>
</li>
<li>
<p><strong>Very inefficient，even scalar pipeline will not use policy</strong></p>
</li>
<li>
<p>In Superscalar pipeline</p>
<ul>
<li>
<p>May fetch more than one instruction</p>
</li>
<li>
<p><strong>To ensure orderly completion, when the functional units conflict, or the execution of the functional units requires multiple cycles, instruction issue must wait</strong></p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-7.png" title="/img/Computer Organization and Architecture/chapter14-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-7.png">
        
    </a>
<ul>
<li>
<p><strong>超标量处理器有2个独立的流水线，能够同时取2个指令</strong></p>
</li>
<li>
<p><strong>有3个执行单元，以及2个写回的单元</strong></p>
</li>
<li>
<p>I1需要2个周期完成执行；I3和I4需要同时使用某个功能单元，导致出现冲突；I5依赖于I4的结果；I5和I6需要同时使用某个功能单元，导致出现冲突</p>
</li>
<li>
<p>成对取指并送到译码单元进行译码。I1需要花费2个时钟周期执行。所以I3和I4需要在第四个周期开始执行。由于I3和I4资源冲突，所以I3和I4需要顺序执行。I5需要依赖I4的结果，并且I5和I6存在资源冲突，所以I5和I6需要串行执行</p>
</li>
<li>
<p>8个指令，总共需要8个时钟周期才能完成</p>
</li>
<li>
<p>由于指令执行的时间不一样，所以如果同时发射的指令给执行单元，需要等全部执行完成之后，才能进行下一次发射</p>
</li>
<li>
<p>如果指令间存在数据依赖关系，需要停止调度行为，等具备条件之后，才能进行指令发射</p>
</li>
</ul>
<hr>
<h6 id="in-order-issueout-of-order-completion">In-order issue/out-of-order completion</h6>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-8.png" title="/img/Computer Organization and Architecture/chapter14-8.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-8.png">
        
    </a>
<ul>
<li>
<p>I1和I2同时发射到执行单元，由于I2只需要1个周期完成，所以I2可以先完成。I3可以和I1同时执行，并进入写的阶段</p>
</li>
<li>
<p>I4由于和I3资源冲突，所以需要等I3完成之后才能执行。I5依赖于I4的结果，所以也需要等待I4，同理I6需要等待I5</p>
</li>
<li>
<p>整体上需要7个周期完成指令的执行</p>
</li>
</ul>
<hr>
<p><strong>Output (write-write) dependency</strong></p>
<ul>
<li>In the process of out of sequence completion, the execution order is different from the original order, which may lead to output dependency problems</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">R3 = R3 + R5 ;(l1)
</span></span><span class="line"><span class="cl">R4 = R3 + 1  ;(l2)
</span></span><span class="line"><span class="cl">R3 = R5 + 1  ;(l3)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>Analyze
<ul>
<li>I2 depends on result of I1 - data dependency</li>
<li>If I3 completes before I1, the result from I1 will be wrong - output (write-write) dependency</li>
</ul>
</li>
</ul>
<hr>
<p><strong>How?</strong></p>
<ul>
<li>
<p><strong>Adopt dynamic scheduling strategy</strong></p>
</li>
<li>
<p>Idea: Move the dependent instructions out of the way of independent ones (s.t. independent ones can execute)</p>
<ul>
<li>Rest areas for dependent instructions: Reservation stations</li>
</ul>
</li>
<li>
<p>Monitor the source “values” of each instruction in the resting area</p>
</li>
<li>
<p>When all source “values” of an instruction are available, “fire” (i.e. dispatch) the instruction</p>
<ul>
<li>Instructions dispatched in <strong>data-flow order，not control-flow</strong></li>
</ul>
</li>
<li>
<p>Benefit</p>
<ul>
<li>
<p>Latency tolerance: Allows independent instructions to execute and complete in the presence of a long latency operation</p>
</li>
<li>
<p>Reasonably schedule instructions with dependencies</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Problem about In-order issue</strong></p>
</li>
<li>
<p>When decoding instructions, if there are related points or conflicting points, the decoding needs to stop</p>
</li>
<li>
<p>In this way, subsequent instructions cannot be decoded</p>
</li>
<li>
<p>At this time, the processor cannot check whether any instruction is independent and can be executed on the pipeline</p>
</li>
</ul>
<hr>
<h6 id="out-of-order-issueout-of-order-completion">Out-of-order issue/out-of-order completion</h6>
<ul>
<li>
<p>Solution: decouple decode from execution</p>
</li>
<li>
<p>Decode</p>
<ul>
<li>
<p>Decode stage can continuously fetch and decode</p>
</li>
<li>
<p>Decoded instruction is put into the buffer</p>
</li>
<li>
<p>As long as the buffer is not full, fetching and decoding can continue</p>
</li>
</ul>
</li>
<li>
<p>Execution</p>
<ul>
<li>
<p>When the functional unit is available, transmit the executable instructions to execute</p>
</li>
<li>
<p>Since the instruction has been decoded, the processor can first identify whether the instruction can be executed</p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-9.png" title="/img/Computer Organization and Architecture/chapter14-9.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-9.png">
        
    </a>
<ul>
<li>第一个周期，I1和I2进行解码，完成解码后进入发射缓冲区。执行单元为空，I1和I2被发射出去执行</li>
<li>第二个周期，I3和I4进行解码，完成解码后进入发射缓冲区。由于I3和I4共用执行单元，I3发射出去进行执行</li>
<li>第三个周期，I5和I6进行解码，完成解码后进入发射缓冲区。此时，I3执行完了，所以I4可以发射了。同时由于I5和I4有数据相关性，所以I5不能发射，于是把I6发射出去执行</li>
<li>第四个周期，没有指令需要解码</li>
<li>第五个周期，没有指令需要解码。此时发射缓冲区只有I5。I6执行完成，可以发射I5指令。I5在第五个时钟周期完成执行，并在第六个时钟周期完成写入操作</li>
<li>整个过程需要6个时钟周期。比之前的又缩短了1个周期</li>
</ul>
<h6 id="anti-dependencywrite-after-read">Anti-dependency(Write-after-read)</h6>
<ul>
<li>
<p>Out-of-order issue/out-of-order completion also need to comply with restrictions</p>
</li>
<li>
<p>Anti correlation occurs</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">R3 = R3 + R5 ;l1
</span></span><span class="line"><span class="cl">R4 = R3 + 1  ;l2
</span></span><span class="line"><span class="cl">R3 = R5 + 1  ;l3
</span></span><span class="line"><span class="cl">R7 = R3 + R4 ;l4
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>Analyze
<ul>
<li>I3 can not complete before I2 starts as I2 needs a value in R3 and I3 changes R3</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Dependency Analyzing</strong></p>
<ul>
<li>
<p>True data dependency reflects the real dependency between data</p>
</li>
<li>
<p>In essence, anti dependency and output dependency are caused by register conflict</p>
<ul>
<li>Register contents may not reflect the correct ordering from the program</li>
</ul>
</li>
<li>
<p>Instruction issue stops, pipeline stall</p>
<ul>
<li>Processor pauses for one cycle</li>
</ul>
</li>
<li>
<p>This situation is more serious when register optimization technology is used</p>
<ul>
<li>
<p>Register optimization technology maximizes the use of registers to improve performance</p>
</li>
<li>
<p>Register conflicts will be more significant</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Register renaming</strong></p>
<ul>
<li>
<p>Registers are dynamically allocated by hardware</p>
</li>
<li>
<p>When an instruction with a register as the destination operand is executed, a new register is allocated</p>
</li>
<li>
<p><strong>The instruction that accesses the original register after this instruction must be modified to the newly allocated register to maintain consistency</strong></p>
</li>
<li>
<p>Avoid dependencies caused by register conflicts</p>
</li>
</ul>
<hr>
<ul>
<li><strong>Original</strong></li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">R3 = R3 + R5 ;I1
</span></span><span class="line"><span class="cl">R4 = R3 + 1  ;I2
</span></span><span class="line"><span class="cl">R3 = R5 + 1  ;I3
</span></span><span class="line"><span class="cl">R7 = R3 + R4 ;I4
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>I1和I2存在真实数据相关性</p>
</li>
<li>
<p>I3和I4存在真实数据相关性</p>
</li>
<li>
<p>I3和I2存在反相关性，读后写</p>
</li>
<li>
<p>I3和I1存在输出相关性，写后写</p>
</li>
<li>
<p><strong>Register renaming</strong></p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">R3b = R3a + R5a ;l1
</span></span><span class="line"><span class="cl">R4b = R3b + 1   ;l2
</span></span><span class="line"><span class="cl">R3c = R5a + 1   ;l3
</span></span><span class="line"><span class="cl">R7 = R3c + R4b  ;l4
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>采用寄存器重命名的规则，I1的R3修改成R3b，I3中的R3，修改成R3c。</p>
</li>
<li>
<p><strong>I3和I2之间的反相关性没有了，I3和I1之间的输出相关性也没有了，I3可以立即发射</strong></p>
</li>
<li>
<p><strong>真实数据相关性无法通过寄存器重命名来解决</strong></p>
</li>
</ul>
<h4 id="analysis-of-three-technologies---">Analysis of three technologies ! ! !</h4>
<ul>
<li>
<p><strong>Techniques for improving performance in superscalar processors</strong></p>
<ul>
<li>
<p><strong>Duplication of Resources</strong></p>
</li>
<li>
<p><strong>Out of order issue</strong></p>
</li>
<li>
<p><strong>Renaming</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Resources are the foundation</strong></p>
<ul>
<li>Sufficient resources to execute multiple pipelines</li>
</ul>
</li>
<li>
<p><strong>Out of order issue is the method</strong></p>
<ul>
<li>Provide executable instructions through disordered transmissionRenaming is a guarantee</li>
</ul>
</li>
<li>
<p><strong>Renaming is a guarantee</strong></p>
<ul>
<li>Rename mechanism reduces the correlation between instructions</li>
</ul>
</li>
</ul>
<h4 id="about-instruction-window">About instruction window</h4>
<ul>
<li>
<p>Out of order issue: register window is used to cache instructions after decoding</p>
</li>
<li>
<p>Through the register window, the processor can identify independent instructions that can be placed in the execution segment</p>
</li>
<li>
<p><strong>If the instruction window is very small, the probability of successful recognition is very low</strong></p>
</li>
<li>
<p><strong>The instruction window needs to be large enough to find independent instructions and use the hardware more effectively</strong></p>
</li>
<li>
<p><strong>Need instruction window large enough (more than 8)</strong></p>
</li>
</ul>
<hr>
<p><strong>Effect of technology</strong></p>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter14-10.png" title="/img/Computer Organization and Architecture/chapter14-10.png" data-thumbnail="/img/Computer Organization and Architecture/chapter14-10.png" data-sub-html="<h2>Without Procedural Dependencies</h2>">
        
    </a><figcaption class="image-caption"><code>Without Procedural Dependencies</code></figcaption>
    </figure>
<ul>
<li>
<p>Base：不复制任何功能单元</p>
</li>
<li>
<p>+Id/st：增加了装入/存储单元</p>
</li>
<li>
<p>+alu：增加了ALU单元</p>
</li>
<li>
<p>+both：增加了ALU和Id/st</p>
</li>
<li>
<p>不考虑过程相关性</p>
</li>
<li>
<p>没有采用寄存器重命名，增加硬件执行效果并不明显。而采用寄存器重命名后，增加了ALU会明显提高加速比</p>
</li>
<li>
<p>从发射窗口的角度来看，窗口数量从8个增加到16个，效果就很明显。但从16个到32个，效果稍差一些</p>
</li>
<li>
<p><strong>资源复制、乱序发射、寄存器重命名三者相互影响</strong></p>
</li>
</ul>
<h4 id="consideration-of-control-dependence">Consideration of control dependence</h4>
<ul>
<li>
<p>Also called branch hazard</p>
</li>
<li>
<p>When branching instructions, it is not possible to determine which instruction to execute after the branch</p>
</li>
<li>
<p>In the pipeline, after prefetching the wrong instruction, it is necessary to discard and re fetch the instruction, which causes the pipeline to fail to run with full load</p>
</li>
</ul>
<p><strong>Methods</strong></p>
<ul>
<li>
<p>Processing method of control dependence</p>
<ul>
<li>
<p>Multiple Streams</p>
</li>
<li>
<p>Prefetch Branch Target</p>
</li>
<li>
<p>Loop buffer</p>
</li>
<li>
<p>Branch prediction</p>
</li>
<li>
<p>Delayed branching</p>
</li>
</ul>
</li>
<li>
<p>Goal: Keep the pipeline running full</p>
</li>
</ul>
<p><strong>About delayed branch</strong></p>
<ul>
<li>
<p>Delayed branching is often used in RIS</p>
</li>
<li>
<p>Calculate result of branch before unusable instructions pre-fetched</p>
<ul>
<li>
<p>Instructions that are not affected by branches are immediately followed by branch</p>
</li>
<li>
<p>Keeps pipeline full while fetching new instruction stream</p>
</li>
</ul>
</li>
<li>
<p>Not as good for superscalar</p>
<ul>
<li>Multiple instructions need to execute in delay slot</li>
<li>Instruction dependence problems</li>
<li>Often use branch prediction</li>
</ul>
</li>
</ul>
<p><strong>Superscalar execution</strong></p>
<ul>
<li>
<p>静态程序通过取指和分支预测，形成动态的指令流</p>
</li>
<li>
<p>指令流经过处理器的相关性检查，会去掉不必要的相关性，比如反相关和输出相关。然后将指令放到执行窗口中，等待执行</p>
</li>
<li>
<p>在执行窗口中的指令，根据真实数据相关性来排序。处理器根据真实数据相关性和资源可用性，来发射指令到执行单元进行执行</p>
</li>
<li>
<p>最后的执行结果需要有一个提交的步骤。因为指令不是按照原有的顺序来执行的，同时分支预测和推测执行使得有些执行的结果需要丢弃</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Simultaneously fetch multiple instructions</p>
<ul>
<li>
<p>Multiple fetching and decoding</p>
</li>
<li>
<p>Branch prediction logic</p>
</li>
</ul>
</li>
<li>
<p>Logic to determine true dependencies involving register values</p>
<ul>
<li>Determine instruction position of true correlation</li>
</ul>
</li>
<li>
<p>Dealing with unnecessary dependencies</p>
<ul>
<li>Anti-dependency and output dependency</li>
</ul>
</li>
<li>
<p>Mechanisms to initiate multiple instructions in parallel</p>
<ul>
<li>
<p>Instruction window</p>
</li>
<li>
<p>Out of order issue logic</p>
</li>
</ul>
</li>
<li>
<p>Resources for parallel execution of multiple instructions</p>
<ul>
<li>The system has sufficient resources</li>
</ul>
</li>
<li>
<p>Mechanisms for committing process state in correct order</p>
<ul>
<li>Submit results according to the order of instructions</li>
</ul>
</li>
</ul>
<h4 id="summary">Summary</h4>
<ul>
<li>
<p><strong>Resources are the foundation</strong></p>
<ul>
<li><strong>Machine parallelism</strong></li>
</ul>
</li>
<li>
<p><strong>Out of order issue is the method</strong></p>
<ul>
<li><strong>Instruction level parallelism</strong></li>
</ul>
</li>
<li>
<p><strong>Renaming is a guarantee</strong></p>
<ul>
<li><strong>Methods of improving instruction level parallelism</strong></li>
</ul>
</li>
<li>
<p>Through superscalar pipeline, multiple pipelines can run at the same time to achieve truly parallel operation at the instruction level</p>
</li>
</ul>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Reduced Instruction Set Computers</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-reduced-instruction-set-computers/</link>
    <pubDate>Sun, 29 Jan 2023 16:34:59 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-reduced-instruction-set-computers/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="reduced-instruction-set-computers">Reduced Instruction Set Computers</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>Register and instruction architecture</p>
</li>
<li>
<p>Reduced Instruction Set Architecture</p>
</li>
<li>
<p>The Use of a Large Register File</p>
</li>
<li>
<p>Compiler-Based Register Optimization</p>
</li>
<li>
<p><code>RISC</code> Pipelining</p>
</li>
<li>
<p><code>RISC</code> Versus <code>CISC</code> Controversy</p>
</li>
</ul>
<h3 id="register-and-instruction-architecture">Register and instruction architecture</h3>
<p><strong>Major advanced in computers</strong></p>
<ul>
<li>
<p><strong>The family concept</strong></p>
<ul>
<li>
<p>IBM System/360 1964，DEC PDP-8</p>
</li>
<li>
<p><strong>Separates architecture from implementation</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Microprogrammed control unit</strong></p>
<ul>
<li>
<p>Idea by Wilkes 1951,Produced by IBM S/360 1964</p>
</li>
<li>
<p><strong>Easier controller design and implementation</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Cache</strong></p>
<ul>
<li>
<p>IBM S/360 model 85 1969</p>
</li>
<li>
<p><strong>Greatly improves the performance of computer</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Microprocessors</strong></p>
<ul>
<li>
<p>Intel 4004 1971</p>
</li>
<li>
<p><strong>Reduced the size of the computer</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Pipelining</strong></p>
<ul>
<li>
<p><strong>Introducing parallelism into instruction execution</strong></p>
</li>
<li>
<p><strong>Greatly improves instruction throughput</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Multiple processors</strong></p>
<ul>
<li>
<p><strong>Multiple processors combine to form a new architecture</strong></p>
</li>
<li>
<p><strong>Further improve the processing capacity of the computer</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>RISC</strong></p>
<ul>
<li>
<p>Major challenges to traditional CPU</p>
</li>
<li>
<p>It has been widely used</p>
</li>
<li>
<p>Learn from RISC and be widely used in different fields</p>
</li>
</ul>
</li>
<li>
<p>Solid State RAM</p>
<ul>
<li>Access speed is much faster than mechanical hard disk</li>
<li>Greatly improves the computer’s I/O performance</li>
</ul>
</li>
</ul>
<h4 id="register-and-isas">Register and ISAs</h4>
<ul>
<li>
<p>Accumulators</p>
<ul>
<li>
<p>Early stored-program computers had <strong>one</strong> register</p>
</li>
<li>
<p>Very inconvenient to use</p>
</li>
<li>
<p>Requires a memory-based operand-addressing mode in instruction</p>
</li>
</ul>
</li>
</ul>
<p>Example</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">ADD 200
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>Add the accumulator to the word in memory at address 200</strong></p>
</li>
<li>
<p>Place the sum back in the accumulator</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Next step, more registers…</p>
<ul>
<li>
<p>Dedicated registers</p>
<ul>
<li>
<p>separate accumulators for multiply or divide instructions</p>
</li>
<li>
<p>op-of-stack pointer</p>
</li>
</ul>
</li>
<li>
<p>Extended Accumulator</p>
<ul>
<li>Increase bits of register</li>
<li>Increase the number of registers</li>
</ul>
</li>
</ul>
</li>
<li>
<p>More flexible</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Next step, more registers…</p>
<ul>
<li>General-purpose registers
<ul>
<li>Registers can be used for any purpose E.g. MIPS, ARM, x86</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Instruction architecture</p>
<ul>
<li>
<p><em>Register-memory</em> architectures</p>
<ul>
<li><strong>One operand may be in memory</strong> (i.e. 80386 processors)</li>
</ul>
</li>
<li>
<p><em>Register-register</em> architectures (load-store)</p>
<ul>
<li><strong>All operands must be in registers</strong> E.g. MIPS, ARM</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="comparison-of-processors">Comparison of processors</h4>
<ul>
<li>
<p>指令数量、长度、寻址方式等方面，CISC明显高于RISC</p>
</li>
<li>
<p>RISC和超标量的通用寄存器数量比CISC要多</p>
</li>
<li>
<p>RISC和超标量一般采用硬布线控制，所以没有配置控制存储器</p>
</li>
</ul>
<h3 id="reduced-instruction-set-architecture">Reduced Instruction Set Architecture</h3>
<h4 id="cisc">CISC</h4>
<ul>
<li>
<p><strong>CISC&ndash;Complex Instruction Set Computer</strong></p>
</li>
<li>
<p>With the development of computer technology, an instruction set design concept is proposed</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>The gap between high-level programming languages and instruction sets is growing</p>
<ul>
<li>
<p><strong>Need more complex compilers to translate high-level languages</strong></p>
</li>
<li>
<p><strong>A high-level language statement requires multiple instructions to complete，low execution efficiency</strong></p>
</li>
</ul>
</li>
<li>
<p>CISC proposed by instruction set designer</p>
<ul>
<li>
<p><strong>Provides more types of instructions, and even uses a single instruction to implement complex high-level language statements</strong></p>
</li>
<li>
<p><strong>Provide more addressing modes to meet the needs of high-level languages for various addressing</strong></p>
</li>
</ul>
</li>
</ul>
<h5 id="characteristics-of-cisc">Characteristics of CISC</h5>
<ul>
<li>
<p>There are many kinds of instruction opcodes</p>
<ul>
<li>The opcode of X86 is 1-2 bytes</li>
</ul>
</li>
<li>
<p>Variable instruction length</p>
<ul>
<li>The instruction length of X86 is 1-16 bytes</li>
</ul>
</li>
<li>
<p>Various addressing modes</p>
<ul>
<li><strong>X86 has 9 addressing modes</strong>, such as base address proportional index band offset</li>
</ul>
</li>
</ul>
<h5 id="ideal-effect-of-cisc">Ideal effect of CISC</h5>
<ul>
<li>
<p><strong>Compilers are easy to write</strong></p>
<ul>
<li>
<p>The instruction set provides many types of instructions</p>
</li>
<li>
<p>The compiler can use the most appropriate instructions to translate statements in high-level languages. Less instructions after compilation and less space</p>
</li>
<li>
<p>The instruction set provides rich addressing modes</p>
</li>
<li>
<p>Meet the requirements of high-level language for flexible addressing mode</p>
</li>
</ul>
</li>
<li>
<p>Improve the execution efficiency of high-level language statements</p>
<ul>
<li>
<p>It used to require multiple instructions to complete statements in a high-level language, but now it can be completed with one instruction, and some high-level language statements can be implemented at the hardware level</p>
</li>
<li>
<p>Instruction level addressing mode to help implement complex instructions</p>
</li>
</ul>
</li>
</ul>
<h5 id="instruction-execution-characteristics">Instruction execution characteristics</h5>
<ul>
<li>
<p>Operations performed</p>
<ul>
<li>Functions that can be completed by CPU and interaction with memory</li>
</ul>
</li>
<li>
<p>Operands used</p>
<ul>
<li>Type and frequency of operands，which determine the organization and addressing mode of the storage system</li>
</ul>
</li>
<li>
<p>Execution sequencing</p>
<ul>
<li>Control function and pipeline organization</li>
</ul>
</li>
</ul>
<h6 id="operations">Operations</h6>
<ul>
<li>
<p>It is best to optimize the most used and time-consuming statements</p>
</li>
<li>
<p>Assignments</p>
<ul>
<li>Movement of data</li>
</ul>
</li>
<li>
<p>Condition(Loop and IF)</p>
<ul>
<li>Sequence control</li>
</ul>
</li>
<li>
<p>Procedure call-return</p>
<ul>
<li>Very time consuming</li>
</ul>
</li>
<li>
<p><strong>过程调用和返回是典型的高级语言程序中最耗时的操作</strong></p>
</li>
<li>
<p><strong>循环语句、条件语句和幅值语句也占很大的比重</strong></p>
</li>
</ul>
<hr>
<ul>
<li>Operands
<ul>
<li>
<p>主要是局部标量变量</p>
</li>
<li>
<p>优化方向应集中于本地变量的存储和访问</p>
</li>
</ul>
</li>
</ul>
<h5 id="procedure-calls">Procedure calls</h5>
<ul>
<li>
<p><strong>Very time consuming</strong></p>
<ul>
<li>
<p>Depends on number of parameters passed</p>
</li>
<li>
<p>Depends on level of nesting</p>
</li>
</ul>
</li>
<li>
<p>Characteristics</p>
<ul>
<li>
<p>Number of parameter is mostly less than 6</p>
</li>
<li>
<p>Most variables are local</p>
</li>
<li>
<p>Most programs do not do a lot of calls followed by lots of returns</p>
</li>
</ul>
</li>
<li>
<p>It further explains that operand access is highly localized</p>
</li>
</ul>
<h5 id="summary">Summary</h5>
<ul>
<li>
<p>Assignment statement</p>
<ul>
<li>
<p>high proportion, valuable to improve efficiency</p>
</li>
<li>
<p>Need to access cache or storage</p>
</li>
<li>
<p>Use register access to reduce memory access and improve efficiency</p>
</li>
</ul>
</li>
<li>
<p>Condition and procedure calls</p>
<ul>
<li>
<p>time consuming, high proportion, valuable to improve efficiency</p>
</li>
<li>
<p>Influence the execution of the pipeline</p>
</li>
<li>
<p>Design a better pipeline to reduce the impact of transfer statements on the water line</p>
</li>
</ul>
</li>
</ul>
<p><strong>单纯依靠提供接近于高级语言的指令并不一定能提高典型语句的执行效率</strong></p>
<hr>
<ul>
<li>
<p><strong>Ideal 1 of CISC: Compilers are easy to write</strong></p>
</li>
<li>
<p>Implementation method: complex instruction</p>
</li>
<li>
<p>Compiler simplification?</p>
<ul>
<li>
<p>Because of strict requirements of instruction design，compiler needs high-level language strictly meet the instruction</p>
</li>
<li>
<p>The compiler needs to optimize machine instructions to reduce the length of generated machine code and meet the requirements of pipeline operation. This is also difficult to achieve for complex instructions Optimization more difficult</p>
</li>
</ul>
</li>
<li>
<p><strong>Ideal 2 of CISC: smaller programs</strong></p>
</li>
<li>
<p>Implementation method: mores instruction</p>
</li>
<li>
<p>Smaller programs?</p>
<ul>
<li>
<p>Program looks using less memory</p>
</li>
<li>
<p>Memory is now cheap</p>
</li>
<li>
<p>May not occupy less bits, just look shorter in symbolic form</p>
</li>
<li>
<p>More instructions require longer op-codes</p>
</li>
<li>
<p>CISC has no fewer machine instructions than RISC</p>
</li>
</ul>
</li>
<li>
<p><strong>Ideal 3 of CISC: high efficiency</strong></p>
</li>
<li>
<p>Implementation method: more instructions and more addressing mode</p>
</li>
<li>
<p>Faster programs?</p>
<ul>
<li>
<p>Compiler bias towards use of simpler instructions</p>
</li>
<li>
<p>CISC need more complex control unit</p>
</li>
<li>
<p>Microprogram control store larger</p>
</li>
<li>
<p>Simple instructions take longer to execute</p>
</li>
</ul>
</li>
</ul>
<h5 id="conclusion">Conclusion</h5>
<ul>
<li>
<p>The goal CISC hopes to achieve is actually contradictory to the way CISC realizes it</p>
</li>
<li>
<p>Target: improve operational efficiency by optimizing the most frequently used and time-consuming functions</p>
</li>
<li>
<p>Following methods may be better choices</p>
<ul>
<li>
<p>More registers to reduce memory access</p>
</li>
<li>
<p>Careful design of pipeline to improve the efficiency of the pipeline</p>
</li>
<li>
<p>Careful designed simple instruction set to improve the efficiency of instruction execution</p>
</li>
</ul>
</li>
</ul>
<h4 id="risc">RISC</h4>
<ul>
<li>
<p>RISC: Reduced Instruction Set Computer</p>
</li>
<li>
<p>Key features</p>
<ul>
<li>
<p><strong>Large number of general purpose registers</strong></p>
</li>
<li>
<p><strong>Compiler technology to optimize register use</strong></p>
</li>
<li>
<p><strong>Limited and simple instruction set</strong></p>
</li>
<li>
<p><strong>Emphasis on optimising the instruction pipeline</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>Main contributors of RISC</strong></p>
<ul>
<li>
<p>John Cocke: IBM</p>
<ul>
<li>Influences: Known as “the father of RISC Architecture”. Turing Award Recipient and National Medal of Science</li>
</ul>
</li>
<li>
<p>Dave Patterson: UC Berkeley</p>
<ul>
<li>Influences: Sun SPARC from his achievements</li>
</ul>
</li>
<li>
<p>John L. Hennessy: Stanford</p>
<ul>
<li>Influences: In 1984, MIPS (Microprocessor without interlocked pipelined stages) was founded</li>
</ul>
</li>
</ul>
<h5 id="typical-features-of-risc">Typical features of RISC</h5>
<ul>
<li>
<p><strong>Simplified instruction set</strong></p>
<ul>
<li>
<p><strong>Standardized, fixed length</strong> instruction format (ARM instructions are all 32-bit)</p>
</li>
<li>
<p><strong>Limited operation types, only 8-bit operation code</strong></p>
</li>
<li>
<p><strong>Fetching and decoding instruction become easier</strong></p>
</li>
<li>
<p>One instruction per machine cycle</p>
</li>
<li>
<p>Hardwired design (no microcode)</p>
</li>
</ul>
</li>
<li>
<p>Use registers whenever possible</p>
<ul>
<li>
<p>Except for load/save instructions, other instructions are for register operations</p>
</li>
<li>
<p><strong>Data operations can only be performed in registers</strong></p>
</li>
<li>
<p><strong>Memory access has only three addressing modes</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Better pipeline design</strong></p>
<ul>
<li>
<p>Instruction pipeline is carefully designed to better meet the impact of conditional branches and procedure calls on the flow pipeline</p>
</li>
<li>
<p><strong>Each instruction is conditionally executed, which can reduce branches</strong></p>
</li>
</ul>
</li>
</ul>
<h5 id="influence-of-risc-concept">Influence of RISC concept</h5>
<ul>
<li>
<p><strong>RISC&rsquo;s design concept gave birth to a series of new computer architectures</strong></p>
<ul>
<li>Simplified pipeline design on RISC instruction set is becoming more and more attractive</li>
</ul>
</li>
<li>
<p><strong>RISC and CISC learn from each other</strong></p>
<ul>
<li>
<p>Make up for the disadvantage of CISC pipeline implementation</p>
</li>
<li>
<p>RISC is also learning from CISC, and both sides are learning from each other</p>
</li>
</ul>
</li>
<li>
<p><strong>Current situation</strong></p>
</li>
<li>
<p>With the development of architecture and microelectronics technology, the so-called disadvantage of CISC in structure is gradually reduced</p>
</li>
<li>
<p>RISC&rsquo;s theory of superiority has gradually died down, and RISC camp has been losing ground</p>
</li>
</ul>
<blockquote>
<p>Focus on the design and implementation of micro structures and physics, and explore the possibilities buried in operating systems, compilers and upper applications</p>
</blockquote>
<h5 id="summary-1">Summary</h5>
<ul>
<li>
<p>The number of available registers greatly influenced the <strong>instruction set architecture (ISA)</strong></p>
</li>
<li>
<p>Complex Instruction Set Computers were very complex</p>
</li>
<li>
<p><strong>CISC was necessary</strong></p>
<ul>
<li>
<p>The processor of X86 architecture dominates the server and desktop market</p>
</li>
<li>
<p>X86 draws many advantages from RISC</p>
</li>
</ul>
</li>
<li>
<p><strong>RISC is still widely concerned and applied</strong></p>
<ul>
<li>
<p><strong>ARM occupies a major share of the embedded market</strong></p>
</li>
<li>
<p><strong>Mobile phones, tablets PC and various sensors in daily life mostly adopt ARM architecture</strong></p>
</li>
<li>
<p><strong>ARM borrows a bit from both RISC and CISC</strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="the-use-of-a-large-register-file">The Use of a Large Register File</h3>
<ul>
<li>
<p>Target: Keep frequently accessed operands in registers</p>
</li>
<li>
<p>Software solution</p>
<ul>
<li>
<p>Require compiler to allocate registers</p>
</li>
<li>
<p>Allocate based on most used variables in a given time</p>
</li>
<li>
<p>Requires sophisticated program analysis</p>
</li>
</ul>
</li>
<li>
<p>Hardware solution</p>
<ul>
<li>
<p>Have more registers</p>
</li>
<li>
<p>Thus more variables will be in registers</p>
</li>
</ul>
</li>
</ul>
<h4 id="how-and-problem">How and problem?</h4>
<ul>
<li>
<p>Limited number of registers requires reasonable use, and the locality principle provides the possibility</p>
<ul>
<li>
<p>Store local scalar variables in registers</p>
</li>
<li>
<p>Reduces memory access</p>
</li>
</ul>
</li>
<li>
<p><strong>Every procedure (function) call changes locality</strong></p>
<ul>
<li>
<p>Parameters must be passed</p>
</li>
<li>
<p>Results must be returned</p>
</li>
<li>
<p>Variables from calling programs must be restored</p>
</li>
</ul>
</li>
</ul>
<h4 id="register-windows">Register windows</h4>
<ul>
<li>
<p><strong>Characteristics of procedure call</strong></p>
<ul>
<li>
<p><strong>Only few parameters</strong></p>
</li>
<li>
<p><strong>Limited range of depth of call</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Divide the available registers into several small registers set</strong></p>
<ul>
<li>
<p><strong>Calls switch to a different set of registers</strong></p>
</li>
<li>
<p><strong>Returns switch back to a previously used set of registers</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Set of registers called register windows</strong></p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Three areas within a register set</strong></p>
<ul>
<li>
<p><strong>Parameter registers</strong></p>
</li>
<li>
<p><strong>Local registers</strong></p>
</li>
<li>
<p><strong>Temporary registers</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Temporary registers from one set overlap parameter registers from the next</strong></p>
<ul>
<li><strong>This allows parameter passing without moving data</strong></li>
</ul>
</li>
<li>
<p><strong>At any time, only one register window is visible</strong></p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter13-1.png" title="/img/Computer Organization and Architecture/chapter13-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter13-1.png" data-sub-html="<h2>Overlapping register windows</h2>">
        
    </a><figcaption class="image-caption"><code>Overlapping register windows</code></figcaption>
    </figure>
<ul>
<li>
<p>本级的临时变量寄存器和下一级的参数寄存器在物理上是同一个，在传递参数时，不需要移动数据</p>
</li>
<li>
<p>程序中过程的调用和返回的数量不确定，所以寄存器窗口应该足够多，以保证所有的过程调用都能用到</p>
</li>
<li>
<p>由于寄存器的数量有限，只能保证少数最近的过程能够使用寄存器。更早的过程调用还是需要保存到存储器中。当嵌套深度减少的时候，再将数据从存储器恢复到寄存器中</p>
</li>
<li>
<p>这种方式称为<strong>环形缓冲窗口</strong></p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter13-2.png" title="/img/Computer Organization and Architecture/chapter13-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter13-2.png" data-sub-html="<h2>Circular buffer diagram</h2>">
        
    </a><figcaption class="image-caption"><code>Circular buffer diagram</code></figcaption>
    </figure>
<ul>
<li>
<p><strong>寄存器窗口以一种部分重叠的形式形成一个环形。当环形寄存器窗口都充满了后，再有过程调用，把最早的寄存器窗口保存到存储器</strong></p>
</li>
<li>
<p>调用时，移动当前窗口指针以显示当前活动的寄存器窗口</p>
</li>
<li>
<p><strong>如果所有窗口都在使用中，将生成一个中断，并将最早的窗口（调用嵌套中最远的窗口）保存到内存中</strong></p>
</li>
<li>
<p>保存的窗口指针标识最近保存在内存中的窗口</p>
</li>
<li>
<p>当过程返回的时候，CWP会回退一个。当CWP回退到和SWP一样的时候，就会引起一个中断，导致保存到存储器中的寄存器窗口恢复</p>
</li>
<li>
<p>嵌套层数不会太深，所以一般不会保存到存储器中</p>
</li>
</ul>
<h4 id="global-variables">Global variables</h4>
<ul>
<li>
<p>Allocated by the compiler to memory</p>
<ul>
<li>
<p><strong>Inefficient for frequently accessed variables</strong></p>
</li>
<li>
<p><strong>Frequent access to memory, low efficiency</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>A set of registers for global variables</strong></p>
<ul>
<li>
<p><strong>compiler determines which global variables can be placed in global registers</strong></p>
</li>
<li>
<p><strong>Replacement is also determined by the compiler</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="registers-v-cache">Registers v cache</h4>
<ul>
<li>
<p>Cache</p>
<ul>
<li>Inserting cache between processor and memory can solve the problem of speed difference</li>
</ul>
</li>
<li>
<p>Register</p>
<ul>
<li>organized in the form of windows, which is similar to a small fast buffer. It stores a subset of all variables that may be used many times</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>寄存器组中保存的是所有局部标量变量。cache保存的是最近使用过的标量变量</p>
</li>
<li>
<p>寄存器组中保存的是个别的变量。cache中保存的是内存中的一个块</p>
</li>
<li>
<p>寄存器组方案中，需要编译器来决定全局变量的保存。cache中则是根据最近使用原则进行管理</p>
</li>
<li>
<p>寄存器的数据保存或者恢复，依赖的是过程调用嵌套的深度。cache根据替换算法进行替换</p>
</li>
<li>
<p>寄存器组采用的是寄存器寻址。cache采用的是内存寻址</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>The register saves time because all local scalar variables are retained</p>
<ul>
<li>Not efficient use of space, because not all procedures will need the full window space allocated to them</li>
</ul>
</li>
<li>
<p>The cache may make more efficient use of space because it stores necessary data dynamically</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter13-3.png" title="/img/Computer Organization and Architecture/chapter13-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter13-3.png" data-sub-html="<h2>Register access</h2>">
        
    </a><figcaption class="image-caption"><code>Register access</code></figcaption>
    </figure>
<ul>
<li>
<p>要访问基于窗口的寄存器组中的一个标量变量，需要给出窗口号和一个寄存器号</p>
</li>
<li>
<p>通过一个相对简单的译码器，就可以得到对应的寄存器，读出这个数据</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter13-4.png" title="/img/Computer Organization and Architecture/chapter13-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter13-4.png" data-sub-html="<h2>Cache access</h2>">
        
    </a><figcaption class="image-caption"><code>Cache access</code></figcaption>
    </figure>
<ul>
<li>
<p>对于cache访问，需要生成一个完整的地址，操作的复杂度和寻址方式有关</p>
</li>
<li>
<p>进行对比，看数据是否命中</p>
</li>
<li>
<p>如果命中，就可以读取数据</p>
</li>
<li>
<p>如果没有命中，那么就需要先替换cache行，然后才能得到数据</p>
</li>
</ul>
<h3 id="compiler-based-register-optimization">Compiler-Based Register Optimization</h3>
<ul>
<li>
<p><strong>HLL programs have no explicit references to registers</strong></p>
</li>
<li>
<p><strong>Optimizing use is up to compiler</strong></p>
<ul>
<li>
<p>Assign symbolic or virtual register to each candidate variable</p>
</li>
<li>
<p>Map symbolic registers to real registers</p>
</li>
<li>
<p>Symbolic registers that do not overlap can share real registers</p>
</li>
<li>
<p>If you run out of real registers，some variables use memory</p>
</li>
</ul>
</li>
<li>
<p><strong>The essence is to judge which data needs to be put in the register at any time</strong></p>
</li>
</ul>
<h4 id="graph-coloring">Graph coloring</h4>
<ul>
<li>
<p>Symbol registers is more than register</p>
</li>
<li>
<p>determine which symbol registers can use the actual registers</p>
</li>
<li>
<p><strong>Using Graph Coloring of topology</strong></p>
<ul>
<li>
<p>Given a graph of nodes and edges</p>
</li>
<li>
<p>Assign a colour to each node</p>
</li>
<li>
<p>Adjacent nodes have different colours</p>
</li>
<li>
<p>Use minimum number of colours</p>
</li>
</ul>
</li>
<li>
<p>Nodes are symbolic registers</p>
</li>
<li>
<p>Two registers that are live in the same program fragment are joined by an edge</p>
</li>
<li>
<p>Try to colour the graph with <em>n</em> colours, where <em>n</em> is the number of real registers</p>
</li>
<li>
<p>Nodes that can not be coloured are placed in memory</p>
</li>
</ul>
<hr>
<p><strong>Graph colouring approach</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter13-5.png" title="/img/Computer Organization and Architecture/chapter13-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter13-5.png">
        
    </a>
<ul>
<li>
<p>构造无向图：A和BC在时间上有重叠，A和BC有连线；B和所有的节点都有时间重叠，B和所有的节点都有连线。C和ABD有时间上的重叠，C和ABD有连线</p>
</li>
<li>
<p>从A开始，给A赋一个灰色，B和C必须要和A不一样，并且B和C也不能一样，给B附一个顺斜杠，C赋一个反斜杠。D节点和BC相连，和A不相连，D点可以用灰色。E节点和BD相连，E可以用C的颜色。F和BED相连，而BDE分别是正斜杠、灰色和反斜杠，F必须要用到第四个颜色</p>
</li>
<li>
<p>如果物理寄存器只有3个的话，那么F就需要保存到存储器中了，通过加载和保存来处理</p>
</li>
</ul>
<h4 id="large-register-vs-compiler">Large Register vs Compiler</h4>
<ul>
<li>
<p>When the number of registers is small, the effect will be better by optimizing the registers</p>
</li>
<li>
<p>When the number of registers is large, the effect of register optimization will not be very good</p>
</li>
<li>
<p>Optimization of registers is mainly for the case of a small number of registers</p>
</li>
</ul>
<h3 id="risc-pipelining">RISC Pipelining</h3>
<ul>
<li>
<p>Most instructions are register to register</p>
</li>
<li>
<p>Two phases of execution</p>
<ul>
<li>
<p>I: Instruction fetch</p>
</li>
<li>
<p>E: Execute</p>
<ul>
<li>ALU operation with register input and output</li>
</ul>
</li>
</ul>
</li>
<li>
<p>For load and store</p>
<ul>
<li>
<p>I: Instruction fetch</p>
</li>
<li>
<p>E: Execute: Calculate memory address</p>
</li>
<li>
<p>D: Register to memory or memory to register operation</p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter13-6.png" title="/img/Computer Organization and Architecture/chapter13-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter13-6.png">
        
    </a>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter13-7.png" title="/img/Computer Organization and Architecture/chapter13-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter13-7.png">
        
    </a>
<ul>
<li>
<p>图a是没有采用流水线技术，完全按照顺序来执行</p>
</li>
<li>
<p><strong>图b是采用两阶段流水线的执行情况。由于同时只能有1个存储器访问，取指和存储会冲突，导致取指会延后一个时钟周期</strong></p>
</li>
<li>
<p>存储器的访问限制导致了时钟周期的浪费</p>
</li>
<li>
<p>如果存储支持2个访问，可以用三阶段流水线</p>
</li>
<li>
<p>指令相关性：Add rC$\leftarrow$rA+rB，指令需要的操作数为rA和rB。而第二条指令要到第四个时钟周期才能得到rB。所以要插入一个空指令NOOP</p>
</li>
<li>
<p>指令执行阶段，通常涉及到寄存器的读和ALU的操作，把E阶段进一步分为E1和E2。其中E1阶段完成寄存器的读，而E2阶段则完成ALU操作和寄存器的写操作</p>
</li>
<li>
<p>使用四阶段流水线来提高效率。但同样需要考虑相关性问题</p>
</li>
</ul>
<h4 id="optimization-of-pipelining">Optimization of Pipelining</h4>
<ul>
<li>
<p>Dependency of data and branch will disrupt the pipeline and affect the efficiency</p>
</li>
<li>
<p>Two methods: Delayed branch, Loop Unrolling</p>
</li>
<li>
<p>Delayed branch</p>
<ul>
<li>
<p>Branch instruction affects only the instructions that follow it</p>
</li>
<li>
<p>This following instruction is the delay slot</p>
</li>
<li>
<p><strong>Arrange a useful instruction to replace the NOOP instruction</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="delayed-branch">delayed branch</h4>
<ul>
<li>
<p><strong>Calculate result of branch before unusable instructions pre-fetched</strong></p>
<ul>
<li>
<p><strong>Instructions that are not affected by branches are immediately followed by branch</strong></p>
</li>
<li>
<p><strong>Keeps pipeline full while fetching new instruction stream</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Not as good for superscalar</strong></p>
<ul>
<li>
<p>Multiple instructions need to execute in delay slot</p>
</li>
<li>
<p>Instruction dependence problems</p>
</li>
<li>
<p>Often use branch prediction</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Problem: How do you find instructions to fill the delay slots?</p>
<ul>
<li>
<p>Branch must be independent of delay slot instructions</p>
</li>
<li>
<p>Unconditional branch: Easier to find instructions to fill the delay slot</p>
</li>
<li>
<p>Conditional branch: Condition computation should not depend on instructions in delay slots → difficult to fill the delay slot</p>
</li>
</ul>
</li>
</ul>
<h4 id="advantage">Advantage</h4>
<ul>
<li>
<p>Keeps the pipeline full with useful instructions in a simple way assuming</p>
<ul>
<li>
<p>Number of delay slots = number of instructions to keep the pipeline full before the branch resolves</p>
</li>
<li>
<p>All delay slots can be filled with useful instructions</p>
</li>
</ul>
</li>
</ul>
<h4 id="disadvantage">Disadvantage</h4>
<ul>
<li>
<p>Not easy to fill the delay slots (even with a 2-stage pipeline)</p>
<ul>
<li>
<p>Number of delay slots increases with pipeline depth, superscalar execution width</p>
</li>
<li>
<p>Number of delay slots should be variable with variable latency operations</p>
</li>
</ul>
</li>
</ul>
<h4 id="another-method-loop-unrolling">Another method-Loop Unrolling</h4>
<ul>
<li>
<p>Replicate body of loop a number of times</p>
<ul>
<li>Iterate loop fewer times</li>
<li>Reduces loop overhead</li>
<li>Increases instruction parallelism</li>
</ul>
</li>
<li>
<p>During the execution of the loop body, because of the locality principle, some data can be used for many times, which can reduce the number of times to access the</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fortran" data-lang="fortran"><span class="line"><span class="cl"><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">	</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">end do</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>原始的循环是要做一个一维数组的变化。循环体中有一个语句需要执行</p>
</li>
<li>
<p>把这个循环体进行拆解，变成了2个语句，一个循环体执行了2个迭代操作</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fortran" data-lang="fortran"><span class="line"><span class="cl"><span class="k">do </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">	</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">	</span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">a</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">end do</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>2个指令可以并行进行。原来每次循环需要访问3次存储器，现在相当于2次循环只需要访问4次存储器，降低了存储器访问的次数</li>
</ul>
<h3 id="risc-versus-cisc-controversy">RISC Versus CISC Controversy</h3>
<ul>
<li>
<p>Not clear cut</p>
<ul>
<li>
<p>RISC designs may benefit from the inclusion of some CISC features and that</p>
</li>
<li>
<p>CISC designs may benefit from the inclusion of some RISC features</p>
</li>
</ul>
</li>
<li>
<p>Many designs borrow from both philosophies</p>
<ul>
<li>
<p>PowerPC are no longer “pure” RISC</p>
</li>
<li>
<p>Pentium II and later Pentium models do incorporate some RISC characteristics</p>
</li>
</ul>
</li>
</ul>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Processor Structure and Function</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-processor-structure-and-function/</link>
    <pubDate>Sat, 28 Jan 2023 14:20:25 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-processor-structure-and-function/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="processor-structure-and-function">Processor Structure and Function</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>Processor Organization</p>
</li>
<li>
<p>Register Organization</p>
</li>
<li>
<p>Instruction Cycle</p>
</li>
<li>
<p>Instruction Pipelining</p>
</li>
</ul>
<h3 id="processor-organization">Processor Organization</h3>
<ul>
<li>
<p>A CPU must be able to</p>
<ul>
<li>
<p>Fetch instruction from memory</p>
</li>
<li>
<p>Decode the instruction to determine what action to do</p>
</li>
<li>
<p>Fetch data</p>
</li>
<li>
<p>Process data</p>
</li>
<li>
<p>Write data</p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-1.png" title="/img/Computer Organization and Architecture/chapter12-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-1.png">
        
    </a>
<ul>
<li>
<p>CPU必须要能够暂时保存一些数据，以对数据进行处理</p>
</li>
<li>
<p>CPU需要记住下一个指令的位置，这样才能在当前指令执行完成之后，能到找到下一个指令</p>
</li>
<li>
<p>处理过程中需要能够保存指令和数据</p>
</li>
<li>
<p><strong>CPU包括ALU，CU，还需要有一组存储部件——寄存器</strong></p>
</li>
<li>
<p>CPU通过一组系统总线和计算机的其他部件进行连接。系统总线包括控制总线、数据总线和地址总线</p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-2.png" title="/img/Computer Organization and Architecture/chapter12-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-2.png">
        
    </a>
<ul>
<li>
<p><strong>CPU的内部总线把ALU、寄存器和CU连在一起，完成数据在寄存器和ALU的传送</strong></p>
</li>
<li>
<p>控制单元对寄存器、内部总线和ALU进行控制，控制各个部件按照指令要求完成相应的处理</p>
</li>
<li>
<p>在ALU内部，还包括各种更小的组件，例如状态标志，移位器，求补器，以及算术和布尔逻辑等</p>
</li>
</ul>
<h3 id="register-organization">Register Organization</h3>
<ul>
<li>
<p>CPU must have some working space (temporary storage)</p>
<ul>
<li>Called registers</li>
</ul>
</li>
<li>
<p>Number and function vary between processor designs</p>
</li>
<li>
<p><strong>One of the major design decisions</strong></p>
</li>
<li>
<p><strong>Top level of memory hierarchy</strong></p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Registers in the CPU Including two types</strong></p>
<ul>
<li>
<p><strong>User-visible registers</strong></p>
</li>
<li>
<p><strong>Reduce access to main memory and improve instruction processing efficiency by optimizing the use of registers</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Control and status registers</strong></p>
<ul>
<li>
<p><strong>Used by control unit</strong></p>
</li>
<li>
<p><strong>Control the operation of the CPU and the execution of the program by the privileged operating system</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="user-visible-registers">User-visible registers</h4>
<ul>
<li>
<p>User visible registers can be divided into four categories according to its purpose</p>
<ul>
<li>
<p><strong>General purpose: assigned to various purposes</strong></p>
</li>
<li>
<p><strong>Data: for data retention only</strong></p>
</li>
<li>
<p><strong>Address: used for some addressing mode</strong></p>
</li>
<li>
<p><strong>Condition codes: also called flag register, it stores some flags of operation results</strong></p>
</li>
</ul>
</li>
</ul>
<h5 id="general-purpose-registers">General purpose registers</h5>
<ul>
<li>
<p>True general purpose</p>
<ul>
<li>Registers and opcodes are orthogonal in the instruction set</li>
<li>Registers can be arbitrarily matched with opcodes</li>
</ul>
</li>
<li>
<p><strong>Restricted general registers</strong></p>
<ul>
<li><strong>Specially used for floating point number or stack operation</strong></li>
</ul>
</li>
<li>
<p>In some cases, general registers can be used for addressing</p>
<ul>
<li>Register indirect addressing</li>
<li>Displacement addressing</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Data register</p>
<ul>
<li><strong>It can only be used for store data, not for addressing</strong></li>
<li><strong>Accumulator</strong></li>
</ul>
</li>
<li>
<p><strong>Addressing register</strong></p>
<ul>
<li>
<p><strong>Used for a specific addressing mode</strong></p>
</li>
<li>
<p><strong>Segment pointer</strong></p>
</li>
<li>
<p><strong>Index register</strong></p>
</li>
<li>
<p><strong>Stack pointer</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>General or Specialized</strong></p>
<ul>
<li>
<p>Whether registers are general or special affects the design of instruction sets</p>
</li>
<li>
<p><strong>Specialized</strong></p>
<ul>
<li>
<p><strong>Opcode can implicitly use a register group or a register</strong></p>
</li>
<li>
<p><strong>Smaller instructions</strong></p>
</li>
<li>
<p><strong>Less flexibility</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>General purpose</strong></p>
<ul>
<li>
<p><strong>Increase flexibility and programmer options</strong></p>
</li>
<li>
<p><strong>Increase instruction size &amp; complexity</strong></p>
</li>
</ul>
</li>
<li>
<p>More registers require more bits to specify registers in instructions</p>
</li>
<li>
<p>Fewer registers require more memory access</p>
</li>
<li>
<p>Too many registers does not reduce memory references remarkably and takes up processor real estate</p>
<ul>
<li>Between 8-32 is appropriate</li>
</ul>
</li>
<li>
<p><strong>Using register files with RISC makes use of using more registers</strong></p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Address register: large enough to hold full address</p>
</li>
<li>
<p>Data address: large enough to hold full word</p>
</li>
<li>
<p><strong>Sometimes combine two data registers to hold double length data</strong></p>
<ul>
<li><strong>In C language, there is a double integer and a long integer, both of which are two words long</strong></li>
</ul>
</li>
</ul>
<hr>
<p><strong>Condition code registers</strong></p>
<ul>
<li>
<p><strong>Also called flag registers, some of which are visible to users</strong></p>
</li>
<li>
<p><strong>After operating,CPU set the condition bit according to the result</strong></p>
<ul>
<li>
<p>After arithmetic operation, positive, negative, zero or overflow may occur</p>
</li>
<li>
<p>These conditions will be set in</p>
</li>
</ul>
</li>
<li>
<p>Programs are allowed to read the condition code and perform</p>
</li>
<li>
<p>Condition code cannot be modified by the program</p>
</li>
</ul>
<hr>
<p><strong>Control &amp; status registers</strong></p>
<ul>
<li>
<p>Four registers are essential to instruction execution</p>
<ul>
<li>
<p>Program Counter (PC)</p>
</li>
<li>
<p>Instruction Register (IR)</p>
</li>
<li>
<p>Memory Address Register (MAR)</p>
</li>
<li>
<p>Memory Buffer Register (MBR)</p>
</li>
</ul>
</li>
<li>
<p>Not all processors have MAR and MBR. However, the system still needs registers similar to these two registers</p>
</li>
</ul>
<hr>
<p><strong>Program status word</strong></p>
<ul>
<li>
<p>The PSW contains status information</p>
</li>
<li>
<p>The flags include</p>
<ul>
<li>
<p>Sign, zero, carry, equal, overflow</p>
</li>
<li>
<p>interrupt enable/disable</p>
</li>
<li>
<p>Supervisor: indicates whether the CPU is executing in supervisor or user mode</p>
</li>
</ul>
</li>
<li>
<p><strong>Supervisor mode</strong></p>
<ul>
<li>
<p>Not available to user programs</p>
</li>
<li>
<p>Used by operating system(<strong>System call</strong>)</p>
</li>
<li>
<p>Certain privileged instructions can be executed only in supervisor mode</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Other status and control registers</strong></p>
<ul>
<li>
<p>Other additional status and control registers</p>
<ul>
<li>
<p>Pointer register to process control block</p>
</li>
<li>
<p>Interrupt vector register in vector interrupt computer</p>
</li>
<li>
<p>System stack pointer</p>
</li>
<li>
<p>Page table pointer register in virtual memory</p>
</li>
<li>
<p>I/O operation related registers</p>
</li>
</ul>
</li>
<li>
<p>Control and status registers design elements</p>
<ul>
<li>Need to support the operating system</li>
<li>Storage location in registers and memory</li>
</ul>
</li>
</ul>
<h3 id="instruction-cycle">Instruction Cycle</h3>
<ul>
<li>
<p><strong>Instruction cycle includes fetching cycle and execution cycle</strong></p>
</li>
<li>
<p><strong>In execution cycle, first decode to get the operation type of the instruction</strong></p>
</li>
<li>
<p><strong>If instruction has operands, get the operand specifier in the instruction</strong></p>
<ul>
<li>
<p><strong>Immediate</strong></p>
</li>
<li>
<p><strong>Register</strong></p>
</li>
<li>
<p><strong>Direct addressing: memory access once</strong></p>
</li>
<li>
<p><strong>Indirect addressing: may requires more memory accesses</strong></p>
<ul>
<li><strong>Also called “indirect cycle”</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Instruction cycle with indirect</strong></p>
<div class="mermaid" id="id-1"></div>
<ul>
<li>
<p>指令周期包括取指周期和执行周期，还可能包括间接周期和中断周期</p>
</li>
<li>
<p>取指后，通过译码确定是否包含需要间接寻址的操作数，如果有，进入间接周期</p>
</li>
<li>
<p>当前指令执行完成之后，检查是否有中断。如果有，进入中断周期</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-3.png" title="/img/Computer Organization and Architecture/chapter12-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-3.png" data-sub-html="<h2>Instruction Cycle(with Interrupts - State Diagram)</h2>">
        
    </a><figcaption class="image-caption">Instruction Cycle(with Interrupts - State Diagram)</figcaption>
    </figure>
<ul>
<li>
<p>指令周期中，先取指，然后进行指令操作译码</p>
</li>
<li>
<p>如果涉及到操作数，进行操作数地址计算，然后取操作数</p>
</li>
<li>
<p>之后进行数据操作。操作结果如果要保存到存储器中，需要计算操作数的地址，然后保存</p>
</li>
<li>
<p>在这条指令执行完成之后，检测是否有中断。如果没有中断，继续执行下一条指令。如果有中断，就按照中断的处理规则，进行中断处理</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-4.png" title="/img/Computer Organization and Architecture/chapter12-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-4.png" data-sub-html="<h2>Indirect cycle</h2>">
        
    </a><figcaption class="image-caption">Indirect cycle</figcaption>
    </figure>
<ul>
<li>
<p>间接寻址过程中，由于操作数地址需要通过计算得到，所以在取操作数的过程中，可能会存在多次访问存储器的情况</p>
</li>
<li>
<p>取操作数和存结果的过程中，都可能会存在间接周期</p>
</li>
</ul>
<hr>
<p><strong>Data flow (instruction fetch)</strong></p>
<ul>
<li>
<p>Depends on CPU design</p>
</li>
<li>
<p>Fetch inn general</p>
<ul>
<li>
<p>PC contains address of next instruction</p>
</li>
<li>
<p>Address moved to MAR</p>
</li>
<li>
<p>Address placed on address bus</p>
</li>
<li>
<p>Control unit requests memory read</p>
</li>
<li>
<p>Result placed on data bus, copied to MBR, then to IR</p>
</li>
<li>
<p>Meanwhile PC incremented by 1</p>
</li>
</ul>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-5.png" title="/img/Computer Organization and Architecture/chapter12-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-5.png" data-sub-html="<h2>Data flow(fetch diagram)</h2>">
        
    </a><figcaption class="image-caption"><code>Data flow(fetch diagram)</code></figcaption>
    </figure>
<ul>
<li>
<p>刚开始，下一个地址在PC中</p>
</li>
<li>
<p>地址给MAR</p>
</li>
<li>
<p>地址放到数据总线上</p>
</li>
<li>
<p>控制单元发起读控制</p>
</li>
<li>
<p>存储器把数据，也就是指令内容，放到数据总线上</p>
</li>
<li>
<p>MBR读取数据总线内容，然后把指令给IR</p>
</li>
<li>
<p>控制单元还需要让PC+1，指向下一个指令</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>IR is examined</p>
</li>
<li>
<p><strong>If there is no indirect addressing, enter the execution cycle</strong></p>
</li>
<li>
<p><strong>If indirect addressing, indirect cycle is performed</strong></p>
<ul>
<li>
<p>Rightmost N bits of MBR transferred to MAR</p>
</li>
<li>
<p>Control unit requests memory read</p>
</li>
<li>
<p>Result (address of operand) moved to MBR</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Data flow (execute)</strong></p>
<ul>
<li>
<p>May take many forms</p>
</li>
<li>
<p>Depends on instruction being executed</p>
</li>
<li>
<p>May include</p>
<ul>
<li>
<p>Memory read/write</p>
</li>
<li>
<p>Input/Output</p>
</li>
<li>
<p>Register transfers</p>
</li>
<li>
<p>ALU operations</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Data flow (interrupt)</strong></p>
<ul>
<li>
<p>Simple and predictable</p>
</li>
<li>
<p><strong>Current PC saved to allow resumption after interrupt</strong></p>
<ul>
<li>
<p>Contents of PC copied to MBR</p>
</li>
<li>
<p>Special memory location (e.g. stack pointer) loaded to MAR</p>
</li>
<li>
<p>MBR written to memory</p>
</li>
</ul>
</li>
<li>
<p><strong>PC loaded with address of interrupt handling routine</strong></p>
</li>
<li>
<p>Interrupt handler first instruction fetched</p>
</li>
</ul>
<h3 id="instruction-pipelining">Instruction Pipelining</h3>
<p><strong>Why need pipeline?</strong></p>
<ul>
<li>
<p>Development of computer application requires continuous improvement of processing capacity</p>
</li>
<li>
<p>The development of integrated circuit, clock frequency, registers, cache, etc. have reduced the instruction processing time and improved the processing ability</p>
</li>
<li>
<p><strong>More and more difficult to solve problems by simply relying on the performance of hardware</strong></p>
</li>
<li>
<p><strong>The goal is the execution efficiency of instructions</strong></p>
</li>
<li>
<p><strong>Better organization is needed to improve the efficiency of instruction execution</strong></p>
</li>
</ul>
<hr>
<p><strong>What is pipeline? ！ ！ ！</strong></p>
<ul>
<li>
<p><strong>The working mode of factory assembly line is used for reference</strong></p>
<ul>
<li>
<p><strong>Divide the execution of instructions into several stages</strong></p>
</li>
<li>
<p><strong>Different stages of multiple instructions can be processed in parallel</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Although execution time of each instruction is not shortened, the execution time of a group of instructions is shortened due to the parallel method</strong></p>
</li>
<li>
<p><strong>This is the basic idea of instruction pipeline</strong></p>
</li>
</ul>
<h4 id="prefetch">Prefetch</h4>
<ul>
<li>
<p>Before pipelining, next instruction is taken after current instruction is executed</p>
</li>
<li>
<p>With pipelining, more than one instruction in different stages of the pipeline</p>
</li>
<li>
<p>How to get instructions is a problem</p>
<ul>
<li>
<p><strong>Fetch accessing main memory</strong></p>
</li>
<li>
<p><strong>Execution usually does not access memory</strong></p>
</li>
<li>
<p><strong>Fetch next instruction during execution of current instruction</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Called instruction prefetch</strong></p>
</li>
</ul>
<hr>
<p><strong>Advantage</strong></p>
<ul>
<li>
<p>During execution of an instruction, a new instruction has entered the pipeline</p>
</li>
<li>
<p><strong>After current instruction is executed, it can be executed immediately</strong></p>
<ul>
<li>
<p>Next instruction has finished fetching</p>
</li>
<li>
<p><strong>Save time for fetching</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Accessing memory is required for fetching</strong></p>
<ul>
<li>
<p>If cache hits, take it directly</p>
</li>
<li>
<p>If cache missing, access memory</p>
</li>
</ul>
</li>
<li>
<p>In fact, the instruction cycle is divided into more detailed stages, more pipeline stages, and more overlapping and efficient instruction execution stages</p>
</li>
</ul>
<hr>
<p><strong>Which instruction is Prefetched?</strong></p>
<ul>
<li>
<p>Which instruction is appropriate for prefetching?</p>
</li>
<li>
<p><strong>Next instruction of the current instruction?</strong></p>
<ul>
<li>
<p><strong>If it is executed sequentially, no problem</strong></p>
</li>
<li>
<p><strong>If there is a transition, the next instruction needs to be determined according to the conditions</strong></p>
</li>
<li>
<p><strong>Hard to predict</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Does a misprediction in prefetching affect correctness?</strong></p>
<ul>
<li>
<p><strong>No, prefetched data at a “mis-predicted” address is simply not used</strong></p>
</li>
<li>
<p><strong>There is no need for state recovery</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Basics characteristics</strong></p>
<ul>
<li>
<p>In modern systems, prefetching is usually done in cache block granularity</p>
</li>
<li>
<p>Prefetching is a technique that can reduce both</p>
<ul>
<li>
<p>Miss rate</p>
</li>
<li>
<p>Miss latency</p>
</li>
</ul>
</li>
<li>
<p><strong>Prefetching can be done by</strong></p>
<ul>
<li><strong>Hardware</strong></li>
<li><strong>Compiler</strong></li>
<li><strong>Programmer</strong></li>
</ul>
</li>
</ul>
<h4 id="prefetching-the-four-questions">Prefetching: the four questions</h4>
<ul>
<li>
<p>What</p>
<ul>
<li>What addresses to prefetch</li>
</ul>
</li>
<li>
<p>When</p>
<ul>
<li>When to initiate a prefetch request</li>
</ul>
</li>
<li>
<p>Where</p>
<ul>
<li>Where to place the prefetched data</li>
</ul>
</li>
<li>
<p>How</p>
<ul>
<li>Software, hardware, execution-based, cooperative</li>
</ul>
</li>
</ul>
<h4 id="two-stage-instruction-pipeline">Two stage instruction pipeline</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-6.png" title="/img/Computer Organization and Architecture/chapter12-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-6.png">
        
    </a>
<ul>
<li>
<p>简单的指令过程就是串行处理，取指-执行-取指-执行，效率低</p>
</li>
<li>
<p>采用两阶段流水线后，在当前指令的执行过程中，进行下一个指令的取指</p>
</li>
<li>
<p>如果当前指令执行完成后，下一个指令不是预取的，需要重新取指</p>
</li>
<li>
<p>取指和执行指令的时间重叠，节省了时间</p>
</li>
<li>
<p>但是由于取指和执行指令的时间需要不一样，所以执行速度不能翻倍</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-7.png" title="/img/Computer Organization and Architecture/chapter12-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-7.png" data-sub-html="<h2>Instruction pipelining</h2>">
        
    </a><figcaption class="image-caption"><code>Instruction pipelining</code></figcaption>
    </figure>
<ul>
<li>
<p>两阶段流水线的执行过程</p>
</li>
<li>
<p><strong>上一条指令的执行阶段和下一条指令的取指阶段在时间上是重叠的</strong></p>
</li>
<li>
<p>每个指令的总体执行时间没有缩短，部指令的执行时间缩短了</p>
</li>
<li>
<p>如果取指和执行时间相同，那么流水线的执行时间是串行执行的一半，性能提升一倍</p>
</li>
</ul>
<h4 id="improved-performance">Improved performance</h4>
<ul>
<li>
<p><strong>But not doubled</strong></p>
<ul>
<li>
<p><strong>Fetch usually shorter than execution</strong></p>
</li>
<li>
<p>Instruction execution process is complex and time-consuming</p>
</li>
<li>
<p><strong>Execution time determines the improvement effect</strong></p>
</li>
</ul>
</li>
<li>
<p>Jump or branch instruction</p>
<ul>
<li>
<p><strong>means that prefetched instructions are not the required instructions</strong></p>
</li>
<li>
<p><strong>Get the actual instructions according to the results</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Add more stages to improve performance</strong></p>
</li>
</ul>
<h4 id="improve-concurrency">improve concurrency</h4>
<ul>
<li>
<p>Goal: More concurrency → Higher instruction throughput</p>
</li>
<li>
<p><strong>Method: When an instruction is using some resources in its processing phase, process other instructions on idle resources</strong></p>
<ul>
<li>
<p>Fetch next instruction when an instruction is being decoded</p>
</li>
<li>
<p>Decode an instruction when an instruction is being executed</p>
</li>
<li>
<p>Execute the next instruction when current instruction is accessing memory</p>
</li>
<li>
<p>When an instruction is writing its result into the register file, access data memory for the next instruction</p>
</li>
</ul>
</li>
</ul>
<h4 id="summary">Summary</h4>
<ul>
<li>
<p>Analogy: “Assembly line processing” of instructions</p>
</li>
<li>
<p>Pipeline the execution of multiple instructions</p>
<ul>
<li>
<p><strong>Divide the instruction processing cycle into distinct “stages” of processing</strong></p>
</li>
<li>
<p>Ensure there are enough hardware resources to process one instruction in each stage</p>
</li>
<li>
<p>Process a different instruction in each stage</p>
</li>
<li>
<p>Instructions are executed in the order of program</p>
</li>
</ul>
</li>
<li>
<p><strong>Benefit: Increases instruction processing throughput</strong></p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-8.png" title="/img/Computer Organization and Architecture/chapter12-8.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-8.png" data-sub-html="<h2>execution of four independent add</h2>">
        
    </a><figcaption class="image-caption">execution of four independent add</figcaption>
    </figure>
<ul>
<li>
<p>加法指令流水线</p>
</li>
<li>
<p>整个指令分为4个阶段：取指，译码，执行，写结果，均为t</p>
</li>
<li>
<p>采用4阶段流水线，每个阶段完全独立，n个指令，需要$nt+3t$的时间</p>
</li>
<li>
<p>基本上是$\frac {1}{4}$的时间</p>
</li>
</ul>
<h4 id="in-practice">In practice</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-9.png" title="/img/Computer Organization and Architecture/chapter12-9.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-9.png">
        
    </a>
<ul>
<li>
<p>烘干衣服需要2个时间单位，这样，如果完全串行，需要20个时间单位</p>
</li>
<li>
<p>采用流水线后，有等待烘干机的时间</p>
</li>
<li>
<p>4件衣服需要11个时间单位</p>
</li>
<li>
<p>理论上的速度为非流水线的$2.5$倍</p>
</li>
<li>
<p><strong>最慢的步骤决定了整个系统的吞吐量</strong></p>
</li>
</ul>
<h5 id="how">How</h5>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-10.png" title="/img/Computer Organization and Architecture/chapter12-10.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-10.png">
        
    </a>
<ul>
<li>
<p>烘干机成为整个系统的瓶颈</p>
</li>
<li>
<p>补充资源，配置2个烘干机</p>
</li>
<li>
<p>下一个衣服洗完后，不需要等待上一个衣服的烘干，用另一台烘干机</p>
</li>
<li>
<p>关键环节增加资源，使得整个吞吐量回到之前的情况</p>
</li>
<li>
<p>代价就是配置额外的资源</p>
</li>
</ul>
<h4 id="goal">Goal</h4>
<ul>
<li>
<p>Increase instruction throughput with little increase in cost</p>
<ul>
<li>
<p><strong>Process instructions in the order required by the program</strong></p>
</li>
<li>
<p><strong>Hardware cost cannot be increased too much</strong></p>
</li>
<li>
<p>Instruction throughput can be greatly increased</p>
</li>
</ul>
</li>
</ul>
<h4 id="an-ideal-pipeline">An ideal pipeline</h4>
<ul>
<li>
<p><strong>Repetition of identical operations</strong></p>
<ul>
<li>
<p><strong>Same operation, different operation objects</strong></p>
</li>
<li>
<p>Automobiles of the same model can be produced on one assembly line</p>
</li>
<li>
<p><strong>Different operations require different steps, which affects the operation of the pipeline</strong></p>
</li>
<li>
<p>The production of automobiles and motorcycles requires different steps and cannot be put on the same assembly line</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Operating objects are independent of each other</strong></p>
<ul>
<li>
<p><strong>There is no dependency between each operation object</strong></p>
</li>
<li>
<p>For example, there is no relationship between cars produced on the assembly line</p>
</li>
<li>
<p><strong>Operating objects with sequential dependencies affect each other during parallel operations</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>A complete operation can be decomposed into several sub operations</p>
<ul>
<li>
<p><strong>Each sub operation takes the same time</strong></p>
</li>
<li>
<p><strong>Each sub operation requires independent resources and does not share resources</strong></p>
</li>
<li>
<p>If sub operation requires different time, some sub operations must wait</p>
</li>
<li>
<p>Resource sharing leads to resource contention</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>For the pipeline design of instructions, we divide the execution of instructions into six stages</p>
<ul>
<li>
<p><strong>Fetch instruction(FI)</strong></p>
</li>
<li>
<p><strong>Decode instruction(DI)</strong></p>
</li>
<li>
<p><strong>Calculate operands(CO)</strong></p>
</li>
<li>
<p><strong>Fetch operands(FO)</strong></p>
</li>
<li>
<p><strong>Execute instructions(EI)</strong></p>
</li>
<li>
<p><strong>Write result(WO)</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Overlap these operations</strong></p>
</li>
</ul>
<h4 id="timing-of-pipeline">Timing of pipeline</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-11.png" title="/img/Computer Organization and Architecture/chapter12-11.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-11.png">
        
    </a>
<ul>
<li>
<p>理想的指令流水线的执行过程</p>
</li>
<li>
<p><strong>指令执行分为6个阶段，相互之间不共享资源</strong></p>
</li>
<li>
<p>按照流水线的方式来执行，从第六个时间单位开始，每个时间单位都会有1个指令完成执行</p>
</li>
<li>
<p>指令数量足够多时，执行效率为原来的6倍</p>
</li>
</ul>
<h4 id="summary-1">Summary</h4>
<ul>
<li>
<p>The total execution time for each individual instruction is not changed by pipelining</p>
<ul>
<li>It still takes an instruction cycle to make it all the way through the processor</li>
</ul>
</li>
<li>
<p>Pipelining doesn&rsquo;t speed up instruction execution time</p>
</li>
<li>
<p>It does speed up program execution time by increasing the number of instructions finished per unit time</p>
</li>
</ul>
<h4 id="branch-in-a-pipeline">Branch in a pipeline</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-12.png" title="/img/Computer Organization and Architecture/chapter12-12.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-12.png">
        
    </a>
<ul>
<li>
<p>指令1和2的执行都是正常的</p>
</li>
<li>
<p>指令3在时间片8时，需要跳转到指令15的执行</p>
</li>
<li>
<p>指令4-7已经完成的处理作废</p>
</li>
<li>
<p>需要重新开始指令15的取指</p>
</li>
<li>
<p><strong>第9到第12时间片，没有指令完成执行，称为分支惩罚</strong></p>
</li>
<li>
<p><strong>分支越多，分支惩罚就越多，整个程序的指令吞吐率就越低</strong></p>
</li>
</ul>
<hr>
<p><strong>Six stage instruction pipeline</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-13.png" title="/img/Computer Organization and Architecture/chapter12-13.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-13.png">
        
    </a>
<ul>
<li>
<p>第一步是取指，之后是指令译码，并计算操作数地址</p>
</li>
<li>
<p><strong>此时，需要判断指令是否是无条件转移，如果是，那么更新PC，并清空流水线，继续开始取指</strong></p>
</li>
<li>
<p><strong>如果不转移，正常执行指令，取操作数，然后执行指令，并写操作数</strong></p>
</li>
<li>
<p><strong>判断是否进行分支，或者是否有中断。如果是，那么和无条件分支一样，更改PC，清空流水线，继续往下执行后续指令</strong></p>
</li>
</ul>
<h4 id="other-factors">Other factors</h4>
<ul>
<li>
<p>Data transmission between different parts takes time</p>
</li>
<li>
<p>Theoretically, the more stages, the higher the efficiency of instruction execution</p>
<ul>
<li>
<p>The more stages are divided, the more complex the control between stages will be</p>
</li>
<li>
<p><strong>Latching delay, buffering between phases takes a certain time</strong></p>
</li>
<li>
<p>Need reasonable design</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Speedup factors with instruction pipelining</strong></p>
<ul>
<li>假定总共需要执行n条指令，采用的流水线段数为k，那么使用指令流水线相对于不使用流水线的加速比的定义是</li>
</ul>
<p>$$
S_k=\frac {nk}{k+n-1}
$$</p>
<ul>
<li>
<p>随着指令数的增加，加速比趋向于流水线的阶段</p>
</li>
<li>
<p>指令数越多，加速比越接近理论上的加速比。而随着段数的增加，加速比增加缓慢</p>
</li>
<li>
<p>流水线段数能带来更好的潜在加速比，但同时也带来很多问题。比如分支时需要清空流水线，段间延时也需要考虑</p>
</li>
</ul>
<h4 id="analysis-of-instruction-pipeline">Analysis of instruction pipeline</h4>
<ul>
<li>What are the characteristics of an ideal pipeline?
<ul>
<li>
<p>Repetition of identical operations</p>
</li>
<li>
<p>Operating objects are independent of each other</p>
</li>
<li>
<p>A complete operation can be decomposed into several sub operations</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Identical operations … NOT!</strong></p>
<ul>
<li>
<p><strong>different instructions → not all need the same stages</strong></p>
</li>
<li>
<p>Forcing different instructions to go through the same pipe stages</p>
</li>
<li>
<p><strong>Some pipeline stages are idle</strong></p>
</li>
<li>
<p><strong>Leading to a waste of time, called external fragmentation</strong></p>
</li>
</ul>
<hr>
<p><strong>Independent operations &hellip; NOT!</strong></p>
<ul>
<li>
<p><strong>instructions are not independent of each other</strong></p>
</li>
<li>
<p>Need to detect and resolve inter-instruction dependencies to ensure the pipeline provides correct results</p>
</li>
<li>
<p>Pipeline stalls frequently due to branch</p>
</li>
<li>
<p>Poor operation of the pipeline</p>
</li>
</ul>
<hr>
<p><strong>Uniform sub-operations &hellip; NOT!</strong></p>
<ul>
<li>
<p><strong>different pipeline stages → not the same latency</strong></p>
</li>
<li>
<p>Need to force each stage to be controlled by the same clock</p>
</li>
<li>
<p><strong>Some pipe stages are too fast but all take the same clock cycle time</strong></p>
</li>
<li>
<p><strong>These wasted time are called internal fragmentation</strong></p>
</li>
</ul>
<hr>
<h4 id="issues-in-pipeline-design">Issues in pipeline design</h4>
<ul>
<li>
<p>Reasonably divide the stages of instructions</p>
<ul>
<li>
<p><strong>How many stages is the instruction cycle divided into?</strong></p>
</li>
<li>
<p>what is done in each stage</p>
</li>
</ul>
</li>
<li>
<p>Handling exceptions, interrupts</p>
</li>
<li>
<p>Keeping the pipeline correct, moving, and full</p>
<ul>
<li>
<p>Data dependences</p>
</li>
<li>
<p>Control dependences</p>
</li>
<li>
<p>Resource conflict</p>
</li>
<li>
<p>Long-latency (or multi-cycle) operations</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Causes of pipeline stalls</strong></p>
<ul>
<li>
<p><strong>Pipeline stall: A condition when the pipeline stops moving</strong></p>
</li>
<li>
<p>Causes of stall</p>
<ul>
<li>Resource contention</li>
<li>Dependences between instructions, including data dependence and control dependence</li>
<li>Long-latency (multi-cycle) operations</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Dependences and Their Types</strong></p>
<ul>
<li>
<p>Also called “hazard” or “pipeline bubble”</p>
</li>
<li>
<p>Dependences dictate ordering requirements between instructions</p>
</li>
<li>
<p>Two types</p>
<ul>
<li>
<p>Data dependence</p>
</li>
<li>
<p>Control dependence</p>
</li>
</ul>
</li>
<li>
<p><strong>Resource contention is sometimes called resource dependence</strong></p>
</li>
<li>
<p><strong>When dependency occurs, the pipeline will be suspended, which is called pipeline adventure</strong></p>
</li>
</ul>
<h4 id="resource-hazards">Resource hazards</h4>
<ul>
<li>
<p><strong>Two (or more) instructions in pipeline need same resource</strong></p>
<ul>
<li>
<p><strong>Executed in serial rather than parallel for part of pipeline</strong></p>
</li>
<li>
<p><strong>Also called <em>structural hazard</em></strong></p>
</li>
</ul>
</li>
<li>
<p>It is caused by unreasonable structure or insufficient resources</p>
<ul>
<li>Such as using the same register</li>
</ul>
</li>
<li>
<p><strong>The solution is generally to increase available resources, such as adding a dryer in the previous example</strong></p>
</li>
</ul>
<p><strong>Example</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-14.png" title="/img/Computer Organization and Architecture/chapter12-14.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-14.png">
        
    </a>
<ul>
<li>
<p>第3个时钟周期，$I_1$需要读取内存取操作数，同时$I_3$也需要取指</p>
</li>
<li>
<p>两个指令读需要读存储器，发生资源冲突</p>
</li>
<li>
<p>$I_3$需要空一个时钟周期，等到第4个时钟周期的时候，才去取指</p>
</li>
<li>
<p>因为资源冲突而浪费了1个时钟周期</p>
</li>
<li>
<p>如果只有一个$ALU$，执行指令也可能会冲突</p>
</li>
</ul>
<h4 id="handling-resource-contention">Handling resource contention</h4>
<ul>
<li>
<p><strong>Solution 1: Eliminate the cause of contention</strong></p>
<ul>
<li>
<p>Duplicate the resource or increase its throughput</p>
</li>
<li>
<p>E.g., use separate instruction and data memories (caches)</p>
</li>
<li>
<p>E.g., use multiple ports for memory structures</p>
</li>
</ul>
</li>
<li>
<p><strong>Solution 2: Detect the resource contention and stall one</strong></p>
<ul>
<li>Need to decide which one to stop</li>
</ul>
</li>
</ul>
<h4 id="data-hazards">Data hazards</h4>
<ul>
<li>
<p>Conflict in access of an operand</p>
<ul>
<li>E.g. ,both instructions access a particular memory or register operand</li>
</ul>
</li>
<li>
<p><strong>If two instructions are executed serially in strict order, that is one instruction executes after the finish of the previous instruction execution. No problem</strong></p>
</li>
<li>
<p><strong>If in a pipeline, operand value could be updated so as to produce different result from strict sequential execution</strong></p>
</li>
<li>
<p><strong>Data Hazard is caused by the conflict of access to the same operand location</strong></p>
</li>
</ul>
<hr>
<h4 id="types-of-data-hazard">Types of data hazard</h4>
<ul>
<li>
<p>Types of data dependences：</p>
<ul>
<li>
<p><strong>read after write</strong></p>
<ul>
<li><strong>Called “True dependence ”</strong></li>
</ul>
</li>
<li>
<p><strong>write after read</strong></p>
<ul>
<li><strong>Called “Anti dependence ”</strong></li>
</ul>
</li>
<li>
<p><strong>write after write</strong></p>
<ul>
<li><strong>Called “Output dependence”</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="true-dependency">True dependency</h5>
<ul>
<li>
<p><strong>Read after write (RAW), or true dependency</strong></p>
<ul>
<li>
<p><strong>An instruction modifies a register or memory location</strong></p>
</li>
<li>
<p><strong>Succeeding instruction reads data in that location</strong></p>
</li>
<li>
<p><strong>Hazard occurs if read takes place before write complete</strong></p>
</li>
<li>
<p><strong>What needs to be read by succeeding instruction is the modified data</strong></p>
</li>
<li>
<p><strong>After the pipeline is adopted, the read data becomes the data before writing</strong></p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-15.png" title="/img/Computer Organization and Architecture/chapter12-15.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-15.png">
        
    </a>
<ul>
<li>
<p>第一个指令需要写$r_3$</p>
</li>
<li>
<p>第二个指令需要读$r_3$</p>
</li>
<li>
<p>第二个指令<strong>必须要等第一个指令执行完成之后并写了</strong>$r_3$，才能完成读操作数的指令，否则读取的$r_3$不是需要的数</p>
</li>
</ul>
<h5 id="anti-dependence">Anti dependence</h5>
<ul>
<li>
<p><strong>Write after read (WAR), or anti-dependency</strong></p>
</li>
<li>
<p><strong>An instruction reads a register or memory location</strong></p>
</li>
<li>
<p><strong>Succeeding instruction writes to location</strong></p>
</li>
<li>
<p><strong>Hazard occur if write completes before read takes place</strong></p>
</li>
<li>
<p><strong>The data of the first instruction read operation is incorrect</strong></p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-16.png" title="/img/Computer Organization and Architecture/chapter12-16.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-16.png">
        
    </a>
<ul>
<li>
<p>第一个指令读$r_1$</p>
</li>
<li>
<p>第二个指令写$r_1$</p>
</li>
<li>
<p>如果先执行了第二个指令，那么结果也不正确</p>
</li>
<li>
<p>在超标量中会出现这种情况</p>
</li>
</ul>
<h5 id="output-dependence">Output dependence</h5>
<ul>
<li>
<p><strong>Write after write (WAW), or output dependency</strong></p>
<ul>
<li>
<p><strong>Two instructions both write to same location</strong></p>
</li>
<li>
<p><strong>Hazard if writes take place in reverse of order intended sequence</strong></p>
</li>
<li>
<p><strong>The data to be stored is the data written by the second instruction</strong></p>
</li>
<li>
<p><strong>In the pipeline, the data actually saved is the data written by the first instruction</strong></p>
</li>
<li>
<p><strong>Data of memory or register is not required</strong></p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-17.png" title="/img/Computer Organization and Architecture/chapter12-17.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-17.png">
        
    </a>
<ul>
<li>
<p>第一个执行写$r_3$</p>
</li>
<li>
<p>第三个指令也写$r_3$</p>
</li>
<li>
<p>如果第三个指令先执行了，也结果不正确</p>
</li>
<li>
<p>在超标量中会出现这种情况</p>
</li>
</ul>
<h4 id="how-1">How?</h4>
<ul>
<li>
<p>True dependences always need to be obeyed because they constitute true dependence on a value</p>
</li>
<li>
<p><strong>True dependences always need to be obeyed because they constitute true dependence on a value</strong></p>
</li>
<li>
<p><strong>Anti and output dependences exist due to limited number of architectural registers</strong></p>
<ul>
<li><strong>They are dependence on a name, not a value</strong></li>
</ul>
</li>
<li>
<p><strong>Without special hardware and specific avoidance algorithms, results in inefficient pipeline usage</strong></p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-18.png" title="/img/Computer Organization and Architecture/chapter12-18.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-18.png" data-sub-html="<h2>Data hazard diagram</h2>">
        
    </a><figcaption class="image-caption"><code>Data hazard diagram</code></figcaption>
    </figure>
<ul>
<li>
<p>在第五个时钟周期，加法指令写EAX</p>
</li>
<li>
<p>第四个时钟周期，减法要用EAX</p>
</li>
<li>
<p>如果第二个指令不等待，那取的EAX还是最早的EAX，不是加法的结果</p>
</li>
<li>
<p>所以减法指令需要停顿2个时钟周期，到第六个时钟周期才会去取操作数</p>
</li>
<li>
<p>浪费了2个时钟周期</p>
</li>
</ul>
<h4 id="method-of-handle">Method of handle</h4>
<ul>
<li>
<p>True dependences are more interesting</p>
<ul>
<li><strong>Actual interdependence between data，requires waiting</strong></li>
</ul>
</li>
<li>
<p><strong>Anti and output dependences are easier to handle</strong></p>
<ul>
<li>
<p><strong>It’s all about writing</strong></p>
</li>
<li>
<p><strong>Use more registers</strong></p>
</li>
<li>
<p><strong>Use different registers to eliminate possible correlation</strong></p>
</li>
</ul>
</li>
<li>
<p>Some fundamental ways of handling true dependences</p>
<ul>
<li>
<p>Detect and wait until value is available in register file</p>
</li>
<li>
<p>Detect and eliminate the dependence at the software level</p>
<ul>
<li>
<p>Register renaming</p>
</li>
<li>
<p>Discussed later</p>
</li>
</ul>
</li>
<li>
<p>Predict the needed value(s), execute “speculatively”, and verify</p>
</li>
</ul>
</li>
</ul>
<h4 id="control-dependence">Control dependence</h4>
<ul>
<li>
<p>Also called “control hazard”“branch hazard”</p>
</li>
<li>
<p>A Special Case of Data Dependence</p>
</li>
<li>
<p>Occurs when the pipeline makes a wrong judgment on branch transfer</p>
</li>
<li>
<p>Brings instructions into pipeline that must subsequently be discarded</p>
</li>
<li>
<p>The pipeline cannot run with full load</p>
</li>
</ul>
<h5 id="solve">solve</h5>
<ul>
<li>
<p><strong>Multiple Streams</strong></p>
</li>
<li>
<p><strong>Prefetch Branch Target</strong></p>
</li>
<li>
<p><strong>Loop buffer</strong></p>
</li>
<li>
<p><strong>Branch prediction</strong></p>
</li>
<li>
<p><strong>Delayed branching</strong></p>
</li>
</ul>
<h6 id="multiple-streams">Multiple streams</h6>
<ul>
<li>
<p>Have two pipelines for each branch</p>
<ul>
<li>Prefetch each branch into a separate pipeline</li>
</ul>
</li>
<li>
<p>Finally, determine which pipeline to use according to the branching conditions</p>
</li>
<li>
<p>Shortcoming</p>
<ul>
<li>
<p>Leads to bus &amp; register contention</p>
</li>
<li>
<p>Multiple branches lead to further pipelines being needed</p>
</li>
</ul>
</li>
</ul>
<h6 id="prefetch-branch-target">Prefetch branch target</h6>
<ul>
<li>Target of branch is prefetched in addition to instructions following branch</li>
<li>It is not executed after prefetching, but fetching and decoding</li>
<li>Keep target until branch is executed</li>
<li>It can save the time of fetching and decoding</li>
<li>Used by IBM 360/91</li>
</ul>
<h6 id="loop-buffer">Loop buffer</h6>
<ul>
<li>
<p>Very fast memory</p>
</li>
<li>
<p>Contains n instructions taken in the most recent order</p>
</li>
<li>
<p>When a branch may occur, first check whether the transfer target is in the buffer</p>
</li>
<li>
<p><strong>Very good for small loops or jumps</strong></p>
</li>
</ul>
<h6 id="branch-prediction">Branch prediction</h6>
<ul>
<li>
<p>There are two types of branch predictions</p>
<ul>
<li>
<p>Static branch predictions: the branch does not depend on the execution history</p>
</li>
<li>
<p>Dynamic branch prediction: the branch depends on the execution history</p>
</li>
</ul>
</li>
<li>
<p>Static branching</p>
<ul>
<li>
<p>Predict never taken</p>
</li>
<li>
<p>Predict always taken</p>
</li>
<li>
<p>Predict by Opcode</p>
</li>
</ul>
</li>
<li>
<p>Dynamic branching</p>
<ul>
<li>
<p>Taken/not taken switch</p>
</li>
<li>
<p>Branch history table</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Static branch prediction</strong></p>
<ul>
<li>
<p><strong>Predict never taken</strong></p>
<ul>
<li>
<p><strong>Assume that jump will not happen</strong></p>
</li>
<li>
<p><strong>Always fetch next instruction</strong></p>
</li>
<li>
<p><strong>68020 &amp; VAX 11/780</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Predict always taken</strong></p>
<ul>
<li>
<p><strong>Assume that jump will happen</strong></p>
</li>
<li>
<p><strong>Always fetch target instruction</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>“Predict always taken ” are most used</strong></p>
</li>
<li>
<p>Predict by Opcode</p>
<ul>
<li>
<p>Some instructions are more likely to result in a jump than others</p>
</li>
<li>
<p>Can get up to 75% success</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Dynamic branch prediction</strong></p>
<ul>
<li>
<p><strong>Record the history of conditional branch instructions in a program</strong></p>
</li>
<li>
<p>Taken/not taken switch: One or more bits are used to indicate recent history of the instruction</p>
<ul>
<li>
<p><strong>The branching decision is depended on these bits</strong></p>
</li>
<li>
<p><strong>Based on previous history</strong></p>
</li>
<li>
<p><strong>Good for loops</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Branch history table</strong></p>
<ul>
<li>
<p>If Predict branch，target address can only be obtained by decoding instructions</p>
<ul>
<li>
<p>A waiting time is required</p>
</li>
<li>
<p>How to improve efficiency?</p>
</li>
</ul>
</li>
<li>
<p>A storage area called branch target buffer is designed</p>
<ul>
<li>
<p>Also called branch history table</p>
</li>
<li>
<p>It records information related to branch transfer, including branch instruction address, transfer history bit, and target address information</p>
</li>
</ul>
</li>
<li>
<p>Target address information</p>
<ul>
<li>
<p>Can be target instruction</p>
<ul>
<li>
<p>Use this instruction directly</p>
</li>
<li>
<p>Less time</p>
</li>
<li>
<p>It will take up more space</p>
</li>
</ul>
</li>
<li>
<p>Can be the target instruction address</p>
<ul>
<li>
<p>Less space</p>
</li>
<li>
<p>More time</p>
</li>
</ul>
</li>
<li>
<p>Whether to save time or space depends on the specific situation</p>
</li>
</ul>
</li>
</ul>
<h4 id="branch-history-table">Branch history table</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter12-19.png" title="/img/Computer Organization and Architecture/chapter12-19.png" data-thumbnail="/img/Computer Organization and Architecture/chapter12-19.png">
        
    </a>
<ul>
<li>
<p>预测转移后，指令预取的时候，先去转移历史表中查询</p>
<ul>
<li>
<p>如果有的话，根据指令状态进行预测，可能是目标地址，或者是下一顺序地址</p>
</li>
<li>
<p>如果不匹配，顺序取下一个指令</p>
</li>
</ul>
</li>
<li>
<p>分支指令执行时，根据实际是否发生了转移，更新转移历史表中的状态位</p>
</li>
<li>
<p>如果条件分支指令不在表中的时候，需要把指令加到这个表中，同时需要替换到当前表中的一项。替换方法可以采用很多种方法，<strong>类似于cache的替换策略</strong></p>
</li>
<li>
<p>转移历史表动态自动维护</p>
</li>
</ul>
<hr>
<p><strong>Correlation-based prediction</strong></p>
<ul>
<li>
<p>The execution effect of the branch history table in the loop statement is good</p>
</li>
<li>
<p>In more complex structures, branch instruction directly correlates with that of related branches instruction</p>
</li>
<li>
<p><strong>A method called Correlation-based branch history is proposed</strong></p>
<ul>
<li><strong>Create a global branch history table</strong></li>
<li><strong>Predict by combining global and current branch instructions</strong></li>
</ul>
</li>
</ul>
<hr>
<p><strong>Delayed Branch</strong></p>
<ul>
<li>
<p>A method of instruction rearrangement</p>
</li>
<li>
<p><strong>Delayed branches need to calculate the impact of branches and determine which instructions are not affected before prefetching unwanted instructions</strong></p>
<ul>
<li>
<p><strong>Execute such an instruction immediately after the branch instruction</strong></p>
</li>
<li>
<p><strong>The execution of this instruction keeps the pipeline in a full rotation state, and the clock cycle will not be wasted due to waiting</strong></p>
</li>
</ul>
</li>
</ul>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Instruction Sets Addressing Modes and Formats</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-instruction-sets-addressing-modes-and-formats/</link>
    <pubDate>Thu, 26 Jan 2023 16:30:34 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-instruction-sets-addressing-modes-and-formats/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="instruction-sets-addressing-modes-and-formats">Instruction Sets: Addressing Modes and Formats</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>Addressing</p>
</li>
<li>
<p><code>x86</code> and <code>ARM</code> addressing modes</p>
</li>
<li>
<p>Instruction Formats</p>
</li>
<li>
<p><code>x86</code> and <code>ARM</code> instruction formats</p>
</li>
</ul>
<h3 id="addressing">Addressing</h3>
<h4 id="what-is-addressing-mode">What is addressing mode?</h4>
<ul>
<li>
<p><strong>Elements in the instruction include: opcode, source operand, destination operand, and next instruction address</strong></p>
</li>
<li>
<p>Possible positions of operands</p>
<ul>
<li>
<p>Memory</p>
</li>
<li>
<p>Register</p>
</li>
<li>
<p>Immediate</p>
</li>
<li>
<p>I/O</p>
</li>
</ul>
</li>
<li>
<p><strong>Addressing mode specifies how to obtain an operand of an instruction</strong></p>
</li>
<li>
<p>Addressing is relatively simple when the operand is in a register or immediate</p>
</li>
<li>
<p>If the operand is in memory</p>
<ul>
<li>
<p>The address field of an operand in an instruction cannot be too long</p>
</li>
<li>
<p>Want to access a large memory space</p>
</li>
</ul>
</li>
<li>
<p>Memory addressing adopts multiple addressing modes</p>
<ul>
<li><strong>Balance</strong> the addressable address range, addressing flexibility, addressing complexity and the number of storage units occupied</li>
</ul>
</li>
</ul>
<h4 id="memory-addressing">Memory addressing</h4>
<ul>
<li>
<p>Absolute</p>
</li>
<li>
<p>Displacement</p>
</li>
<li>
<p>Indexed</p>
</li>
<li>
<p>register indirect</p>
</li>
<li>
<p>memory indirect</p>
</li>
<li>
<p>Autoincrement</p>
</li>
<li>
<p>Autodecrement</p>
</li>
</ul>
<hr>
<p><strong>Advantage</strong></p>
<ul>
<li>
<p>Expanding addressable address space</p>
</li>
<li>
<p>Improved addressing flexibility</p>
</li>
<li>
<p>Provide better program architecture to help programmers design more flexible programs</p>
<ul>
<li>For example, array, pointer based access, etc</li>
</ul>
</li>
</ul>
<h4 id="common-addressing-mode">Common addressing mode</h4>
<ul>
<li>
<p>Immediate</p>
</li>
<li>
<p>Direct</p>
</li>
<li>
<p>Indirect</p>
</li>
<li>
<p>Register</p>
</li>
<li>
<p>Register Indirect</p>
</li>
<li>
<p>Displacement (Indexed)</p>
</li>
<li>
<p>Stack</p>
</li>
</ul>
<h5 id="immediate-addressing">Immediate addressing</h5>
<ul>
<li>
<p>Operand is part of instruction</p>
<ul>
<li><strong>Operand = address field</strong></li>
</ul>
</li>
<li>
<p>e.g.</p>
<ul>
<li>
<p>ADD 5</p>
</li>
<li>
<p>Add 5 to contents of accumulator</p>
</li>
<li>
<p>5 is operand</p>
</li>
</ul>
</li>
<li>
<p><strong>No memory reference to fetch data</strong></p>
<ul>
<li>
<p><strong>Fast</strong></p>
</li>
<li>
<p><strong>Limited range: length of the address field in the instruction is limited</strong></p>
</li>
<li>
<p><strong>Inflexible</strong></p>
</li>
</ul>
</li>
</ul>
<div class="mermaid" id="id-1"></div>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">MOV BL,10
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>指令中包含了操作码和立即数</strong></p>
</li>
<li>
<p><strong>复杂一点的指令中，操作数包括立即数，以及其他寻址方式</strong></p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">MOV BL,10
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>这个指令把10这个立即数送到BL寄存器中</strong></p>
</li>
<li>
<p><strong>立即数寻址在很多指令中都会用到，但是受到的限制比较大</strong></p>
</li>
</ul>
<h5 id="direct-addressing">Direct addressing</h5>
<ul>
<li>
<p><strong>Address field contains address of operand</strong></p>
</li>
<li>
<p>Effective address (EA) = address field (A)</p>
<ul>
<li>
<p><strong>Single memory reference to access data</strong></p>
</li>
<li>
<p><strong>No additional calculations to work out effective address</strong></p>
</li>
<li>
<p><strong>Limited address space</strong></p>
</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">ADD A
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>Add contents of cell A to accumulator</p>
</li>
<li>
<p>Look in memory at address A for operand</p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-1.png" title="/img/Computer Organization and Architecture/chapter11-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-1.png">
        
    </a>
<ul>
<li>
<p>指令中给出了操作数在主存储器中的地址</p>
</li>
<li>
<p>通过一次存储器访问，就可以得到操作数</p>
</li>
<li>
<p>操作数的地址直接在指令中。指令的长度有限，能留给直接寻址的地址域的长度有限，导致寻址空间有限</p>
</li>
</ul>
<h5 id="indirect-addressing">Indirect addressing</h5>
<ul>
<li>
<p>Memory cell pointed to by address field contains the address of (pointer to) the operand</p>
</li>
<li>
<p>EA = (A)</p>
<ul>
<li>
<p><strong>Access the storage unit with address A to obtain the actual address of the operand</strong></p>
</li>
<li>
<p><strong>Access the memory according to this address to get the operand</strong></p>
</li>
<li>
<p>Memory needs to be accessed twice</p>
</li>
</ul>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">ADD (A)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>Add contents of cell pointed to by contents of A to accumulator</strong></p>
</li>
<li>
<p>Large address space</p>
<ul>
<li>$2^n\ where\ \rightarrow n=word\ length\newline$</li>
</ul>
</li>
<li>
<p><strong>May be nested, multilevel, cascaded</strong></p>
<ul>
<li>
<p>e.g. EA=((A))</p>
</li>
<li>
<p>Effective address is the value of the storage unit pointed to by (A)</p>
</li>
</ul>
</li>
<li>
<p><strong>Multiple memory accesses to find operand</strong></p>
</li>
<li>
<p><strong>Hence slower</strong></p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-2.png" title="/img/Computer Organization and Architecture/chapter11-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-2.png">
        
    </a>
<ul>
<li>
<p>指令中包含了一个地址A</p>
</li>
<li>
<p>根据A去存储器中访问，得到操作数的地址</p>
</li>
<li>
<p>根据这个地址去获得操作数</p>
</li>
<li>
<p>要2次访问存储器，访问速度相对比较慢</p>
</li>
</ul>
<h5 id="register-addressing">Register addressing</h5>
<ul>
<li>
<p>Operand is held in register named in address field</p>
</li>
<li>
<p>EA = R</p>
</li>
<li>
<p><strong>Limited number of registers</strong></p>
<ul>
<li>Register address field is 3-5 bits, and the number of accessible registers ranges from 8 to 32</li>
</ul>
</li>
<li>
<p><strong>Very small address field needed</strong></p>
<ul>
<li><strong>Shorter instructions</strong></li>
<li><strong>Faster instruction fetch</strong></li>
</ul>
</li>
<li>
<p><strong>Similar to direct addressing</strong></p>
<ul>
<li>
<p><strong>No memory access</strong></p>
</li>
<li>
<p><strong>Very fast execution</strong></p>
</li>
</ul>
</li>
<li>
<p>Very limited address space</p>
</li>
<li>
<p>Multiple registers helps performance</p>
<ul>
<li>
<p>Requires good assembly programming or compiler writing</p>
</li>
<li>
<p>Multiple used operands are placed in registers</p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-3.png" title="/img/Computer Organization and Architecture/chapter11-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-3.png">
        
    </a>
<ul>
<li>
<p>寄存器寻址和存储器直接寻址非常类似</p>
</li>
<li>
<p>访问的是CPU内部的寄存器</p>
</li>
<li>
<p><strong>访问寄存器的速度比访问存储器快很多，并且寄存器的数量少，充分利用好寄存器寻址，可以提高处理速度</strong></p>
</li>
</ul>
<h5 id="register-indirect-addressing">Register indirect addressing</h5>
<ul>
<li>
<p>Similar to indirect addressing</p>
</li>
<li>
<p>EA = (R)</p>
<ul>
<li>Operand is in memory cell pointed to by contents of register R</li>
</ul>
</li>
<li>
<p><strong>Large address space</strong>($2^n$)</p>
<ul>
<li><strong>n is the word length of register</strong></li>
</ul>
</li>
<li>
<p><strong>Much faster than indirect addressing</strong></p>
<ul>
<li><strong>One memory access + one register access</strong></li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-4.png" title="/img/Computer Organization and Architecture/chapter11-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-4.png">
        
    </a>
<ul>
<li>
<p>指令中的地址域中是寄存器R，而寄存器R中的值是操作数在主存中的地址</p>
</li>
<li>
<p>经过两次访问，才能得到操作数。第一次是寄存器访问，第二次是存储器访问</p>
</li>
<li>
<p>由于寄存器的访问时间很短，所以寄存器间接寻址的时间，基本上和访问存储器的时间相当</p>
</li>
</ul>
<h5 id="displacement-addressing">Displacement addressing</h5>
<ul>
<li>
<p><strong>Add a displacement to the base address to obtain the actual address of the operand</strong></p>
<ul>
<li>EA = A + (R)</li>
</ul>
</li>
<li>
<p><strong>Address field hold two values</strong></p>
<ul>
<li><strong>A = base value</strong></li>
<li><strong>R = register that holds displacement</strong></li>
<li><strong>or vice versa</strong></li>
</ul>
</li>
<li>
<p>The operand address is the relative address of the base address, which is often used in virtual addresses</p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-5.png" title="/img/Computer Organization and Architecture/chapter11-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-5.png">
        
    </a>
<ul>
<li>
<p>指令中包含了2个地址字段，寄存器R和基址A</p>
</li>
<li>
<p>寻址时，根据R的值，去寄存器中读取操作数的地址偏移量，加上基址A，得到操作数在主存中的地址，访问存储器，得到操作数</p>
</li>
<li>
<p>偏移寻址有三种方式：第一种是相对寻址，第二种是基址寄存器寻址，第三种是变址寻址</p>
</li>
</ul>
<h6 id="relative-addressing">Relative addressing</h6>
<ul>
<li>
<p>A version of displacement addressing</p>
<ul>
<li>
<p>R = Program counter, PC</p>
</li>
<li>
<p><strong>EA = A + (PC)</strong></p>
</li>
<li>
<p>obtain the operand from the memory, and the address of the operand comes from PC and A</p>
</li>
</ul>
</li>
<li>
<p>Locality of reference &amp; cache usage</p>
<ul>
<li>
<p>Program counter is instruction address</p>
</li>
<li>
<p>Based on the principle of locality, the probability of data in cache is very high, and data access is fast</p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-6.png" title="/img/Computer Organization and Architecture/chapter11-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-6.png">
        
    </a>
<ul>
<li>
<p>相对寻址中，<strong>隐含使用了PC作为基础地址，用指令中地址域中的A作为偏移量</strong></p>
</li>
<li>
<p>通过两个的计算，得到操作数在主存中的地址</p>
</li>
<li>
<p>根据这个地址，访问存储器，得到实际的操作数</p>
</li>
</ul>
<h6 id="base-register-addressing">Base-register addressing</h6>
<ul>
<li>
<p>Use a register R as the base register</p>
<ul>
<li>
<p>R holds pointer to base address</p>
</li>
<li>
<p>R may be explicit or implicit</p>
</li>
<li>
<p>e.g. segment registers in 80x86 is implicit</p>
</li>
</ul>
</li>
<li>
<p>The address field in the instruction gives displacement A</p>
</li>
<li>
<p>The operation of R and A can obtain the actual address of the operand</p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-7.png" title="/img/Computer Organization and Architecture/chapter11-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-7.png">
        
    </a>
<ul>
<li>
<p>基址寄存器BR中包含了寻址的基址，而指令中的地址字段中包含了偏移量</p>
</li>
<li>
<p>这两个相加，得到操作数地址，访问存储器，获取操作数</p>
</li>
<li>
<p>基址寄存器寻址的寻址过程包括：<strong>1. 访问1次寄存器；2. 进行一次加法运算；3. 访问一次主存</strong></p>
</li>
</ul>
<h6 id="indexed-addressing">Indexed addressing</h6>
<ul>
<li>
<p>One type of displacement addressing mode</p>
</li>
<li>
<p><strong>The base address is in the address field, and the offset is in the register</strong></p>
<ul>
<li>
<p>A = base</p>
</li>
<li>
<p>R = displacement</p>
</li>
<li>
<p>EA = A + R</p>
</li>
</ul>
</li>
<li>
<p><strong>Good for accessing arrays</strong></p>
<ul>
<li>EA = A + R</li>
<li>R++</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-8.png" title="/img/Computer Organization and Architecture/chapter11-8.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-8.png">
        
    </a>
<ul>
<li>
<p>变址寻址中，<strong>寄存器中的值是偏移量，基址为指令中给出的地址</strong></p>
</li>
<li>
<p>寻址时，将基址和寄存器中的偏移量进行相加，得到存储器地址</p>
</li>
<li>
<p>根据这个地址访问内存，得到操作数</p>
</li>
</ul>
<h5 id="combinations">Combinations</h5>
<ul>
<li>
<p>Post-index: Indexing after indirect addressing</p>
<ul>
<li>
<p>First get address from memory, then indexing address</p>
</li>
<li>
<p>EA = (A) + (R)</p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-9.png" title="/img/Computer Organization and Architecture/chapter11-9.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-9.png">
        
    </a>
<ul>
<li>指令中地址字段的内容用来访问存储器，获得操作数的直接地址</li>
<li>直接地址被寄存器值变址，得到操作数的实际地址，然后访问这个地址，得到操作数</li>
</ul>
<hr>
<ul>
<li>
<p>Pre-index: Indirect addressing after indexing</p>
<ul>
<li>
<p>Index first, read the memory after getting the address</p>
</li>
<li>
<p>EA = (A + (R))</p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-10.png" title="/img/Computer Organization and Architecture/chapter11-10.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-10.png">
        
    </a>
<ul>
<li>
<p>指令中地址字段和寄存器先进行变址，得到操作数的间接地址</p>
</li>
<li>
<p>访问存储器，得到操作数的实际地址</p>
</li>
<li>
<p>再一次访问存储器，得到操作数</p>
</li>
</ul>
<h5 id="stack-addressing">Stack addressing</h5>
<ul>
<li>
<p><strong>Operand is implicitly on top of stack</strong></p>
</li>
<li>
<p>e.g. ADD</p>
<ul>
<li>
<p><strong>Pop top two number from stack</strong></p>
</li>
<li>
<p><strong>Add the two numbers</strong></p>
</li>
<li>
<p><strong>Push the sum</strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="x86-and-arm-addressing-modes"><code>x86</code> and <code>ARM</code> addressing modes</h3>
<h4 id="swapping">Swapping</h4>
<ul>
<li>
<p>Problem: I/O is so slow compared with CPU that even in multi-programming system, CPU can be idle most of the time</p>
</li>
<li>
<p>Solutions</p>
<ul>
<li>
<p>Increase main memory</p>
<ul>
<li>Expensive</li>
<li>Leads to larger programs</li>
</ul>
</li>
<li>
<p><strong>Swapping</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="partitioning">Partitioning</h4>
<ul>
<li>
<p><strong>Splitting memory into sections to allocate to processes (including Operating System)</strong></p>
</li>
<li>
<p>Fixed-sized partitions</p>
<ul>
<li>
<p>May not be equal size</p>
</li>
<li>
<p><strong>Process is fitted into smallest hole that will take it (best fit)</strong></p>
</li>
<li>
<p><strong>Some wasted memory</strong></p>
</li>
<li>
<p>Leads to variable sized partitions</p>
</li>
</ul>
</li>
</ul>
<h5 id="variable-sized-partitions">Variable sized partitions</h5>
<ul>
<li>
<p>Allocate exactly the required memory to a process</p>
<ul>
<li>
<p>This leads to a hole at the end of memory, too small to use</p>
</li>
<li>
<p>Only one small hole - less waste</p>
</li>
</ul>
</li>
<li>
<p>When all processes are blocked, swap out a process and bring in another</p>
<ul>
<li>New process may be smaller than swapped out process</li>
<li>Another hole</li>
</ul>
</li>
<li>
<p><strong>Eventually have lots of holes，called fragmentation</strong></p>
</li>
<li>
<p>Solutions</p>
<ul>
<li>
<p><strong>Coalesce - Join adjacent holes into one large hole</strong></p>
</li>
<li>
<p><strong>Compaction - From time to time go through memory and move all hole into one free block</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="relocation">Relocation</h4>
<ul>
<li>
<p>Instructions contain addresses</p>
<ul>
<li>
<p>Locations of data</p>
</li>
<li>
<p>Addresses for instructions (branching)</p>
</li>
</ul>
</li>
<li>
<p>No guarantee that process will load into the same place in memory</p>
<ul>
<li>
<p>Logical address - relative to beginning of program</p>
</li>
<li>
<p>Physical address - actual location in memory (this time)</p>
</li>
<li>
<p>Automatic conversion using base address</p>
</li>
</ul>
</li>
</ul>
<h4 id="paging">Paging</h4>
<ul>
<li>
<p>Use paging to solve the problem of memory waste</p>
<ul>
<li>
<p>Split memory into equal sized, small chunks-page frames</p>
</li>
<li>
<p>Split programs (processes) into equal sized small chunks–pages</p>
</li>
<li>
<p>Allocate the required number page frames to a process</p>
</li>
</ul>
</li>
<li>
<p><strong>Operating System is responsible for the management of page tables</strong></p>
<ul>
<li>
<p>A process does not require contiguous page frames</p>
</li>
<li>
<p><strong>Each process uses a page table to record which page frames in memory it uses</strong></p>
</li>
</ul>
</li>
<li>
<p>Each process has its own page table</p>
</li>
<li>
<p><strong>Each page table entry contains the frame number of the corresponding page in main memory</strong></p>
</li>
<li>
<p>Two extra bits are needed to indicate</p>
<ul>
<li>
<p><strong>whether the page is in main memory or not</strong></p>
</li>
<li>
<p><strong>Whether the contents of the page has been altered since it was last loaded</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="real-and-virtual-memory">Real and virtual memory</h4>
<ul>
<li>
<p><strong>Real memory</strong></p>
<ul>
<li><strong>Main memory, the actual <code>RAM</code></strong></li>
</ul>
</li>
<li>
<p><strong>Virtual memory</strong></p>
<ul>
<li>
<p><strong>Memory on disk</strong></p>
</li>
<li>
<p><strong>Allows for effective multiprogramming and relieves the user of tight constraints of main memory</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Advantage of virtual memory</strong></p>
<ul>
<li>
<p><strong>You do not need to load all processes into memory</strong></p>
</li>
<li>
<p><strong>Running multiple processes simultaneously</strong></p>
</li>
<li>
<p><strong>Improved operational efficiency</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="segmentation">Segmentation</h4>
<ul>
<li>
<p><strong>Paging is not (usually) visible to the programmer</strong></p>
</li>
<li>
<p><strong>Segmentation is visible to the programmer</strong></p>
</li>
<li>
<p>Usually different segments allocated to program and data</p>
</li>
<li>
<p>May be a number of program and data segments</p>
</li>
</ul>
<h4 id="x86-addressing-modes"><code>x86</code> addressing modes</h4>
<ul>
<li>
<p><strong><code>x86</code> adopts a memory management mechanism combining segments and pages</strong></p>
</li>
<li>
<p><strong>Virtual or effective address is offset into segment</strong></p>
<ul>
<li>
<p>Starting address plus offset gives linear address</p>
</li>
<li>
<p>This goes through page translation if paging enabled</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>9 addressing modes available</p>
<ul>
<li>
<p>Immediate</p>
</li>
<li>
<p>Register operand</p>
</li>
<li>
<p>Displacement</p>
</li>
<li>
<p>Base</p>
</li>
<li>
<p>Base with displacement</p>
</li>
<li>
<p>Scaled index with displacement</p>
</li>
<li>
<p>Base with index and displacement</p>
</li>
<li>
<p>Base scaled index with displacement</p>
</li>
<li>
<p>Relative</p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-11.png" title="/img/Computer Organization and Architecture/chapter11-11.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-11.png">
        
    </a>
<ul>
<li>
<p>指令中给的逻辑地址包含两个部分：段和段内偏移量</p>
</li>
<li>
<p>查找段表，可以得到段起始地址，加上段内偏移量，得到操作数的线性地址</p>
</li>
<li>
<p>线性地址采用了分页的方式，所以还需要通过页转换机制，得到物理地址，最后通过物理地址查询得到这个操作数。页表采用两级页表的形式</p>
</li>
<li>
<p>6个段寄存器，每个进程使用哪个段寄存器由指令和执行的上下文来确定。每个段寄存器对应一个段描述符表，记录了段的访问权限，段的起始地址和段的长度</p>
</li>
<li>
<p>基址寄存器和变址寄存器，用于构造复杂的寻址方式</p>
</li>
<li>
<p>基址、变址以及指令中的偏移量计算得到有效地址，加上段地址得到操作数的线性地址，然后再根据分页的规则，得到物理地址</p>
</li>
</ul>
<hr>
<p><strong>Terms</strong></p>
<ul>
<li>
<p>Effective address</p>
</li>
<li>
<p>Physical address</p>
</li>
<li>
<p>LA: linear address</p>
</li>
<li>
<p>SR : segment register</p>
</li>
<li>
<p>B: base register</p>
</li>
<li>
<p>I : index register</p>
</li>
<li>
<p>S: scale factor</p>
</li>
</ul>
<hr>
<p><strong><code>x86</code> addressing modes</strong></p>
<ul>
<li>
<p>8个32位通用寄存器，分别是EAX、EBX、ECX、EDX、ESI、EDI、ESP、EBP</p>
</li>
<li>
<p>8个16位通用寄存器，AX、BX、CX、DX、SI、DI、SP、BP</p>
</li>
<li>
<p>8个8位通用寄存器，AH、BH、CH、DH、AL、BL、CL、DL</p>
</li>
<li>
<p>通过段寄存器来确定段的起始地址，然后计算得到线性地址</p>
</li>
<li>
<p>比例变址寻址带偏移量寻址模式中，变址比例因子为1、2、4、8，这个是因为<code>x86</code>是按字节寻址，设置比例因子可以按16位或32位进行变址</p>
</li>
<li>
<p>相对寻址主要用于控制转移指令</p>
</li>
<li>
<p>将偏移量加到程序计数器中，得到相对于下一个需要执行指令的地址的偏移地址</p>
</li>
<li>
<p>偏移量是一个有符号整数，通过计算，可以增加也可以减少程序计数器中的地址值</p>
</li>
</ul>
<h4 id="arm-addressing-modes"><code>ARM</code> addressing modes</h4>
<ul>
<li>
<p><strong><code>ARM</code> is a <code>RISC</code> architecture processor</strong></p>
</li>
<li>
<p>RISC uses simple addressing modes, but ARM provides more addressing modes</p>
</li>
<li>
<p>Only load/store instructions can reference memory</p>
</li>
<li>
<p>Indirectly through base register plus offset</p>
</li>
<li>
<p>Base register itself may be updated during addressing</p>
</li>
<li>
<p>3 addressing mode</p>
</li>
</ul>
<h5 id="offset">Offset</h5>
<ul>
<li>偏移寻址：只偏移，不变址。从基址寄存器增加或减少偏移量来形成内存地址</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">STRB r0, [r1,#12]
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><strong>将r0存放到存储器中，存储器地址为r1的值加上立即数12</strong></li>
</ul>
<h5 id="pre-index">Pre-index</h5>
<ul>
<li>
<p>内存地址跟偏移寻址一样，基址寄存器增加或减少偏移量来形成内存地址</p>
</li>
<li>
<p><strong>内存地址会写回到基址寄存器，基址寄存器的值会增加或减少一个偏移量</strong></p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">STRB r0, [r1,#12]!
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p>这里！就是标识是前变址</p>
</li>
<li>
<p>寻址完成后，r1寄存器的值变成了r1-12</p>
</li>
</ul>
<h5 id="post-index">Post-index</h5>
<ul>
<li>操作数的地址就是在基址寄存器的值</li>
<li><strong>寻址完成后，基址寄存器的值会增加或减少一个偏移量，相当于寻址完成后，基址寄存器自身增加或减少了一个偏移量</strong></li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">STRBv r0, [r1],#12
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>
<p><strong>#表示后变址</strong></p>
</li>
<li>
<p><strong>寻址用r1地址，同时r1寄存器的值变成了r1-12</strong></p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Base register acts as index register for pre-index and postindex addressing</p>
</li>
<li>
<p><strong>Offset either immediate value in instruction or another register</strong></p>
</li>
<li>
<p><strong>If register，scaled register addressing available</strong></p>
<ul>
<li>
<p>Offset register value scaled by shift operator</p>
</li>
<li>
<p>Instruction specifies shift size</p>
</li>
</ul>
</li>
<li>
<p>Data Processing</p>
<ul>
<li>
<p>Register addressing</p>
</li>
<li>
<p>Value in register operands may be scaled using a shift operator</p>
</li>
<li>
<p>Or mixture of register and immediate addressing</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Addressing of branch</strong></p>
<ul>
<li>
<p>Branch</p>
<ul>
<li>
<p><strong>Only immediate</strong></p>
</li>
<li>
<p>Instruction contains 24 bit value</p>
</li>
<li>
<p>When addressing, this immediate value will be shifted two bits to the left, reaching the boundary of a 32-bit word</p>
</li>
<li>
<p>Shifted 2 bits to the left, which is equivalent to an offset of 26 bits. The effective address range is+- 32MB</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>ARM Load/Store Multiple Addressing</strong></p>
<ul>
<li>
<p>One instruction can load or store multiple data at the same time</p>
<ul>
<li>Load or store a set of general registers</li>
</ul>
</li>
<li>
<p>16-bit instruction field in instruction specifies list of registers</p>
<ul>
<li>Registers corresponds to a sequential storage unit in memory</li>
<li>Memory unit with the lowest address corresponds to the register with the lowest number</li>
</ul>
</li>
<li>
<p>Base register specifies first main memory address</p>
</li>
<li>
<p>Four types</p>
<ul>
<li>increment after</li>
<li>increment before</li>
<li>decrement after</li>
<li>decrement before</li>
</ul>
</li>
<li>
<p><strong>Incrementing or decrementing starts before or after first memory access</strong></p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-12.png" title="/img/Computer Organization and Architecture/chapter11-12.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-12.png" data-sub-html="<h2>Multiple addressing diagram</h2>">
        
    </a><figcaption class="image-caption"><code>Multiple addressing diagram</code></figcaption>
    </figure>
<ul>
<li>
<p>r10开始的三个单元内容加载到r0，r1，r4这三个寄存器中。R0为低地址，r4为高地址</p>
</li>
<li>
<p>采用后递增，从0x20C开始，连续三个存储单元的内容取出后，分别给r0，r1和r4。采用前递增，第一个存储单元的地址要在基址寄存器中的地址基础上加1，然后取连续三个存储单元的内容取出后，分别给r0，r1和r4</p>
</li>
<li>
<p>对于后递减，就是从基址寄存器开始，地址递减的连续三个存储单元。对于前递减，就是先在基址寄存器的地址上减1，然后地址递减的连续三个存储单元</p>
</li>
</ul>
<h3 id="instruction-formats">Instruction Formats</h3>
<ul>
<li>
<p>Instruction set is the interface provided by the processor to the upper layer</p>
<ul>
<li>
<p>An important symbol of CPU performance</p>
</li>
<li>
<p>The rationality of the instruction set has a great impact on the performance of the CPU</p>
</li>
</ul>
</li>
<li>
<p><strong>Therefore, the design of instruction format is the core content of processor design</strong></p>
</li>
</ul>
<hr>
<p><strong>Instruction formats</strong></p>
<ul>
<li>
<p>Instruction include</p>
<ul>
<li>
<p>Opcode</p>
</li>
<li>
<p>Operand(s) (implicit or explicit) and addressing mode</p>
</li>
</ul>
</li>
<li>
<p><strong>Instruction formats: How many bits do the parts of the instruction occupy, and in what order</strong></p>
</li>
<li>
<p>Layout of bits in an instruction</p>
</li>
<li>
<p>Usually more than one instruction format in an instruction set</p>
</li>
</ul>
<h4 id="key-of-instruction-formats">Key of instruction formats</h4>
<ul>
<li>
<p>The width of opcodes: determines number of operation</p>
<ul>
<li><strong>The more opcodes, the more functions of the instruction set, and the larger the number of bits</strong></li>
</ul>
</li>
<li>
<p>The width of operands: effect the instruction length</p>
<ul>
<li>
<p>The operand takes up a large proportion of the instruction length</p>
</li>
<li>
<p><strong>Number of operands, addressing mode and size of addressing space have a great impact on the length of instructions</strong></p>
</li>
</ul>
</li>
<li>
<p>Addressing modes: determine the complexity and the length of the instruction</p>
<ul>
<li>
<p><strong>The more complex the addressing mode is, the more operations are required to obtain the physical address of the operand, and the higher the time complexity is</strong></p>
</li>
<li>
<p><strong>Complex addressing mode can use less address field length to obtain larger addressing space and save instruction length</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>First step in instruction set design is to determine the length of instructions</strong></p>
</li>
<li>
<p><strong>Trade off between powerful instruction repertoire and saving space</strong></p>
</li>
</ul>
<hr>
<p><strong>Summary</strong></p>
<ul>
<li>
<p>The operation code and operands should have as many digits as possible</p>
</li>
<li>
<p>The longer the instruction, the more memory space it takes</p>
</li>
<li>
<p>Generally，instruction length is consistent with the bus width , or an integer multiple</p>
</li>
<li>
<p>In the design of instruction set</p>
<ul>
<li>
<p>Every part of the directive needs to be properly planned</p>
</li>
<li>
<p>Seeking the best balance among various design scheme</p>
</li>
</ul>
</li>
</ul>
<h4 id="allocation-of-bits">Allocation of bits</h4>
<ul>
<li>
<p>After the length of the instruction is determined, each bit in the instruction needs to be allocated reasonably to maximize the use of each bit</p>
<ul>
<li><strong>If the opcode is long, operands is short</strong></li>
<li><strong>Variable length opcode, additional bits determine operation</strong></li>
</ul>
</li>
<li>
<p><strong>First, you need to determine the number of operands and opcodes</strong></p>
</li>
</ul>
<p><strong>The following factors need to be considered</strong></p>
<ul>
<li>
<p>Number of operands</p>
</li>
<li>
<p>Number of addressing modes</p>
</li>
<li>
<p>Register versus memory</p>
</li>
<li>
<p>Number of register sets</p>
</li>
<li>
<p>Address range</p>
</li>
<li>
<p>Address granularity</p>
</li>
</ul>
<hr>
<p><strong>Number of addressing modes</strong></p>
<ul>
<li>
<p>Some opcodes implicitly specify the addressing mode of the operand, which does not need to be specified separately</p>
</li>
<li>
<p>Sometimes it is necessary to explicitly specify the addressing mode of this operand, and one or more addressing mode bits are required</p>
</li>
<li>
<p>There may be multiple addressing modes in an instruction</p>
</li>
</ul>
<hr>
<p><strong>Number of operands</strong></p>
<ul>
<li>
<p>If the instruction only supports one operand, it is troublesome to write the program</p>
</li>
<li>
<p>Generally, two operands are supported</p>
</li>
<li>
<p>Each operand hope an independent addressing mode</p>
<ul>
<li>
<p>Flexible</p>
</li>
<li>
<p>Need addressing indication bit</p>
</li>
</ul>
</li>
<li>
<p>Some processors allow one operand to specify the addressing bit</p>
</li>
</ul>
<hr>
<p><strong>Register versus memory</strong></p>
<ul>
<li>Data needs to be loaded into CPU through registers for processing</li>
<li>If there is only one register, it does not need to be specified, but it is very troublesome to use</li>
<li>Several registers are generally provided
<ul>
<li>Several bits can specify a register, which takes up less instruction bits</li>
</ul>
</li>
<li>Most processors have more than 32 registers</li>
</ul>
<hr>
<p><strong>Number of register sets</strong></p>
<ul>
<li>
<p>Most processors provide only one set of general-purpose registers</p>
<ul>
<li>
<p>Store Data</p>
</li>
<li>
<p>Store address field in offset addressing mode</p>
</li>
</ul>
</li>
<li>
<p>Some processors, such as the x86 processor, can provide multiple sets of registers</p>
<ul>
<li>
<p>Divide by function, some store data, some store offset</p>
</li>
<li>
<p>Opcode implicitly determines which set of registers to use</p>
</li>
<li>
<p>Reduce the number of instructions</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Address range</strong></p>
<ul>
<li>
<p>In direct addressing, the address range is determined by the length of the address field in the instruction</p>
<ul>
<li>
<p>Instruction length is limited</p>
</li>
<li>
<p>The address range of direct addressing is small</p>
</li>
</ul>
</li>
<li>
<p><strong>General use offset addressing</strong></p>
<ul>
<li>
<p>Length of the address register is critical</p>
</li>
<li>
<p>If the offset is large, the length of the address field in the instruction is also long</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Address granularity</strong></p>
<ul>
<li>
<p><strong>The smaller the addressable address granularity is, the longer the address bits are required</strong></p>
</li>
<li>
<p>Addressing by byte</p>
<ul>
<li>
<p>Some operations are more convenient</p>
</li>
<li>
<p>e.g. character processing</p>
</li>
<li>
<p>More address bits required</p>
</li>
</ul>
</li>
<li>
<p>Operate according to words</p>
<ul>
<li>
<p>Number of address bits reduced</p>
</li>
<li>
<p>Reduced operational flexibility</p>
</li>
</ul>
</li>
</ul>
<h3 id="x86-and-arm-instruction-formats"><code>x86</code> and <code>ARM</code> instruction formats</h3>
<h4 id="x86-instruction-format"><code>x86</code> instruction format</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-13.png" title="/img/Computer Organization and Architecture/chapter11-13.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-13.png">
        
    </a>
<p><strong>Characteristic</strong></p>
<ul>
<li>
<p><strong>Addressing mode is associated with the instruction opcode</strong></p>
</li>
<li>
<p><strong>An instruction has only one addressing mode</strong></p>
</li>
<li>
<p><strong>Only one memory operand can be referenced in an instruction</strong></p>
</li>
<li>
<p><strong>Typical <code>CISC</code> architecture，use complex instruction format</strong></p>
<ul>
<li>
<p><code>X86</code> needs to consider downward compatibility</p>
</li>
<li>
<p>Hope to provide richer instructions for compiler developers</p>
</li>
</ul>
</li>
</ul>
<h4 id="arm-instruction-formats"><code>ARM</code> instruction formats</h4>
<ul>
<li>
<p><strong>Typical <code>RISC</code> architecture</strong></p>
</li>
<li>
<p><strong>All the instructions are 32 bits, and the format is very neat</strong></p>
</li>
<li>
<p><strong><code>ARM</code> instructions are divided into four categories</strong></p>
<ul>
<li>
<p><strong>data processing instructions</strong></p>
</li>
<li>
<p><strong>load / save instructions</strong></p>
</li>
<li>
<p><strong>overload / save instructions</strong></p>
</li>
<li>
<p><strong>branch instructions</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>All instructions are conditionally executed</strong></p>
</li>
</ul>
<h5 id="condition-code">Condition code</h5>
<ul>
<li>
<p><strong>All instructions are conditionally executed</strong></p>
</li>
<li>
<p>The instruction contains a 4-bit condition code, which is in the highest 4-bit of the instruction</p>
</li>
<li>
<p>Except for the condition flags 1110 and 1111, all other instructions must meet the conditions before they can be executed</p>
</li>
<li>
<p><strong>The condition code includes four condition flags, which are stored in the program status register</strong></p>
</li>
<li>
<p><strong>The four condition flags are N negative flag, Z zero flag, C carry flag, V overflow flag</strong></p>
</li>
<li>
<p><strong>For all arithmetic or logic instructions, an S bit is given to indicate whether the instruction modifies the condition flag bit</strong></p>
</li>
</ul>
<h4 id="data-processing">Data processing</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter11-14.png" title="/img/Computer Organization and Architecture/chapter11-14.png" data-thumbnail="/img/Computer Organization and Architecture/chapter11-14.png">
        
    </a>
<ul>
<li>
<p>数据处理指令类型为000或001。操作码都是4位，s表示是否修改条件标志位。指令中都有三个操作数</p>
</li>
<li>
<p>第一种格式中，目的寄存器Rd，第一个操作数寄存器Rn和第二个操作数寄存器Rm，操作数可以根据shift的标志进行移位，shift amount指明移动多少位</p>
</li>
<li>
<p>第二种格式跟第一种类似，只是移位的位数不是立即数，而是由寄存器Rs来确定</p>
</li>
<li>
<p>第三种格式中，第二操作数是一个立即数，并且可以针对立即数进行循环右移，循环右移的次数由rotate域中的值决定</p>
</li>
</ul>
<h4 id="loadstore">Load/Store</h4>
<ul>
<li>
<p>加载/保存指令中，指令一般类型为010和011。后面5位标识了寻址模式、数据类型，是字节还是字，以及加载和保存标志。</p>
</li>
<li>
<p>第一种加载/保存指令是立即数偏移指令，指令中给出了12位的偏移量。内存地址就是基址寄存器Rn加上或减去立即数偏移量。</p>
</li>
<li>
<p>第二种指令是寄存器偏移。偏移量在Rm寄存器中，通过shift确定移位操作，移动shift amount位之后得到，然后再和基址寄存器Rn计算，得到内存地址。</p>
</li>
<li>
<p>多载/多存指令中，指令一般类型为100。指令中给了16位的寄存器列表，内存地址在Rn中，是先递增，先递减，还是后递增，后递减，由寻址模式来决定</p>
</li>
</ul>
<h4 id="branch">Branch</h4>
<ul>
<li>分支指令的指令一般类型为101，提供了一个24位的立即数</li>
<li>还有一个标志位L，这个标志位决定返回地址是否保存在连接寄存器，也就是link register中。</li>
</ul>
<h4 id="arm-immediate-constants">ARM immediate constants</h4>
<ul>
<li>
<p>数据处理指令中，立即数占了8位，<strong>同时还规定了一个循环移位的值。这样设计的目的是为了获得取值范围较大的数</strong></p>
</li>
<li>
<p>通过循环移位，可以将立即数的范围从8位最多扩展到32位</p>
</li>
</ul>
<h4 id="thumb-instruction-set">Thumb instruction set</h4>
<ul>
<li>
<p>Special Usage: use 16 bit instructions to implement most of 32-bit instructions</p>
</li>
<li>
<p>In an embedded system, there may only be a 16 bit bus</p>
</li>
<li>
<p><strong>Thumb instruction set: Re-encoded subset of ARM instruction set</strong></p>
</li>
<li>
<p><strong>Increases performance in 16-bit or less data bus</strong></p>
</li>
<li>
<p>Need to reduce 16 bits in the instruction</p>
</li>
<li>
<p>Unconditional (4 bits saved)</p>
</li>
<li>
<p>Always update conditional flags</p>
<ul>
<li>Update flag not used (1 bit saved)</li>
</ul>
</li>
<li>
<p>Subset of instructions</p>
<ul>
<li>
<p>2 bit opcode, 3 bit type field (2 bit saved)</p>
</li>
<li>
<p>Reduced operand specifications (9 bits saved)</p>
</li>
</ul>
</li>
<li>
<p>压缩指令集的16位指令可以扩展到32位的标准指令</p>
<ul>
<li>
<p>压缩的指令集只有16位，可以在配置较低的硬件上执行</p>
</li>
<li>
<p>如果在标准的ARM处理器上执行，可以按照这个图上的方法，扩充到32位之后进行执行</p>
</li>
</ul>
</li>
<li>
<p>ARM处理器能够执行16位和32位的指令，并且能够两种格式混合执行</p>
</li>
<li>
<p>处理器中的控制寄存器中的1位用来确定当前的执行是16位的指令还是32位的指令</p>
</li>
</ul>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Instruction Sets: Characteristics and Functions</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-instruction-sets-characteristics-and-functions/</link>
    <pubDate>Wed, 25 Jan 2023 17:56:04 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-instruction-sets-characteristics-and-functions/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="instruction-sets-characteristics-and-functions">Instruction Sets: Characteristics and Functions</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>Machine Instruction Characteristics</p>
</li>
<li>
<p>Types of Operands</p>
</li>
<li>
<p>Intel x86 and ARM Data Types</p>
</li>
<li>
<p>Types of Operations</p>
</li>
<li>
<p>Endian Support</p>
</li>
</ul>
<h3 id="machine-instruction-characteristics">Machine Instruction Characteristics</h3>
<h4 id="language">Language</h4>
<p><strong>Programming language</strong></p>
<ul>
<li>
<p>Classification of programming language</p>
<ul>
<li>
<p>Machine language</p>
</li>
<li>
<p>Assembly language</p>
</li>
<li>
<p>High-level language</p>
</li>
</ul>
</li>
<li>
<p>Compiler</p>
<ul>
<li>
<p>Computers can only recognize machine language</p>
</li>
<li>
<p>Translation program that converts high-level/assembly language programs into machine language</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Machine language</strong></p>
<ul>
<li>
<p>Defined by the computer’s hardware design</p>
</li>
<li>
<p>Consists of streams of numbers (1s and 0s)</p>
</li>
<li>
<p>Instruct the computer to perform the most basic operations</p>
</li>
<li>
<p>A computer can understand only its own machine language</p>
</li>
<li>
<p>It is difficult to remember, and generally will not be used directly</p>
</li>
</ul>
<hr>
<p><strong>Assembly language</strong></p>
<ul>
<li>
<p>Represents machine-language instructions using English-like abbreviations</p>
</li>
<li>
<p>Replace the address of an instruction or operand with an address symbol or label</p>
</li>
<li>
<p>Assemblers convert assembly language to machine language</p>
</li>
<li>
<p>Specific assembly language and specific machine language instruction set are one-to-one, and cannot be directly transplanted between different computer</p>
</li>
</ul>
<h4 id="instruction-set">Instruction set</h4>
<ul>
<li>
<p>The complete collection of instructions that are understood by a CPU</p>
<ul>
<li>
<p>Machine Code</p>
</li>
<li>
<p>Binary</p>
</li>
<li>
<p>Usually represented by assembly codes</p>
</li>
</ul>
</li>
</ul>
<div class="mermaid" id="id-1"></div>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-1.png" title="/img/Computer Organization and Architecture/chapter10-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-1.png" data-sub-html="<h2>Instruction cycle state diagram</h2>">
        
    </a><figcaption class="image-caption"><code>Instruction cycle state diagram</code></figcaption>
    </figure>
<h5 id="elements-of-an-instruction">Elements of an instruction</h5>
<ul>
<li>
<p><strong>Operation code (Op code)</strong></p>
<ul>
<li><strong>Do what</strong></li>
</ul>
</li>
<li>
<p><strong>Source Operand reference</strong></p>
<ul>
<li><strong>From this</strong></li>
</ul>
</li>
<li>
<p><strong>Result Operand reference</strong></p>
<ul>
<li><strong>Put the answer here</strong></li>
</ul>
</li>
<li>
<p><strong>Next Instruction Reference</strong></p>
<ul>
<li>
<p><strong>When you have done that, do this&hellip;</strong></p>
</li>
<li>
<p><strong>Generally, it defaults to the next storage unit</strong></p>
</li>
</ul>
</li>
</ul>
<h5 id="instruction-representation">Instruction representation</h5>
<ul>
<li>
<p>In machine code,each opcode has a unique bit string</p>
</li>
<li>
<p>For programmers a symbolic representation is used</p>
<ul>
<li>e.g. ADD,SUB,LOAD</li>
</ul>
</li>
<li>
<p>The operand follows the opcode in the instruction</p>
</li>
<li>
<p>If there are multiple operands, separate them with “, ”</p>
</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">ADD A,B
</span></span></code></pre></td></tr></table>
</div>
</div><hr>
<p><strong>简单的指令格式</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-2.png" title="/img/Computer Organization and Architecture/chapter10-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-2.png">
        
    </a>
<ul>
<li>
<p>指令总共16个bit长，分为三个部分</p>
<ul>
<li>
<p>第一部分是操作码，4个bit。最多有16种操作</p>
</li>
<li>
<p>第二部分是操作数1的引用，6个bit</p>
</li>
<li>
<p>第三部分是操作数2的引用，6个bit</p>
</li>
</ul>
</li>
<li>
<p><strong>在指令中，源操作数和目的操作数可以在内存、CPU寄存器中或者I/O中，也可能是一个数，称之为立即数</strong></p>
</li>
</ul>
<p>Operands</p>
<ul>
<li>
<p>Main memory</p>
<ul>
<li>
<p>Memory address must be supplied</p>
</li>
<li>
<p><strong>If virtual address is supplied,address translation required</strong></p>
</li>
<li>
<p><strong>It may be in the cache</strong></p>
</li>
</ul>
</li>
<li>
<p>I/O device</p>
<ul>
<li><strong>The instruction must specify the I/O module and device for the operation</strong></li>
</ul>
</li>
<li>
<p>CPU register</p>
<ul>
<li>
<p><strong>If only one register exists, reference to it may be implicit</strong></p>
</li>
<li>
<p><strong>If more than one register exists, then each register is assigned a unique name or number</strong></p>
</li>
<li>
<p><strong>Instruction must contain the number of the desired register</strong></p>
</li>
</ul>
</li>
<li>
<p>Immediate</p>
<ul>
<li>The value of the operand is contained in a field in the instruction being executed</li>
</ul>
</li>
</ul>
<h5 id="instruction-types">Instruction types</h5>
<ul>
<li>
<p>The instructions can be categorized into four types</p>
<ul>
<li>
<p>Data processing</p>
</li>
<li>
<p>Data storage</p>
</li>
<li>
<p>Data movement</p>
</li>
<li>
<p>Program flow control</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Data processing instruction</p>
<ul>
<li>
<p>Processing data</p>
</li>
<li>
<p>Including arithmetic and logic instructions</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Data storage</p>
<ul>
<li>
<p>Storing data</p>
</li>
<li>
<p>Mainly refers to the <strong>transfer of data between memory and CPU registers</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>Data movement
<ul>
<li>mainly refers to the data transmission between CPU and I/O</li>
<li>I/O instructions</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Program flow control</p>
<ul>
<li>
<p>Some instructions of CPU execution control</p>
</li>
<li>
<p>Test instructions</p>
</li>
<li>
<p>Branch instructions</p>
</li>
</ul>
</li>
</ul>
<p><strong>Instruction types</strong></p>
<ul>
<li>
<p>Arithmetic instructions</p>
</li>
<li>
<p>Logic (Boolean) instructions</p>
</li>
<li>
<p>Memory instructions: moving data between memory and the registers</p>
</li>
<li>
<p>I/O instructions</p>
</li>
<li>
<p>Test instructions: used to test the value of a data word or the status of a computation</p>
</li>
<li>
<p>Branch instructions: used to branch to a different set of instructions</p>
</li>
</ul>
<h4 id="number-of-addresses">Number of addresses</h4>
<ul>
<li>
<p>The address in the instruction is used to address the operand</p>
</li>
<li>
<p>The number of addresses in instructions varies with different instruction types</p>
</li>
<li>
<p>Different computers support different numbers of operands</p>
</li>
<li>
<p><strong>The number of operands in an instruction may be 3, 2, 1, or none</strong></p>
</li>
</ul>
<h5 id="3-addresses">3 addresses</h5>
<ul>
<li>
<p><strong>Operand 1, Operand 2, Result</strong></p>
</li>
<li>
<p><strong>a = b + c</strong></p>
</li>
<li>
<p>May be a forth - next instruction (usually implicit)</p>
</li>
<li>
<p>Not common</p>
</li>
<li>
<p>Needs very long words to hold everything</p>
</li>
</ul>
<h5 id="2-addresses">2 addresses</h5>
<ul>
<li>
<p>Two operand</p>
</li>
<li>
<p><strong>One address doubles as operand and result</strong></p>
</li>
<li>
<p><strong>a = a + b</strong></p>
</li>
<li>
<p>Reduces length of instruction</p>
</li>
<li>
<p>Requires some extra work</p>
<ul>
<li><strong>Temporary storage to hold some results</strong></li>
</ul>
</li>
</ul>
<h5 id="1-addresses">1 addresses</h5>
<ul>
<li>
<p><strong>Implicit second address</strong></p>
</li>
<li>
<p><strong>Usually a register (accumulator)</strong></p>
</li>
<li>
<p>Common on early machines</p>
<ul>
<li>
<p>LOAD A  $AC \leftarrow A\newline$</p>
</li>
<li>
<p>SUB B  $AC \leftarrow AC-B\newline$</p>
</li>
<li>
<p>STORE Y  $Y \leftarrow AC\newline$</p>
</li>
</ul>
</li>
</ul>
<h5 id="0-addresses">0 addresses</h5>
<ul>
<li>
<p><strong>0 (zero) addresses: All addresses implicit</strong></p>
<ul>
<li>
<p><strong>Usually use stack to imply the operands</strong></p>
</li>
<li>
<p>e.g:</p>
<ul>
<li>push a</li>
<li>push b</li>
<li>add (pop a and b,then add a and b(c=a+b) and push the result to the stack)</li>
<li>pop c</li>
<li>c = a + b</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>More addresses</p>
<ul>
<li>
<p>More complex instructions</p>
</li>
<li>
<p>Fewer instructions per program</p>
</li>
<li>
<p>Inter-register operations are quicker</p>
</li>
<li>
<p>More registers</p>
</li>
</ul>
</li>
<li>
<p>Fewer addresses</p>
<ul>
<li>
<p>Less complex instructions</p>
</li>
<li>
<p>More instructions per program</p>
</li>
<li>
<p>Faster fetch/execution of instructions</p>
</li>
</ul>
</li>
</ul>
<h4 id="instruction-set-design">Instruction set design</h4>
<h5 id="design-issues-of-instruction-set">Design issues of instruction set</h5>
<ul>
<li>
<p>Operation repertoire: how many and which operations to provides, and how complex operations should be</p>
</li>
<li>
<p>Data types: the operands types</p>
</li>
<li>
<p>Instruction format: instruction length, number of addresses…</p>
</li>
<li>
<p>Registers: how many registers can be used by the instructions</p>
</li>
<li>
<p>Addressing: how to access a memory location, how many modes can be used</p>
</li>
</ul>
<h3 id="types-of-operands">Types of Operands</h3>
<ul>
<li>
<p>Addresses</p>
</li>
<li>
<p>Numbers</p>
<ul>
<li>Integer/floating point</li>
</ul>
</li>
<li>
<p>Characters</p>
<ul>
<li>ASCII etc</li>
</ul>
</li>
<li>
<p>Logical Data</p>
<ul>
<li>Bits or flags</li>
</ul>
</li>
</ul>
<h4 id="address">Address</h4>
<ul>
<li>
<p>The data operated by the instruction may be in memory</p>
<ul>
<li>
<p>Address is used for addressing operands</p>
</li>
<li>
<p>Treat as an unsigned integer</p>
</li>
</ul>
</li>
<li>
<p>In many cases, need to process the address to get the actual address of the data</p>
</li>
</ul>
<h4 id="numbers">Numbers</h4>
<ul>
<li>
<p>Three types of numerical data are common in computers</p>
<ul>
<li>
<p>Binary integer or binary fixed point</p>
</li>
<li>
<p>Binary floating point</p>
</li>
<li>
<p>Decimal</p>
<ul>
<li>
<p>Packed decimal</p>
</li>
<li>
<p>Use 4-bit binary number to represent a decimal number</p>
</li>
<li>
<p>In the packed decimal representation, only the previous 10 codes are used, that is, from 0000 to 1001</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="characters">Characters</h4>
<ul>
<li>
<p>A common form of data is text or character strings</p>
</li>
<li>
<p>The most commonly used</p>
<ul>
<li>
<p>International Reference Alphabet (IRA)</p>
</li>
<li>
<p>United States as the American Standard Code for Information Interchange (ASCII)</p>
</li>
</ul>
</li>
<li>
<p>Extended Binary Coded Decimal Interchange Code (EBCDIC)</p>
<ul>
<li>Used on IBM mainframes</li>
</ul>
</li>
</ul>
<h4 id="logical-data">Logical data</h4>
<ul>
<li>
<p>Boolean or binary data items</p>
<ul>
<li>Each item can take on only the values 1 (true) and 0 (false)</li>
</ul>
</li>
<li>
<p>There are occasions when we wish to manipulate the bits of a data item</p>
</li>
</ul>
<p>数据都是以二进制串的形式保存的。<strong>因此数据是什么类型的主要取决于指令的类型。指令中确定了它所操作的数据的类型</strong></p>
<h3 id="intel-x86-and-arm-data-types">Intel x86 and ARM Data Types</h3>
<h4 id="x86-data-types">X86 data types</h4>
<ul>
<li>
<p>8 bit Byte</p>
</li>
<li>
<p>16 bit word</p>
</li>
<li>
<p>32 bit double word</p>
</li>
<li>
<p>64 bit quad word</p>
</li>
<li>
<p>128 bit double quadword</p>
</li>
<li>
<p>Addressing is by 8 bit unit</p>
</li>
<li>
<p><strong>Words do not need to align at even-numbered address</strong></p>
</li>
<li>
<p><strong>Data accessed across 32 bit bus in units of double word read at addresses divisible by 4</strong></p>
</li>
<li>
<p><strong>Little endian</strong></p>
</li>
</ul>
<hr>
<ul>
<li>无符号整数4种格式，分别是8位，16位，32位和64位</li>
<li>有符号数采用补码形式，也有4种格式，位数是8位，16位，32位和64位</li>
<li>浮点数，包括单精度浮点数，32位；双精度浮点数，64位，以及扩展的双精度浮点数，80位</li>
<li>浮点数表示符合IEEE 754标准的要求</li>
</ul>
<h4 id="simd-data-types">SIMD data types</h4>
<ul>
<li>
<p>In the X86 architecture, <code>MMX</code>(Multi Media eXtension)related instructions are added to improve the processing efficiency of multimedia data</p>
</li>
<li>
<p><code>MMX</code> technology adds 57 instructions specially designed for video signal, audio signal and graphic manipulation to the CPU</p>
</li>
<li>
<p>Therefore, <code>MMX</code> CPU greatly improves the computer’s multimedia (such as stereo, video, 3D animation, etc.) processing function</p>
</li>
<li>
<p>In <code>MMX</code> instructions, one instruction can process multiple data at the same time, which is called <strong>single instruction multiple data(<code>SIMD</code>)</strong></p>
</li>
<li>
<p><strong>Basic idea of <code>SIMD</code> is to package multiple operands into one memory addressable data, that is, the data obtained by one addressing is the result of multiple data packages</strong></p>
<ul>
<li><strong>one instruction can obtain multiple operands and process them at the same time</strong></li>
</ul>
</li>
<li>
<p>Five packaging methods for compressed data</p>
<ul>
<li>
<p>Packed byte and packed byte integer</p>
</li>
<li>
<p>Packed word and packed word integer</p>
</li>
<li>
<p>Packed doubleword and packed doubleword integer</p>
</li>
<li>
<p>Packed quadword and packed quadword integer</p>
</li>
<li>
<p>Packed single-precision floating-point and packed double-precision floatingpoint</p>
</li>
</ul>
</li>
<li>
<p>Packed byte and packed byte integer</p>
<ul>
<li>
<p>Bytes packed into 64-bit quadword</p>
</li>
<li>
<p>or 128-bit double quadword</p>
</li>
</ul>
</li>
<li>
<p>Packed word and packed word integer</p>
<ul>
<li>
<p>16-bit words packed into 64-bit quadword</p>
</li>
<li>
<p>or 128-bit double quadword</p>
</li>
</ul>
</li>
<li>
<p>Packed doubleword and packed doubleword integer</p>
<ul>
<li>
<p>32-bit doublewords packed into 64-bit quadword</p>
</li>
<li>
<p>or 128-bit double quadword</p>
</li>
</ul>
</li>
<li>
<p>Packed quadword and packed quadword integer</p>
<ul>
<li>Two 64-bit quadwords packed into 128-bit double quadword</li>
</ul>
</li>
<li>
<p>Packed single-precision floating-point and packed double-precision floating-point</p>
<ul>
<li>Four 32-bit floating-point or two 64-bit floating-point values packed into a 128-bit double quadword</li>
</ul>
</li>
</ul>
<h4 id="arm-data-types">ARM data types</h4>
<ul>
<li>
<p><strong>8 (byte), 16 (halfword), 32 (word) bits</strong></p>
</li>
<li>
<p><strong>Halfword and word accesses should be word aligned</strong></p>
</li>
<li>
<p>Nonaligned access alternatives</p>
<ul>
<li>
<p>Default</p>
<ul>
<li>
<p>Treated as truncated</p>
</li>
<li>
<p><strong>Load single word instructions rotate right word aligned data transferred by non word-aligned address one, two or three bytes Alignment checking</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Data abort signal indicates alignment fault for attempting unaligned access</strong></p>
</li>
<li>
<p><strong>Unaligned access: Processor uses one or more memory accesses to generate transfer of adjacent bytes transparently to the programmer</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Unsigned integer interpretation supported for all types</p>
</li>
<li>
<p>Twos-complement signed integer interpretation supported for all types</p>
</li>
<li>
<p><strong>Majority of implementations do not provide floating-point hardware</strong></p>
<ul>
<li>
<p><strong>Saves power and area</strong></p>
</li>
<li>
<p><strong>Floating-point arithmetic implemented in software</strong></p>
</li>
<li>
<p><strong>Optional floating-point coprocessor</strong></p>
</li>
<li>
<p><strong>Single- and double-precision IEEE 754 floating point data types</strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="types-of-operations">Types of Operations</h3>
<ul>
<li>
<p>Arithmetic</p>
</li>
<li>
<p>Logical</p>
</li>
<li>
<p>Data Transfer</p>
</li>
<li>
<p>Conversion</p>
</li>
<li>
<p>I/O</p>
</li>
<li>
<p>System Control</p>
</li>
<li>
<p>Transfer of Control</p>
</li>
</ul>
<h4 id="data-transfer">Data transfer</h4>
<ul>
<li>
<p>Location of source and destination must be specified</p>
<ul>
<li>Memory</li>
<li>Register</li>
<li>Top of the stack</li>
</ul>
</li>
<li>
<p>For the memory access, addressing mode must be specified</p>
<ul>
<li>Memory has multiple addressing modes, such as direct addressing and indirect addressing</li>
</ul>
</li>
<li>
<p>The length of the operands must be specified</p>
</li>
<li>
<p>Data transmission instructions need to specify</p>
<ul>
<li>
<p><strong>Source address</strong></p>
</li>
<li>
<p><strong>Destination address</strong></p>
</li>
<li>
<p><strong>Amount of data</strong></p>
</li>
</ul>
</li>
<li>
<p>Which data transfer instructions are included is one of the important issues to be considered in instruction set design</p>
</li>
<li>
<p>For example, whether the location of the operand is determined by the opcode or by the operand needs to be designed</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>IBM 390</p>
<ul>
<li>
<p>Use different instructions for different movements</p>
</li>
<li>
<p>Operation code determines the direction of data movement</p>
</li>
</ul>
</li>
<li>
<p>VAX</p>
<ul>
<li>
<p>Data transmission between different data sources with the same</p>
</li>
<li>
<p>The position of each operand must be specified separately in the instruction</p>
</li>
</ul>
</li>
</ul>
<h4 id="common-data-transfer-instructions">Common Data Transfer Instructions</h4>
<ul>
<li>
<p>常见的数据传送指令包括：移动、存储、加载、交换、清除、设置、进栈、出栈等</p>
</li>
<li>
<p>数据传送对于处理器来说是最基本、最简单的操作，实现了数据从一个位置到另一个位置的移动</p>
</li>
<li>
<p>数据传送指令将数据从一个位置移动到另一个位置</p>
</li>
<li>
<p><strong>如果数据传送涉及到内存的话，还有一点复杂:</strong></p>
<ul>
<li>
<p><strong>需要根据寻址方式来计算存储器的地址</strong></p>
</li>
<li>
<p><strong>如果给的是虚拟地址的话，还需要进行虚拟地址到实际地址的转换</strong></p>
</li>
<li>
<p><strong>所以得到实存地址后，需要检查数据是否在cache中。如果在cache中，就对cache进行读取操作；如果没有命中，需要进行存储器的读或者写操作</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="arithmetic">Arithmetic</h4>
<ul>
<li>
<p>Single operand instruction</p>
<ul>
<li>absolute, negate, increment, decrement</li>
</ul>
</li>
<li>
<p>Two operands instruction</p>
<ul>
<li>Add, subtract, multiply, divide</li>
</ul>
</li>
<li>
<p>The operands are</p>
<ul>
<li>
<p>Signed integer (fixed point) numbers</p>
</li>
<li>
<p>Floating-point numbers</p>
</li>
<li>
<p><strong>Packed decimal numbers</strong></p>
</li>
</ul>
</li>
<li>
<p>Mainly completed by CPU</p>
</li>
<li>
<p>算术运算的操作可能会包括数据传输传送操作。数据传送操作的目的是在运算前给ALU提供操作的数据，或者在运算后将结果输出</p>
</li>
<li>
<p>算术操作的实际执行是在ALU中</p>
</li>
<li>
<p>计算完成之后，还会设置状态码或标志位，用以表示计算的结果，比如是否溢出，是否出错等</p>
</li>
</ul>
<h4 id="logical">Logical</h4>
<ul>
<li>
<p>Most processors can operate on a single bit of a word or addressable unit</p>
<ul>
<li>
<p><strong>Called <code>bit twiddling</code></strong></p>
</li>
<li>
<p>It&rsquo;s actually a bit wise Boolean operation</p>
</li>
</ul>
</li>
<li>
<p>Basic logic operation</p>
<ul>
<li><strong>AND, OR, NOT, Exclusive-OR</strong></li>
</ul>
</li>
<li>
<p>Extended logical operations</p>
<ul>
<li><strong>Test，compare，set control variables，shift，rotate</strong></li>
</ul>
</li>
<li>
<p>测试test：测试指令，进行特定条件的测试并设置标志位</p>
</li>
<li>
<p>比较compare：比较指令，对两个或多个操作数进行比较，并设置标志位</p>
</li>
<li>
<p>设置控制变量set control variables：一组用于设置控制位的指令，以进行保护，中断处理，定时控制的用途</p>
</li>
<li>
<p>移位shift：左移或右移数据</p>
</li>
<li>
<p>循环rotate：循环移位</p>
</li>
</ul>
<h4 id="shift-operations--">Shift operations! ! !</h4>
<ul>
<li>
<p><strong>Logical shift: without considering the highest sign bit</strong></p>
<ul>
<li>
<p><strong>Logical right: Move the operand to the right by n bits, and fill in 0 at the left position</strong></p>
</li>
<li>
<p><strong>Logical left: Move the operand to the left by n, and fill in 0 for the n bits vacated on the right</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Arithmetic shift: consider the highest sign bit</strong></p>
<ul>
<li>
<p><strong>Arithmetic right: Shift n bits to the right as a whole, and fill the empty n bits on the left with the highest sign bit</strong></p>
</li>
<li>
<p><strong>Arithmetic left: Retain the sign bit of the highest bit, and then shift the other bits by n bits to the left</strong></p>
</li>
</ul>
</li>
<li>
<p>10100110：移动3位</p>
<ul>
<li>
<p>逻辑右移：00010100，逻辑左移：00110000</p>
</li>
<li>
<p>算术右移：11110100，算术左移：10110000</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Rotate/Cyclic shift</strong></p>
<ul>
<li>
<p>Rotate right: Each number moves one digit to the right, and the rightmost digit moves to the leftmost digit</p>
</li>
<li>
<p>Rotate left: Each number moves one digit to the left, and the leftmost digit moves to the rightmost digit</p>
</li>
<li>
<p><strong>One possible use of the loop is to move left circularly, place each bit at the highest bit in turn, and then test the sign bit to determine the value of each bit</strong></p>
</li>
<li>
<p>10100110：移动3位</p>
<ul>
<li>
<p>循环右移：11010110</p>
</li>
<li>
<p>循环左移：00110101</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Role of shift</strong></p>
<ul>
<li>
<p>Right shift</p>
<ul>
<li>
<p><strong>Logical right shift: which is equivalent to dividing an unsigned integer by 2</strong></p>
</li>
<li>
<p><strong>Arithmetic right shift: for complement representation, it is equivalent to dividing by 2</strong></p>
</li>
</ul>
</li>
<li>
<p>Left shift: overflow needs to be considered</p>
<ul>
<li>
<p><strong>When there is no overflow, it is equivalent to multiplying by 2</strong></p>
</li>
<li>
<p><strong>When there is overflow, it has different effects on logical shift left and arithmetic shift left</strong></p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-3.png" title="/img/Computer Organization and Architecture/chapter10-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-3.png">
        
    </a>
<h4 id="conversion">Conversion</h4>
<ul>
<li>
<p>转换指令主要目的是改变数据格式，或者对数据格式进行操作</p>
</li>
<li>
<p>比如说，对二级制的数据格式进行转换，转换成十进制，或者从压缩的10进制转换为二进制</p>
</li>
<li>
<p>还有一种是翻译，根据一个表的相应位的值，将内存块中的一些数据翻译成另一些数</p>
</li>
</ul>
<h4 id="inputoutput">Input/output</h4>
<ul>
<li>
<p>May be specific instructions</p>
</li>
<li>
<p><strong>May be done using data movement instructions (memory mapped)</strong></p>
</li>
<li>
<p><strong>May be done by a separate controller (<code>DMA</code>)</strong></p>
</li>
</ul>
<h4 id="system-control">System control</h4>
<ul>
<li>
<p>Privileged instructions</p>
</li>
<li>
<p>CPU needs to be in specific state</p>
<ul>
<li>Kernel mode</li>
</ul>
</li>
<li>
<p>For operating systems use</p>
</li>
<li>
<p>Some control instructions</p>
<ul>
<li>
<p><strong>Read or write a control register</strong></p>
</li>
<li>
<p><strong>Read or write a storage protection key</strong></p>
</li>
<li>
<p><strong>Access to process control blocks in a multiprogramming system</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="transfer-of-control">Transfer of control</h4>
<ul>
<li>
<p><strong>The first scenario is that we need to repeat some instructions</strong></p>
<ul>
<li>
<p><strong>Multiplication of vector or matrix is easy to implement if circular statements are used</strong></p>
</li>
<li>
<p><strong>Need use the transfer instruction, starting from the end of the loop body</strong></p>
</li>
<li>
<p>It is almost impossible without a transfer instruction</p>
</li>
</ul>
</li>
<li>
<p><strong>The second scenario is that when we write a program, we often need to judge which operation to do next according to a calculation result</strong></p>
<ul>
<li>
<p>When calculating division, you can first verify whether the divisor is 0. If it is 0, you can directly report an error</p>
</li>
<li>
<p><strong>Transfer instructions are required, and the instructions to be executed in the next step are determined according to the judgment results</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>The third scenario is that when we write programs, we often use procedures or functions</strong></p>
<ul>
<li>
<p>Break a large program into several small parts, and then process them separately</p>
</li>
<li>
<p>Procedures or functions can be called multiple times</p>
</li>
<li>
<p>Transfer instructions must be used when calling procedures or functions</p>
</li>
</ul>
</li>
</ul>
<h5 id="role-of-control-transfer">Role of control transfer</h5>
<ul>
<li>
<p><strong>Normal execution of instructions</strong></p>
<ul>
<li>
<p><strong>PC(program counter)stores the address of the next instruction to be executed</strong></p>
</li>
<li>
<p><strong>After the instruction retrieval is completed, PC automatically adds 1 to point to the next instruction address</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Control transfer instructions</strong></p>
<ul>
<li>
<p><strong>Determine the next instruction to be executed according to the execution result of the current instruction</strong></p>
</li>
<li>
<p><strong>Change the original instruction execution order</strong></p>
</li>
</ul>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-4.png" title="/img/Computer Organization and Architecture/chapter10-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-4.png" data-sub-html="<h2>Types of control transfer</h2>">
        
    </a><figcaption class="image-caption"><code>Types of control transfer</code></figcaption>
    </figure>
<h5 id="some-control-transfer-instruction">Some control transfer instruction</h5>
<ul>
<li>
<p>Branch</p>
<ul>
<li>
<p><strong>Also called jump</strong></p>
</li>
<li>
<p><strong>Take the address of next instruction to be executed as an operand of current instruction</strong></p>
</li>
<li>
<p>For conditional branch instructions, the branch is made only if a certain condition is met</p>
<ul>
<li>Otherwise, executes next instruction in sequence</li>
</ul>
</li>
<li>
<p>Usually the condition is taken as a result of an operation (arithmetic or logic)</p>
</li>
</ul>
</li>
<li>
<p>Skip</p>
<ul>
<li>
<p><strong>Skip execution of the next instruction</strong></p>
</li>
<li>
<p>It is not necessary to specify the address of the next instruction in the instruction</p>
</li>
<li>
<p>The skip instruction includes an implied address</p>
</li>
<li>
<p><strong>The skip implies that one instruction be skipped</strong></p>
<ul>
<li>The implied address equals the address of next instruction plus one instruction-length</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Subroutine call</p>
<ul>
<li>
<p><strong>Call the procedure code to execute the procedure</strong></p>
</li>
<li>
<p><strong>After execution, return to the point where the call occurred and continue to execute next instruction</strong></p>
</li>
<li>
<p><strong>A procedure is a subroutine, that is, a computer program, which can perform certain functions</strong></p>
</li>
<li>
<p>Write the general function as a procedure, which can be called many times in the program</p>
<ul>
<li>
<p>Save the workload of programming</p>
</li>
<li>
<p><strong>Memory space occupied by programs is also reduced</strong></p>
</li>
</ul>
</li>
<li>
<p>Through procedure writing, modular programming is carried out to improve the efficiency of programming</p>
</li>
</ul>
</li>
</ul>
<h4 id="procedure-call-instruction">Procedure call instruction</h4>
<ul>
<li>
<p>It is invoked by a calling instruction and returned by a return instruction</p>
<ul>
<li>
<p><strong>Procedure call can be nested</strong></p>
</li>
<li>
<p><strong>Each procedure call is matched by a return in the called program</strong></p>
</li>
</ul>
</li>
<li>
<p>The CPU must save the return address，it also need to pass parameters to the procedure in one of the following ways</p>
<ul>
<li>
<p><strong>Register</strong></p>
</li>
<li>
<p><strong>Start of called procedure</strong></p>
</li>
<li>
<p><strong>Top of stack</strong></p>
</li>
</ul>
</li>
</ul>
<h5 id="nested-procedure-calls">Nested procedure calls</h5>
<ul>
<li>
<p>主程序中调用过程1</p>
</li>
<li>
<p>过程1中有2个调用过程2的步骤</p>
</li>
<li>
<p>每次调用完必须有返回的指令，返回到调用的地方</p>
</li>
<li>
<p><strong>返回地址的保存和使用方式，一般采用栈来完成</strong></p>
</li>
</ul>
<h5 id="use-of-stacks">Use of stacks</h5>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-5.png" title="/img/Computer Organization and Architecture/chapter10-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-5.png" data-sub-html="<h2>stack</h2>">
        
    </a><figcaption class="image-caption"><code>stack</code></figcaption>
    </figure>
<ul>
<li>
<p><strong>初始化时，栈是空栈</strong></p>
</li>
<li>
<p><strong>调用过程1时，需要把返回地址，也就是4101压栈</strong></p>
</li>
<li>
<p><strong>过程1中调用过程2时，需要把返回地址4601压栈</strong></p>
</li>
<li>
<p><strong>第一个过程2执行完成，把4601弹出，这样就返回到过程调用前的状态</strong></p>
</li>
<li>
<p><strong>第二次调用过程2，同样把返回地址压栈</strong></p>
</li>
<li>
<p><strong>过程执行结束，弹出4651。过程1执行结束，弹出4101，继续执行主程序</strong></p>
</li>
</ul>
<h5 id="passing-parameters">Passing parameters</h5>
<ul>
<li>
<p>Pass parameters is important to the procedure cal</p>
</li>
<li>
<p>Using registers</p>
<ul>
<li>Must assure that the registers are used properly</li>
</ul>
</li>
<li>
<p>Using memory cells</p>
<ul>
<li>It is difficult to exchange the variables</li>
</ul>
</li>
<li>
<p><strong>Using stack</strong></p>
<ul>
<li>
<p>more flexible</p>
</li>
<li>
<p>When a procedure is called</p>
<ul>
<li>
<p>Stack the return address</p>
</li>
<li>
<p>Stack parameters to be passed to the called procedure</p>
</li>
</ul>
</li>
<li>
<p>When return</p>
<ul>
<li>Return parameters can also be placed on the stack</li>
</ul>
</li>
<li>
<p><strong>All above stacked info for the procedure is called a stack frame(OS)</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-6.png" title="/img/Computer Organization and Architecture/chapter10-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-6.png">
        
    </a>
<ul>
<li>
<p>主程序调用P的时候，先把返回地址压栈，然后将之前的帧指针地址保存，之后再将x1和x2这两个参数压到栈里面</p>
</li>
<li>
<p>P调用Q的时候，先把返回地址压栈，然后将老的帧地址保存，再将P要传给Q的y1和y2地址压栈</p>
</li>
<li>
<p>通过栈，完成了参数、返回地址的传递</p>
</li>
</ul>
<h4 id="stack">Stack</h4>
<ul>
<li>
<p>Queues work in two basic ways</p>
<ul>
<li><code>FIFO</code>: first in first out</li>
<li><code>LIFO</code>: last in first out</li>
</ul>
</li>
<li>
<p><strong>Stack is a <code>LIFO</code></strong></p>
</li>
<li>
<p>A stack is an ordered set of elements, only one of which can be accessed at a time</p>
</li>
<li>
<p>The point of access is called the top of the stack</p>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-7.png" title="/img/Computer Organization and Architecture/chapter10-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-7.png" data-sub-html="<h2>stack operation</h2>">
        
    </a><figcaption class="image-caption"><code>stack operation</code></figcaption>
    </figure>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-8.png" title="/img/Computer Organization and Architecture/chapter10-8.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-8.png" data-sub-html="<h2>Typical stack organization</h2>">
        
    </a><figcaption class="image-caption"><code>Typical stack organization</code></figcaption>
    </figure>
<h3 id="endian-support">Endian Support</h3>
<ul>
<li>Example of Endian
<ul>
<li>Suppose we want to store a 32-bit hex value 12345678 to address 184</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter10-9.png" title="/img/Computer Organization and Architecture/chapter10-9.png" data-thumbnail="/img/Computer Organization and Architecture/chapter10-9.png">
        
    </a>
<h4 id="endian">Endian</h4>
<ul>
<li>
<p>Big endian</p>
<ul>
<li>
<p>The most significant byte in the lowest numerical byte address</p>
</li>
<li>
<p>Equivalent to the <strong>left-to-right order</strong> of writing</p>
</li>
</ul>
</li>
<li>
<p>Little endian</p>
<ul>
<li>
<p>The least significant byte in the lowest numerical byte address</p>
</li>
<li>
<p>Reminiscent of the <strong>right-to-left order</strong> of arithmetic operations in arithmetic units</p>
</li>
</ul>
</li>
<li>
<p>Machines from different manufacturers may adopt different endian</p>
</li>
</ul>
<h4 id="standard">Standard</h4>
<ul>
<li>
<p>Pentium (x86), VAX, Alpha are little-endian</p>
</li>
<li>
<p>BM 370, Motorola 680x0 (Mac), and most RISC are big-endian</p>
</li>
<li>
<p><strong>Internet is big-endian</strong></p>
<ul>
<li>
<p><strong>Makes writing Internet programs on PC more awkward!</strong></p>
</li>
<li>
<p><strong>WinSock provides HtoI and ItoH (Host to Internet &amp; Internet to Host) functions to convert</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>ARM endian support</strong></p>
<ul>
<li>
<p>ARM supports two endian</p>
</li>
<li>
<p>E-bit in system control register</p>
</li>
<li>
<p><strong>E-bit=0 is the big endian; if E-bit=1, it is the little endian E-bit=0</strong></p>
</li>
</ul>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Computer Aritmetic</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-computer-aritmetic/</link>
    <pubDate>Tue, 24 Jan 2023 15:49:52 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-computer-aritmetic/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="computer-arithmetic">Computer Arithmetic</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>The Arithmetic and Logic Unit (ALU)</li>
<li>Integer Representation</li>
<li>Integer Arithmetic</li>
<li>Floating-Point Representation</li>
<li>Floating-Point Arithmetic</li>
</ul>
<h3 id="the-arithmetic-and-logic-unit-alu">The Arithmetic and Logic Unit (ALU)</h3>
<p><strong>Arithmetic &amp; logic unit</strong></p>
<ul>
<li>
<p><strong>Core of computer</strong></p>
</li>
<li>
<p><strong>Everything else in the computer is there to service this unit</strong></p>
</li>
<li>
<p>Does arithmetic and logic calculations</p>
</li>
<li>
<p>Handles integers</p>
<ul>
<li>
<p>May handle floating point (real) numbers</p>
</li>
<li>
<p>May be separate <code>FPU</code> ( maths co-processor)</p>
</li>
<li>
<p>May be on chip separate <code>FPU</code> ( <code>486DX + </code>)</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>ALU input &amp; output</strong></p>
<ul>
<li>
<p>一般CPU内部会有一组寄存器，用于用于临时存放数据</p>
</li>
<li>
<p>控制单元告诉ALU需要做什么操作，同时还控制数据的输入和输出</p>
</li>
<li>
<p>数据由寄存器送给ALU进行运算，运算之后的结果也保存在寄存器中</p>
</li>
<li>
<p>ALU在计算后，会设置一些标志，比如溢出标志等，标志也保存在寄存器中</p>
</li>
</ul>
<h3 id="integer-representation">Integer Representation</h3>
<ul>
<li>
<p>Electronic components generally have only two basic states</p>
<ul>
<li>
<p>Whether there is charge, high and low level</p>
</li>
<li>
<p>Represents 0 and 1</p>
</li>
</ul>
</li>
<li>
<p>Computer use 0 &amp; 1 to represent everything</p>
<ul>
<li>
<p>Positive numbers stored in binary</p>
</li>
<li>
<p>e.g. 41=00101001</p>
</li>
<li>
<p>No minus sign</p>
</li>
<li>
<p>No period</p>
</li>
</ul>
</li>
<li>
<p><strong>How to represent negative numbers</strong></p>
<ul>
<li>
<p><strong>Sign-Magnitude</strong></p>
</li>
<li>
<p><strong>Two’s complement</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>unsigned</p>
<ul>
<li>
<p>Use only non-negative integers</p>
</li>
<li>
<p><strong>sign bit does not need</strong></p>
</li>
</ul>
</li>
<li>
<p>sign magnitude</p>
<ul>
<li>Sign +magnitude</li>
</ul>
</li>
<li>
<p>one’s complement</p>
<ul>
<li>represent the value by use inverse value of Sign +magnitude</li>
</ul>
</li>
<li>
<p>two’s complement</p>
<ul>
<li>Use two’s complement to express integer</li>
</ul>
</li>
<li>
<p><strong>biased</strong></p>
</li>
</ul>
<hr>
<h4 id="sign-magnitude">Sign-magnitude</h4>
<ul>
<li>
<p><strong>Left most bit is sign bit</strong></p>
</li>
<li>
<p><strong>0 means positive</strong></p>
</li>
<li>
<p><strong>1 means negative</strong></p>
</li>
</ul>
<p>$$
+18=00010010\newline
-18=10010010\newline
$$</p>
<hr>
<p>$$
A=\begin{cases}
\sum_{i=0}^{n-2}2^ia_i\ if\ a_{n-1}=0\newline
-\sum_{i=0}^{n-2}2^ia_i\ if\ a_{n-1}=1\newline
\end{cases}
$$</p>
<p>$The\ number\ of\ bits\ is\ n\rightarrow Range: [-(2^{n-1}-1),2^{n-1}-1]\newline$</p>
<ul>
<li>
<p>Problems</p>
<ul>
<li>
<p>Need to consider <strong>both sign and magnitude</strong> in arithmetic</p>
</li>
<li>
<p><strong>Two representations of zero (+0 and -0)</strong></p>
<ul>
<li>1000000(-0)</li>
<li>0000000(+0)</li>
</ul>
</li>
<li>
<p><strong>Two methods are required to judge 0</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="ones-complement---">One’s complement ! ! !</h4>
<ul>
<li>
<p>Historically important, and we use this representation to get 2’s complement integers</p>
</li>
<li>
<p><strong>positive integers use the same representation as unsigned</strong></p>
</li>
<li>
<p><strong>Negation is done by taking a bitwise complement of the positive representation</strong></p>
</li>
</ul>
<p>$$
Example:-3:0011\rightarrow 1100\newline
&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;\newline
\begin{align}
&amp;11100000:a\ negative\ number\newline
&amp;To\ find\ out\ the\ value,invert\ each\ bit\ 00011111\ is\ +31\ by\ sight,\newline
&amp;so\ 11100000=-31
\end{align}
$$</p>
<ul>
<li><strong>The 1’s complement number system using N bits has a range from</strong> $-(2^{N-1}-1)\ to\ +(2^{N-1}-1)\newline$</li>
</ul>
<p>$$
\begin{align}
&amp;8-bit\ examples\newline
&amp;1111\ 1110\rightarrow 0000\ 0001\rightarrow -1\newline
&amp;1111\ 1111\rightarrow 0000\ 0000\rightarrow -0\newline
&amp;0000\ 0000\rightarrow +0\newline
&amp;0000\ 0001\rightarrow +1\newline
\end{align}
$$</p>
<ul>
<li>
<p><strong>The two forms of zero are represented by</strong></p>
</li>
<li>
<p>$0000\ 0000(all\ zeros)\newline$</p>
</li>
<li>
<p>$1111\ 1111(all\ ones)\newline$</p>
</li>
</ul>
<hr>
<h4 id="twos-complement---">Two’s complement ! ! !</h4>
<ul>
<li>
<p>Two’s complement is a variation on 1’s complement</p>
<ul>
<li><strong>Does NOT have 2 representations for 0</strong></li>
</ul>
</li>
<li>
<p>negative: (for example -5)</p>
<ul>
<li>
<p>Take the positive value 00101 (+5)</p>
</li>
<li>
<p>Take the 1‘s complement 11010 (-5 in 1’s comp)</p>
</li>
<li>
<p>Add 1: 11011</p>
</li>
</ul>
</li>
</ul>
<p>$$
A=-2^{n-1}a_{n-1}+\sum^{n-2}_{i=0}2^ia_i\newline
$$</p>
<p><strong>Benefits</strong></p>
<ul>
<li>
<p>One representation of zero</p>
</li>
<li>
<p>Arithmetic works easily</p>
</li>
<li>
<p>Negating is fairly easy</p>
</li>
<li>
<p>Example: -3</p>
</li>
</ul>
<p>$$
(3)_{10}=(00000011)_2\newline
Boolean\ complement\ gives:11111100\newline
Add\ 1\ to\ LSB:11111101\newline
$$</p>
<p>$$
\begin{align}
&amp;One\ representation\ of\ zero\newline
&amp;0=00000000\newline
&amp;Bitwise\ not=11111111\newline
&amp;Add\ 1\ to\ LSB:+1\newline
&amp;Result:1\ 00000000\newline
&amp;Overflow\ is\ ignored\ so \rightarrow -0=0
\end{align}
$$</p>
<p><strong>Negation Special Case</strong>
$$
\begin{align}
&amp;-128=10000000\newline
&amp;-(-128)is:\newline
&amp;1. bitwise\ not:01111111\newline
&amp;2. Add\ 1\ to\ LSB:+1\newline
&amp;3. Result:10000000\newline
&amp;\rightarrow -(-128)=-128\newline
&amp;??? \rightarrow\ \times\ \newline
\end{align}
$$</p>
<p><strong>In two ‘s complement notation, the range of positive and negative numbers is not completely symmetric</strong></p>
<p><strong>Range of numbers</strong></p>
<p>$The\ number\ of\ bits\ is\ n\rightarrow Range: [-2^{n-1},2^{n-1}-1]\newline$</p>
<h4 id="sign-extension">Sign extension</h4>
<ul>
<li>For <strong>sign magnitude number</strong>, simply move the sign bit to the new leftmost position and fill in with zeros</li>
</ul>
<p>$$
+18=00010010 \rightarrow extension : 00000000\ 00010010\newline
-18=10010010 \rightarrow extension : 10000000\ 00010010\newline
$$</p>
<ul>
<li>
<p>It is not going to work for two’s complement</p>
</li>
<li>
<p>The rule for <strong>two’s complement</strong> number is</p>
<ul>
<li>Positive number pack with leading zeros
$$
+18=00010010 \rightarrow extension :  00000000\ 00010010\newline
$$</li>
<li>Negative numbers pack with leading ones
$$
-18=10010010 \rightarrow extension : 11111111\ 10010010\newline
$$</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Characteristics of Two’s Complement</strong></p>
<table>
<thead>
<tr>
<th>特点</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>范围</td>
<td>$[-2^{n-1},2^{n-1}-1]$</td>
</tr>
<tr>
<td>0的表示方法</td>
<td>只有1个0的表示法</td>
</tr>
<tr>
<td>计算方法</td>
<td>按位取反后，在最后一位加1，可以得到这个数的相反数的补码</td>
</tr>
<tr>
<td>位的扩展</td>
<td>用符号位进行填充</td>
</tr>
<tr>
<td>溢出规则</td>
<td>如果2个相同符号的数相加，得到的新数的符号位和原数的符号位不一样，就是溢出</td>
</tr>
<tr>
<td><strong>减法规则</strong></td>
<td><strong>取减数的补码，然后和被减数相加</strong></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h3 id="integer-arithmetic">Integer Arithmetic</h3>
<h4 id="addition-and-subtraction">Addition and Subtraction</h4>
<ul>
<li>
<p>Addition</p>
<ul>
<li>
<p>Normal binary addition</p>
</li>
<li>
<p>Monitor sign bit for overflow</p>
</li>
</ul>
</li>
<li>
<p><strong>Subtraction</strong></p>
<ul>
<li>
<p><strong>Take twos compliment of subtrahend and add to minuend</strong></p>
</li>
<li>
<p>$a-b=a+(-b)\newline$</p>
</li>
</ul>
</li>
<li>
<p><strong>So only need addition and complement circuits</strong></p>
</li>
<li>
<p>Straight forward approach consists of adding each bit together from right to left and propagating the carry from one bit to the</p>
</li>
</ul>
<p>$$
\begin{align}
Example:&amp;\newline
&amp;-7_{10}+5_{10}=1001_{2}+0101_{2}=1110_{2}=-2_{10}\newline
&amp;3_{10}+4_{10}=0011_{2}+0100_{2}=0111_{2}=7_{10}\newline
\end{align}
$$</p>
<hr>
<p><strong>Geometric Depiction of Twos Complement Integers</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-1.png" title="/img/Computer Organization and Architecture/chapter9-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-1.png">
        
    </a>
<ul>
<li>
<p>圆周上列出了$4bit$的数表示的16种情况，从0000到1111</p>
</li>
<li>
<p>中间有一个对称轴，一个数的相反数就是它针对中间的对称轴的对称点</p>
</li>
<li>
<p>可以看到1000没有对称点，所以只有-8而没有+8的表示</p>
</li>
<li>
<p>对于加法，就是顺时针移动；而对于减法，就是逆时针移动</p>
</li>
<li>
<p>无论是顺时针移动，还是逆时针移动，如果越过了正负的交接点，就表示有溢出</p>
</li>
</ul>
<hr>
<p><strong>Judgment of overflow</strong></p>
<ul>
<li>
<p>For different representations, the judgment methods of overflow are different</p>
</li>
<li>
<p>For example: 01111101+01111101 = 1 1111010</p>
<ul>
<li>
<p>For unsigned addition, no overflow</p>
</li>
<li>
<p>For signed addition, overflow</p>
</li>
</ul>
</li>
<li>
<p>Another example: 11111101+01111101 = （1）01111010</p>
<ul>
<li>
<p>For unsigned addition, overflow</p>
</li>
<li>
<p>For signed addition, no overflow</p>
</li>
</ul>
</li>
<li>
<p>Carry is not a flag to judge overflow</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>No overflow when adding a positive and a negative number</strong></p>
</li>
<li>
<p><strong>No overflow when signs are the same for subtraction</strong></p>
</li>
<li>
<p><strong>Judgment method for two’s complement addition</strong></p>
<ul>
<li>
<p><strong>When two numbers with the same sign are added, the sign bit of the result is opposite, which must be overflow</strong></p>
</li>
<li>
<p><strong>Subtraction is completed by addition, and the method to judge overflow is the same</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Hardware for Addition and Subtraction</strong></p>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-2.png" title="/img/Computer Organization and Architecture/chapter9-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-2.png" data-sub-html="<h2>Hardware</h2>">
        
    </a><figcaption class="image-caption"><code>Hardware</code></figcaption>
    </figure>
<ul>
<li>
<p>核心是一个加法器。寄存器A和B是加法器的输入</p>
</li>
<li>
<p>计算的结果保存在寄存器A中，如果有溢出，则溢出标志保存在OF中</p>
</li>
<li>
<p>SW开关控制是加法还是减法。如果是加法，B寄存器的数直接输入到加法器中；如果是减法，则B寄存器的数据通过一个补码器生成它的相反数的补码，再输入到加法器中</p>
</li>
</ul>
<h4 id="multiplication">Multiplication</h4>
<ul>
<li>
<p>Much more complex than addition</p>
</li>
<li>
<p>Multiply each bit of the multiplier by the multiplicand to get the partial product</p>
</li>
<li>
<p>calculation of partial product should also take into account the position of the multiplying digit</p>
</li>
<li>
<p>Add all partial products to get the product</p>
</li>
<li>
<p>It’s similar to our manual multiplication</p>
</li>
<li>
<p>Involves the generation of partial products</p>
<ul>
<li>
<p>Equals 0 when the multiplier bit is 0</p>
</li>
<li>
<p>Equals the multiplicand when the multiplier is 1</p>
</li>
<li>
<p>Easier than decimal multiplication</p>
</li>
</ul>
</li>
<li>
<p>The total product is produced by summing the shifted partial products</p>
</li>
<li>
<p><strong>Two n binary number may result in a product of up to 2n bits in length</strong></p>
</li>
</ul>
<p>Example
$$
\begin{align}
&amp;1011\newline
\times&amp;1101\newline
&amp;\rule[-10pt]{5cm}{0.03em}\newline
&amp;1011\newline
0&amp;000\newline
10&amp;11\newline
101&amp;1\newline
&amp;\rule[-10pt]{5cm}{0.03em}\newline
&amp;10001111
\end{align}
$$
Note: 结果需要双倍的比特位</p>
<h5 id="shift-operation--">Shift operation! ! !</h5>
<ul>
<li>
<p>A shift operation is involved in multiplication</p>
</li>
<li>
<p><strong>Any number multiplied by 2 n results the number shifted left by n bits</strong></p>
<ul>
<li>
<p>0000 0001 x 00000010 = 0000 0010</p>
</li>
<li>
<p>0000 0001 x 00000100 = 0000 0100</p>
</li>
<li>
<p>0000 0001 x 00001000 = 0000 1000</p>
</li>
</ul>
</li>
</ul>
<h5 id="unsigned-binary-multiplication">Unsigned binary multiplication</h5>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-3.png" title="/img/Computer Organization and Architecture/chapter9-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-3.png">
        
    </a>
<ul>
<li>
<p>核心是一个n位加法器</p>
</li>
<li>
<p>先取乘数的最低位$Q_0$。如果是1，则将被乘数送到加法器中。如果是0，则不进行加法。</p>
</li>
<li>
<p>加法器将A和M相加，然后向右移位。有一个移位的寄存器C，用于保存进位</p>
</li>
<li>
<p><strong>移位后，继续进行</strong>$Q_1$<strong>的判断，然后相加，移位。这样直到所有的Q都计算完成，这样就可以得到无符号的乘法结果</strong></p>
</li>
</ul>
<p>Example</p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-4.png" title="/img/Computer Organization and Architecture/chapter9-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-4.png">
        
    </a>
<ul>
<li>
<p>初始值C为0，A寄存器为0，乘数为1101，被乘数位1011</p>
</li>
<li>
<p>先取乘数的最低位$Q_0$。<strong>如果是1，则将被乘数送到加法器中。如果是0，则不进行加法</strong></p>
</li>
<li>
<p>第一步，乘数最后一位是1，A和M相加后，得到A为1011。然后移位(<strong>A最低位移向了Q的最高位，多出来的高位用0来补齐</strong>)，A和Q寄存器就变成了：0101 1110</p>
</li>
<li>
<p>第二步，乘数最后一位是0，A不变，然后移位，A和Q寄存器就变成了：0010 1111</p>
</li>
<li>
<p>第三步，乘数最后一位是1，将A和M相加，得到1101。然后移位，得到A和Q寄存器变成了：0110 1111</p>
</li>
<li>
<p>第四步，乘数最后一位是1，A和M相加，得到10001。产生了一个进位。然后移位，进位也右移到A的最高位。得到A和Q寄存器变成了：1000 1111</p>
</li>
</ul>
<p><strong>Summary</strong></p>
<ul>
<li>
<p>三个寄存器A、Q和M。其中A用于存放结果的高位，初始化为0。Q初始化为乘数，M初始化为被乘数。还有一个进位标志C。n表示计算次数</p>
</li>
<li>
<p>先检查$Q_0$，如果为1，将A和M相加，放到C，A。然后将C、A、Q右移一位。同时n-1，表示完成了1次计算</p>
</li>
<li>
<p>如果n不为0，继续进行$Q_0$的检测和计算。直到n为0</p>
</li>
<li>
<p><strong>结果保存在A和Q中。A为高位，Q为低位</strong></p>
</li>
</ul>
<h5 id="multiplying-negative-numbers--">Multiplying negative numbers! ! !</h5>
<ul>
<li>
<p>Solution 1</p>
<ul>
<li>
<p>Convert to positive if required</p>
</li>
<li>
<p>Multiply as above</p>
</li>
<li>
<p>If signs were different, negate answer</p>
</li>
<li>
<p>Convert to two’s complement</p>
</li>
<li>
<p>It’s the same way we do multiplication. Regardless of the sign bit, multiply, and then determine the sign of the result</p>
</li>
</ul>
</li>
<li>
<p><strong>Solution 2</strong></p>
<ul>
<li>
<p><strong>Booth’s algorithm</strong></p>
</li>
<li>
<p><strong>Not only solves the problem, but also improves the efficiency</strong></p>
</li>
</ul>
</li>
</ul>
<h5 id="booths-algorithm--">Booth’s algorithm! ! !</h5>
<ul>
<li>In particular, consider a positive multiplier consisting of one block of 1s surrounded by 0s</li>
</ul>
<p>Example
$$
\begin{align}
M \times (00011110)_2=&amp;M \times (2^4+2^3+2^2+2^1)\newline
=&amp;M \times (16+8+4+2)\newline
=&amp;M \times 30\newline
\end{align}
$$</p>
<p>$$
2^n+2^{N-1}+\dots+2^{n-K}=2^{n+1}-2^{n-K}
$$</p>
<p>$$
\begin{align}
M \times (00011110)_2&amp;=M \times (2^5-2^1)\newline
&amp;=M \times 30\newline
\end{align}
$$</p>
<ul>
<li>
<p><strong>For a binary number, we cannot require all its 1s to be connected together. What should we do？</strong></p>
</li>
<li>
<p><strong>Use the idea of segmentation. Make the connected 1 into a block</strong></p>
</li>
<li>
<p><strong>If single 1 is surrounded by 0, a single 1 is also a block</strong></p>
</li>
</ul>
<p>$$
\begin{align}
M \times (01111010)_2&amp;=M \times (2^6 + 2^5 + 2^4 + 2^3 + 2^1)\newline
&amp;=M \times (2^7 - 2^3 + 2^2-2^1)\newline
\end{align}
$$</p>
<ul>
<li>
<p><strong>Booth’s algorithm makes use of this rule. For continuous 1, it need not calculate, but only at the beginning and end</strong></p>
</li>
<li>
<p><strong>When 10 is encountered , subtraction is performed</strong></p>
</li>
<li>
<p><strong>When 01 is encountered , addition is performed</strong></p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-5.png" title="/img/Computer Organization and Architecture/chapter9-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-5.png">
        
    </a>
<ul>
<li><strong>For continuous 1, it only needs to be calculated at the beginning and end to improve the calculation efficiency</strong></li>
</ul>
<p>$$
M \times (01111110)_2=M \times (2^7-2^0)\newline
$$</p>
<ul>
<li><strong>The worst case is that 0 and 1 alternate, so each time you need to calculate</strong></li>
</ul>
<p>$$
M \times (01010101)_2=M \times (2^7-2^6+2^5-2^4+2^3-2^2+2^1-2^0)\newline
$$</p>
<hr>
<p><strong>Diagram of Booth’s algorithm</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-6.png" title="/img/Computer Organization and Architecture/chapter9-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-6.png">
        
    </a>
<ul>
<li>
<p>A寄存器保存结果的高位，Q寄存器保存乘数和结果的低位，M寄存器保存被乘数。$Q_{-1}$寄存器保存上一个乘数数字。初始化时A和$Q_{-1}$均为0</p>
</li>
<li>
<p>开始计算，如果$Q_0$和$Q_{-1}$是<strong>11或00</strong>，A和Q以及$Q_{-1}$<strong>不处理</strong>，直接移位</p>
</li>
<li>
<p>如果$Q_0$和$Q_{-1}$是<strong>10，减去</strong>M，然后进行移位</p>
</li>
<li>
<p>如果$Q_0$和$Q_{-1}$是<strong>01</strong>，<strong>加上</strong>M，然后进行移位</p>
</li>
<li>
<p>A、Q和$Q_{-1}$右移的时候，A的最高位往下移位时,<strong>最高位不是补0，而是将原来的最高位保留，也就是保留符号位</strong></p>
</li>
<li>
<p>移位之后，继续判断$Q_0$和$Q_{-1}$，直到所有的位数都处理完毕</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Can the Booth’s algorithm just discussed solve the multiplication problem of negative numbers?</p>
<ul>
<li>
<p>Yes</p>
</li>
<li>
<p>关键点：符号位也进行了移位</p>
</li>
</ul>
</li>
</ul>
<h4 id="division">Division</h4>
<h5 id="division-of-unsigned-binary-integers">Division of unsigned binary integers</h5>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-7.png" title="/img/Computer Organization and Architecture/chapter9-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-7.png">
        
    </a>
<ul>
<li>
<p>被除数的高4位都比除数小。到第五位，被除数是10010，比除数大，所以商位为1，然后减去除数，得到部分余数是111，继续下一位。直到被除数的最后一位</p>
</li>
<li>
<p>二进制的长除相对于10进制的长除简单一些。10进制的时候，因为商的每一位可能是0~9，所以我们还需要挨个儿去试，看商的每位是多大</p>
</li>
<li>
<p>对于二进制，商的每一位只能是0或者1，所以只需要对比被除数和除数的大小</p>
</li>
<li>
<p>结果包括商和余数</p>
</li>
</ul>
<p><strong>Flowchart for Unsigned Binary Division</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-8.png" title="/img/Computer Organization and Architecture/chapter9-8.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-8.png">
        
    </a>
<ul>
<li>
<p>除数在M寄存器中，被除数放在Q寄存器中。A的初始值为0，保存被除数的部分余数</p>
</li>
<li>
<p>每一次，先将A和Q进行移位，然后检查A和M的大小，<strong>用无符号减法来比较。如果A大于M，当前的余数可以减去M，得到一个商位为1，放在</strong>$Q_0$<strong>。如果A比M小，则</strong>$Q_0$<strong>为0，同时A恢复成减去M之前的值</strong></p>
</li>
<li>
<p>然后继续移位(<strong>A与Q同时进行左移,类比乘法中的整体移位</strong>)并比较。一直到被除数的所有位都用完</p>
</li>
<li>
<p><strong>最后得到的商在Q寄存器中，余数保存在A寄存器中</strong></p>
</li>
</ul>
<h3 id="floating-point-representation">Floating-Point Representation</h3>
<h4 id="real-numbers">Real numbers</h4>
<ul>
<li>
<p>Real number: number with fractions</p>
</li>
<li>
<p>Could be represent in pure binary</p>
</li>
</ul>
<p>$$
1001.1010=2^4+2^0+2^{-1}+2^{-3}=9.625
$$</p>
<h4 id="scientific-notation">Scientific Notation</h4>
<ul>
<li>
<p>In decimal, large numbers are represented by scientific notation</p>
</li>
<li>
<p>Use a mantissa to multiply by the power of 10</p>
</li>
</ul>
<p>$$
6.02_{10}\times 10^{23}
$$</p>
<ul>
<li>
<p>The same in binary</p>
</li>
<li>
<p>Represent a large binary number by multiplying the mantissa and the power of 2</p>
</li>
<li>
<p>Representation consists of three parts: <strong>sign bit, significant value and exponent</strong></p>
</li>
</ul>
<h4 id="floating-point">Floating point</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-9.png" title="/img/Computer Organization and Architecture/chapter9-9.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-9.png">
        
    </a>
<ul>
<li>
<p><strong>Floating point representation</strong></p>
<ul>
<li>
<p><strong>Symbol represented by 0 or 1</strong></p>
</li>
<li>
<p><strong>Exponent of biased notation</strong></p>
</li>
<li>
<p><strong>Valid value, that is, the mantissa of the number</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Binary point is the first place on the right of the highest significant value</strong></p>
</li>
</ul>
<hr>
<p><strong>Exponent! ! !</strong></p>
<ul>
<li>How to use biased notation?
<ul>
<li>For a k bit exponent,the bias is $2^{k-1}-1(exponent\ add\ \underbrace{0111111\dots111}_{k\ bits})\newline$</li>
<li>actual exponent range is: $[-(2^{k-1}-1),2^{k-1}]\newline$</li>
<li><strong>The bias is added to the actual exponent to get the stored exponent</strong></li>
</ul>
</li>
</ul>
<hr>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-10.png" title="/img/Computer Organization and Architecture/chapter9-10.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-10.png">
        
    </a>
<p>Example</p>
<ul>
<li>
<p>$-1.1010001 \times 2^{10100}\newline$</p>
</li>
<li>
<p>Sign: 1</p>
</li>
<li>
<p>Exponent: $\underbrace{01111111}_{bias}+\overbrace{10100}^{exponment}=10010011\newline$</p>
</li>
<li>
<p>Significand: 101 0001 0000 0000 0000 0000</p>
</li>
<li>
<p>The floating point representation for above number: 1 10010011 10100010000000000000000</p>
</li>
</ul>
<h4 id="normalization">Normalization</h4>
<ul>
<li>
<p>To simplify operations on floating-point numbers, it is required to normalize the number</p>
</li>
<li>
<p>How to normalize?</p>
<ul>
<li>
<p>The leftmost bit of the significand is 1</p>
<ul>
<li>e.g: $1.xxxxx \times 2^k\newline$</li>
</ul>
</li>
<li>
<p><strong>Because the most significand bit is always one, it is unnecessary to store this bit – implicit</strong></p>
</li>
<li>
<p><strong>23-bit field is used to store a 24-bit significant</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="floating-point-range-and-accuracy">Floating point range and accuracy</h4>
<ul>
<li>
<p>For a 32 bit number</p>
<ul>
<li>8 bit exponent， up to 128</li>
<li>$+|-2^{128}\approx1.0 \times 10^{39}\newline$</li>
</ul>
</li>
<li>
<p>Accuracy</p>
<ul>
<li>
<p>The effect of changing <code>lsb</code> of mantissa</p>
</li>
<li>
<p>23 bit mantissa $2^{-23}\approx 1.2 \times 10^{-7}\newline$</p>
</li>
<li>
<p>About 6 decimal places</p>
</li>
</ul>
</li>
<li>
<p><strong>Because total bits of floating point numbers is fixed, the range and accuracy are contradictory</strong></p>
</li>
</ul>
<hr>
<p><strong>Density of floating point numbers</strong></p>
<ul>
<li>
<p>For fixed-point numbers, the numbers are spaced evenly</p>
</li>
<li>
<p>For float-point notation, the numbers are not evenly spaced</p>
<ul>
<li>
<p>The length of exponent is fixed</p>
</li>
<li>
<p>As the number is getting bigger, the space between two numbers is bigger</p>
</li>
</ul>
</li>
</ul>
<h4 id="ieee-754">IEEE 754</h4>
<ul>
<li>
<p>Standard for floating point storage</p>
</li>
<li>
<p>32 and 64 bit standards</p>
</li>
<li>
<p><strong>32 bits standard</strong></p>
<ul>
<li><strong>8 bits exponent , 23 bits significand</strong></li>
</ul>
</li>
<li>
<p><strong>64 bits standard</strong></p>
<ul>
<li><strong>11 bits exponent , 52 bits significand</strong></li>
</ul>
</li>
<li>
<p>Extended formats (both mantissa and exponent) for intermediate results</p>
</li>
</ul>
<h4 id="special-about-ieee-754-formats">Special about IEEE 754 formats</h4>
<ul>
<li>
<p>Extreme value of the exponent to define a particular value</p>
</li>
<li>
<p>Exponent after bias is 2047, that is, all 1, indicating infinity</p>
</li>
<li>
<p>The actual range is smaller than the ideal range</p>
</li>
<li>
<p>For negative, the range is $[-(2-2^{-52}) \times 2^{1023},2^{-1022}]\newline$</p>
</li>
<li>
<p>For positive, the range is $[2^{-1022},(2-2^{-52}) \times 2^{1023}]\newline$</p>
</li>
</ul>
<h3 id="floating-point-arithmetic">Floating-Point Arithmetic</h3>
<h4 id="floating-point-arithmetic--">Floating point arithmetic +/-</h4>
<ul>
<li>
<p>Addition and subtraction of floating point numbers must first ensure that the exponent are the same</p>
</li>
<li>
<p>How to do this？ Move the binary point position of the valid value of the operand</p>
</li>
<li>
<p><strong>Steps for addition and subtraction floating point numbers</strong></p>
<ul>
<li>
<p><strong>Check for zeros</strong></p>
</li>
<li>
<p><strong>Align significands (adjusting exponents)</strong></p>
</li>
<li>
<p><strong>Add or subtract significands</strong></p>
</li>
<li>
<p><strong>Normalize result</strong></p>
</li>
</ul>
</li>
</ul>
<p>Example
$$
\begin{gather}
1.011 \times 2^5+1.001 \times 2^3\newline
Align\ significands \rightarrow 1.001 \times 2^3=0.0101 \times 2^5\newline
Add\ or\ subtract\ significands \rightarrow 1.001+0.0101=1.1011\newline
Normalize\ result \rightarrow result=1.1011 \times 2^5\newline
\end{gather}
$$
<strong>FP Addition &amp; Subtraction Flowchart</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-11.png" title="/img/Computer Organization and Architecture/chapter9-11.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-11.png">
        
    </a>
<h4 id="floating-point-arithmetic-timesbackslashdiv">Floating point arithmetic $\times\backslash\div$</h4>
<ul>
<li>
<p>Multiplication and division are simpler than addition and subtraction</p>
</li>
<li>
<p><strong>Steps:</strong></p>
<ul>
<li>
<p><strong>Check for zero</strong></p>
</li>
<li>
<p><strong>Add/subtract exponents</strong></p>
</li>
<li>
<p><strong>Multiply/divide significands (watch sign)</strong></p>
</li>
<li>
<p><strong>Normalize</strong></p>
</li>
<li>
<p><strong>Round</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>All intermediate results should be in double length storage</strong></p>
</li>
</ul>
<hr>
<p><strong>Floating point multiplication</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-12.png" title="/img/Computer Organization and Architecture/chapter9-12.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-12.png">
        
    </a>
<p><strong>Floating point division</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter9-13.png" title="/img/Computer Organization and Architecture/chapter9-13.png" data-thumbnail="/img/Computer Organization and Architecture/chapter9-13.png">
        
    </a>
<p>Example:
$$
\begin{gather}
(1.001 \times 2^5) \times (1.001 \times 2^3)\newline
Check\ for\ zeros:no\ zero\newline
Add/subtract\ exponents\rightarrow5+3=8=(1000)_2\newline
Multiply/divide\ significands\rightarrow1.011\times1.001=1.100011\newline
Normalize\ result \rightarrow result=1.100011 \times 2^8\newline
Round \rightarrow 1.100011 \times 2^8\approx 1.100 \times 2^8\newline
\end{gather}
$$</p>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Operating System</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-operating-system/</link>
    <pubDate>Sun, 22 Jan 2023 17:47:46 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-operating-system/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="operating-system-support">Operating System Support</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>Operating System Overview</p>
</li>
<li>
<p>Scheduling</p>
</li>
<li>
<p>Memory Management</p>
</li>
</ul>
<h3 id="operating-system-overview">Operating System Overview</h3>
<ul>
<li>什么是操作系统</li>
</ul>
<blockquote>
<p>操作系统是一组主管并控制计算机操作、运用和运行硬件、软件资源和提供公共服务来组织用户交互的相互关联的系统软件程序。根据运行的环境，操作系统可以分为桌面操作系统，手机操作系统，服务器操作系统，嵌入式操作系统等</p>
</blockquote>
<ul>
<li>有哪些常用的操作系统
<ul>
<li>DOS</li>
<li>windows</li>
<li>UNIX</li>
<li>Linux</li>
<li>OS/2</li>
<li>IOS,Android</li>
<li>Mac OS</li>
</ul>
</li>
</ul>
<h4 id="operating-system-objectives-and-functions">Operating System Objectives and Functions</h4>
<ul>
<li>
<p><strong>Operating system, or OS for short, is a computer program that manages computer hardware and software resources</strong></p>
</li>
<li>
<p>The operating system deals with such basic matters as</p>
<ul>
<li>
<p><strong>managing and configuring memory</strong></p>
</li>
<li>
<p><strong>determining the priority of system resource supply and demand</strong></p>
</li>
<li>
<p><strong>controlling input devices and output devices</strong></p>
</li>
<li>
<p><strong>operating networks and managing file systems</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>The operating system also provides an operation interface for users to interact with the system</strong></p>
</li>
</ul>
<h5 id="objectives-and-functions">Objectives and Functions</h5>
<ul>
<li>
<p>A system program developed to improve resource utilization and enhance computer system performance</p>
</li>
<li>
<p>Convenience</p>
<ul>
<li>
<p>Shields the details of computer hardware</p>
</li>
<li>
<p>Provides convenient interfaces for users</p>
</li>
<li>
<p>Making the computer easier to use</p>
</li>
</ul>
</li>
<li>
<p>Efficiency</p>
<ul>
<li>
<p>Process scheduling</p>
</li>
<li>
<p>Memory management</p>
</li>
<li>
<p>Fully exploit the power of computer</p>
</li>
</ul>
</li>
</ul>
<h5 id="characteristic">Characteristic</h5>
<ul>
<li>
<p>The most fundamental system program is the operating system</p>
<ul>
<li>
<p>Provides an interface between the user and the computer</p>
</li>
<li>
<p>Manages the computer resources</p>
</li>
<li>
<p>Provides an environment for the application program execution</p>
</li>
<li>
<p>Improves the efficiency and stability of program execution</p>
</li>
</ul>
</li>
</ul>
<h5 id="layers-of-a-computer-system">Layers of a Computer System</h5>
<ul>
<li>
<p>系统软件是指控制和协调计算机及外部设备,支持应用软件开发和运行的系统，主要功能是调度，监控和维护计算机系统</p>
</li>
<li>
<p>系统软件包括操作系统和一系列基本的工具，比如编译器，数据库管理，存储器格式化，文件系统管理等，支持计算机系统正常运行并实现用户操作</p>
</li>
<li>
<p>操作系统是最重要的系统软件，位于硬件和工具之间</p>
</li>
<li>
<p>使得上层方便地访问和使用计算机系统提供的资源和服务</p>
</li>
</ul>
<h5 id="operating-system-services">Operating system services</h5>
<ul>
<li>
<p>Program creation</p>
</li>
<li>
<p>Program execution</p>
</li>
<li>
<p>Access to I/O devices</p>
</li>
<li>
<p>Controlled access to files</p>
</li>
<li>
<p>System access</p>
</li>
<li>
<p>Error detection and response</p>
</li>
<li>
<p>Accounting</p>
</li>
</ul>
<h5 id="os-as-a-resource-management">OS as a resource management</h5>
<ul>
<li>
<p>操作系统是一个计算机程序，执行也是由处理器来进行，通过给处理器提供一系列指令，来执行操作系统程序</p>
</li>
<li>
<p><strong>操作系统不能一直占用了处理器，而是需要放弃对处理器的控制，让处理器去执行应用程序</strong>。之后，它再次获得控制权，为下一个应用程序的执行进行准备(System Call)</p>
</li>
<li>
<p><strong>操作系统有一部分驻留在内存中，称为操作系统内核</strong></p>
</li>
<li>
<p>操作系统还要对I/O的使用进行分配</p>
</li>
</ul>
<h4 id="types-of-operating-systems">Types of Operating Systems</h4>
<p><strong>Operating system support batch processing or not?</strong></p>
<ul>
<li>
<p>Interactive</p>
<ul>
<li>
<p>User usually interacts with the computer by keyboard or display</p>
</li>
<li>
<p>Request to execute jobs or process transactions</p>
</li>
</ul>
</li>
<li>
<p>Batch</p>
<ul>
<li>
<p>Multiple user programs are packaged and submits to the computer in batches for processing</p>
</li>
<li>
<p>After processing, print the results</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Support multiple programs or not?</strong></p>
<ul>
<li>
<p>Single program (<code>Uni</code>-programming)</p>
<ul>
<li>Processor can only process one program at a time</li>
</ul>
</li>
<li>
<p>Multi-programming (Multi-tasking)</p>
<ul>
<li>
<p>Processor can process multiple programs at one time</p>
</li>
<li>
<p>Multiple programs loaded into memory at the same time</p>
</li>
<li>
<p>processor switches between programs and processes</p>
</li>
</ul>
</li>
</ul>
<h5 id="memory-layout-for-resident-monitor">Memory layout for resident monitor</h5>
<ul>
<li>
<p>多程序批量处理系统中，内存划分为监控程序和用户程序两个区域</p>
<ul>
<li>
<p>监控程序包括：中断处理，设备驱动程序，作业排序，控制语言解释器</p>
</li>
<li>
<p>通过监控程序，实现了作业的调度</p>
</li>
</ul>
</li>
<li>
<p>用户程序提交之后，就可以按照顺序处理，不会浪费处理器</p>
</li>
</ul>
<h5 id="required-hardware-support">Required hardware support</h5>
<ul>
<li>
<p>Memory protection</p>
<ul>
<li>To protect the Monitor</li>
</ul>
</li>
<li>
<p>Timer</p>
<ul>
<li>To prevent a job monopolizing the system</li>
</ul>
</li>
<li>
<p>Privileged instructions</p>
<ul>
<li>Only executed by Monitor</li>
<li>e.g. I/O</li>
</ul>
</li>
<li>
<p>Interrupts</p>
<ul>
<li>Allows operation system for relinquishing and regaining control</li>
</ul>
</li>
</ul>
<h5 id="multi-programmed-batch-system">Multi-programmed batch system</h5>
<ul>
<li>
<p>Batch system performs monitoring and user programs <strong>in turn</strong>, which improves the utilization of the whole system</p>
</li>
<li>
<p>I/O devices very slow</p>
</li>
<li>
<p>Processors are also often idle</p>
</li>
<li>
<p><strong>Multi-programmed batch systems</strong></p>
<ul>
<li>
<p><strong>Memory load multiple user programs</strong></p>
</li>
<li>
<p><strong>When one program is waiting for I/O, another can use the CPU</strong></p>
</li>
<li>
<p><strong>CPU keeps working</strong></p>
</li>
<li>
<p><strong>Core idea of modern operation system</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>Single program</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-1.png" title="/img/Computer Organization and Architecture/chapter8-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-1.png">
        
    </a>
<p><strong>Multi-Programming with two programs</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-2.png" title="/img/Computer Organization and Architecture/chapter8-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-2.png">
        
    </a>
<p><strong>Multi-Programming with three programs</strong></p>
<ul>
<li>
<p>同时有三个程序处于执行状态</p>
</li>
<li>
<p>CPU等待状态的时间更少</p>
</li>
<li>
<p>CPU效率更高</p>
</li>
</ul>
<p><strong>Utilization</strong></p>
<ul>
<li>
<p>单个程序逐个执行，总共需要30个时间单位</p>
</li>
<li>
<p>多道程序同时执行，只需要15个时间单位</p>
</li>
<li>
<p>节省了一半时间</p>
</li>
</ul>
<h5 id="time-sharing-systems">Time sharing systems</h5>
<ul>
<li>
<p><strong>Multi-programmed batch system</strong></p>
<ul>
<li>
<p><strong>Improve the efficiency of system operation</strong></p>
</li>
<li>
<p><strong>Disadvantage is that the response to users is not timely</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>For multiple interactive job scenarios, a time-sharing system is proposed</strong></p>
<ul>
<li>
<p><strong>Multiple users to share processor time and interact with the processor</strong></p>
</li>
<li>
<p><strong>Operating system responds to each user&rsquo;s request in time slices computer</strong></p>
</li>
<li>
<p><strong>For each user, he thinks the processor only serves him</strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="scheduling">Scheduling</h3>
<ul>
<li>
<p><strong>Key to multi-programming</strong></p>
</li>
<li>
<p><strong>Determines the efficiency of multiprogramming</strong></p>
</li>
<li>
<p>Includes long term, medium term, short term</p>
<ul>
<li>
<p><strong>Long term: determines the number of processes added to the pending process pool</strong></p>
</li>
<li>
<p><strong>Medium term: determines the number of processes added to main memory</strong></p>
</li>
<li>
<p><strong>Short term: decide which process the processor will execute</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="five-state-process-model">Five state process model</h4>
<div class="mermaid" id="id-1"></div>
<ul>
<li>
<p>新建状态：调度程序提交一个程序，操作系统为这个程序创建一个进程，并将进程移入就绪状态</p>
</li>
<li>
<p>就绪状态：进程已经准备就绪，等待处理器的执行</p>
</li>
<li>
<p>运行状态：进程正在由处理器执行</p>
</li>
<li>
<p>等待状态：进程在等待资源，处于挂起状态</p>
</li>
<li>
<p>终止状态：进程运行结束</p>
</li>
</ul>
<h4 id="what-is-process---">What is process? ! ! !</h4>
<ul>
<li>
<p><strong>A program in execution</strong></p>
<ul>
<li>
<p><strong>An instance of a program running on a computer</strong></p>
</li>
<li>
<p><strong>The entity that can be assigned to and executed on a processor</strong></p>
</li>
<li>
<p><strong>A unit of activity characterized by the execution of a sequence of instructions, a current state, and an associated set of system instructions</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="process-elements">Process elements</h4>
<ul>
<li>
<p>A process is comprised of</p>
<ul>
<li>
<p><strong>Program code (possibly shared)</strong></p>
</li>
<li>
<p><strong>A set of data</strong></p>
</li>
<li>
<p><strong>A number of attributes describing the state of the process</strong></p>
</li>
</ul>
</li>
<li>
<p>Process elements</p>
<ul>
<li>
<p><strong>Identifier</strong></p>
</li>
<li>
<p><strong>State</strong></p>
</li>
<li>
<p><strong>Priority</strong></p>
</li>
<li>
<p><strong>Program counter</strong></p>
</li>
<li>
<p><strong>Memory pointers</strong></p>
</li>
<li>
<p><strong>Context data</strong></p>
</li>
<li>
<p><strong>I/O status information</strong></p>
</li>
<li>
<p><strong>Accounting information</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="process-control-block">Process control block</h4>
<ul>
<li>
<p><strong>Contains the process elements</strong></p>
</li>
<li>
<p><strong>Created and manage by the operating system</strong></p>
</li>
<li>
<p><strong>Allows support for multiple processes</strong></p>
</li>
</ul>
<div class="mermaid" id="id-2"></div>
<h4 id="trace-of-the-process">Trace of the process</h4>
<ul>
<li>
<p>The behavior of an individual process is shown by listing the sequence of instructions that are executed</p>
<ul>
<li><strong>This list is called a Trace</strong></li>
</ul>
</li>
<li>
<p>Processor needs to execute multiple processes one by one</p>
<ul>
<li>
<p><strong>Dispatcher is responsible for scheduling the process</strong></p>
</li>
<li>
<p><strong>Dispatcher is a small program which switches the processor from one process to another</strong></p>
</li>
</ul>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-3.png" title="/img/Computer Organization and Architecture/chapter8-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-3.png" data-sub-html="<h2>trace</h2>">
        
    </a><figcaption class="image-caption"><code>trace</code></figcaption>
    </figure>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-4.png" title="/img/Computer Organization and Architecture/chapter8-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-4.png" data-sub-html="<h2>trace</h2>">
        
    </a><figcaption class="image-caption"><code>trace</code></figcaption>
    </figure>
<h4 id="virtual-memory">Virtual memory</h4>
<ul>
<li>
<p>虚拟存储器是内存管理的一种技术，允许程序从逻辑的角度对内存进行寻址，而不考虑物理上可用的内存空间</p>
</li>
<li>
<p><strong>本质上是一种内存扩充技术，不会使内存的物理空间大小发生改变，但是能够使程序访问内存的方式更灵活</strong></p>
</li>
<li>
<p><strong>由于虚拟内存的存在，所以程序中可以只将其中的一部分加载到物理内存中。只有当需要的程序段不在内存中的时候，才通过换页的方式将它加载到内存中</strong></p>
</li>
</ul>
<h4 id="execution-of-a-process">Execution of a process</h4>
<ul>
<li>
<p><strong>Entire program does not need to be loaded to memory</strong></p>
<ul>
<li>
<p><strong>Operating system brings into main memory a few pieces of the program</strong></p>
</li>
<li>
<p><strong>Resident set - portion of process that is in main memory</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>An interrupt is generated when an address is needed that is not in main memory</strong></p>
<ul>
<li><strong>Operating system places the process in a blocking state</strong></li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>Piece of process that contains the logical address is brought into main memory</strong></p>
<ul>
<li>
<p><strong>Operating system issues a disk I/O Read request</strong></p>
</li>
<li>
<p><strong>Another process is dispatched to run while the disk I/O takes place</strong></p>
</li>
<li>
<p><strong>An interrupt is issued when disk I/O complete which causes the operating system to place the affected process in the Ready state</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="implications-of-this-new-strategy">Implications of this new strategy</h4>
<ul>
<li>
<p>More processes may be maintained in main memory</p>
<ul>
<li>
<p>Only load in some of the pieces of each process</p>
</li>
<li>
<p>With so many processes in main memory, it is very likely a process will be in the Ready state at any particular time</p>
</li>
</ul>
</li>
<li>
<p>A process may be larger than all of main memory</p>
</li>
</ul>
<h4 id="wording-mode-of-os">Wording mode of OS</h4>
<ul>
<li>
<p><strong>操作系统中维护一个长期队列和一个短期队列</strong></p>
</li>
<li>
<p><strong>长期队列是等待系统资源的作业列表，短期队列包含所有就绪状态的进程</strong></p>
</li>
<li>
<p><strong>中断发生时，操作系统接管处理器的控制权，执行中断处理程序</strong></p>
</li>
<li>
<p><strong>进程调用服务时，操作系统执行服务调用处理程序</strong></p>
</li>
<li>
<p><strong>中断或服务调用程序处理完成后，短期调度会调度某个进程进入到运行状态</strong></p>
</li>
<li>
<p><strong>每个I/O设备有一个I/O队列</strong></p>
</li>
</ul>
<h5 id="process-scheduling---">Process scheduling ！ ！ ！</h5>
<ul>
<li>
<p><strong>进程请求进入长期队列</strong></p>
</li>
<li>
<p><strong>进程的请求满足后，进程进入就绪状态并进入短期队列</strong></p>
</li>
<li>
<p><strong>如果进程请求I/O，则进入I/O队列</strong></p>
</li>
<li>
<p><strong>I/O完成后，继续进入短期队列，完成进程的执行</strong></p>
</li>
</ul>
<h3 id="memory-management">Memory Management</h3>
<ul>
<li>
<p><strong><code>Uni</code>-program</strong></p>
<ul>
<li>
<p><strong>Memory split into two</strong></p>
</li>
<li>
<p><strong>One for Operating System (monitor)</strong></p>
</li>
<li>
<p><strong>One for currently executing program</strong></p>
</li>
</ul>
</li>
<li>
<p><strong><code>Multi</code>-program</strong></p>
<ul>
<li><strong>“User” part is sub-divided and shared among active processes</strong></li>
</ul>
</li>
<li>
<p>Memory management</p>
<ul>
<li>
<p>Make full use of the memory space</p>
</li>
<li>
<p>keep the CPU busy</p>
</li>
<li>
<p>avoid idle CPU due to IO waiting</p>
</li>
</ul>
</li>
</ul>
<h4 id="methods-of-memory-management">Methods of memory management</h4>
<ul>
<li>
<p>Swapping</p>
</li>
<li>
<p>Partitioning</p>
</li>
<li>
<p>Paging</p>
</li>
<li>
<p>Virtual Memory</p>
</li>
<li>
<p>Translation Lookaside Buffer</p>
</li>
<li>
<p>Segmentation</p>
</li>
</ul>
<h5 id="swapping">Swapping</h5>
<ul>
<li>
<p>Problem</p>
<ul>
<li>
<p><strong>I/O is so slow compared with CPU</strong></p>
</li>
<li>
<p>Even in multi-programming system，CPU is idle most of the time</p>
</li>
</ul>
</li>
<li>
<p>Solutions</p>
<ul>
<li>
<p>Increase main memory，more process in memory</p>
<ul>
<li>
<p>Expensive</p>
</li>
<li>
<p>Leads to larger programs</p>
</li>
</ul>
</li>
<li>
<p><strong>Swapping</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>What is swapping?</strong></p>
<ul>
<li>
<p>Long term queue of processes stored on disk</p>
<ul>
<li>
<p>Processes “swapped” in as space becomes available</p>
</li>
<li>
<p>As a process completes it is moved out of main memory</p>
</li>
</ul>
</li>
<li>
<p>If none of the processes in memory are ready (i.e. all I/O blocked)</p>
<ul>
<li>
<p>Swap out a blocked process to intermediate queue</p>
</li>
<li>
<p>Swap in a ready process or a new process</p>
</li>
<li>
<p><strong>Swapping is an I/O process</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>Use of swapping</strong></p>
<ul>
<li>
<p><strong>简单的进程调度中，磁盘维护一个长周期队列。当内存中有作业完成了，会将它从内存中去掉，同时将长周期队列中的一个作业放到内存中</strong></p>
</li>
<li>
<p><strong>交换调度中，磁盘中维护了一个中间队列。阻塞进程将会被“交换”到中间队列中，并从中间队列中调入一个已经就绪的进程。如果中间队列没有就绪的进程，就从长期队列中调度一个新的进程到内存中</strong></p>
</li>
<li>
<p><strong>通过中间队列，可以在进程均处于阻塞的时候进行进程的有效调度，提高CPU效率</strong></p>
</li>
</ul>
<h5 id="partitioning">Partitioning</h5>
<ul>
<li>
<p>Swapping does not explain how memory is managed</p>
</li>
<li>
<p><strong>Memory management mode</strong></p>
<ul>
<li>
<p>Partitioning</p>
</li>
<li>
<p>Paging</p>
</li>
<li>
<p>Segmentation</p>
</li>
</ul>
</li>
<li>
<p><strong>Partitioning: Splitting memory into sections to allocate to processes (including Operating System)</strong></p>
</li>
</ul>
<p><strong>Fixed partitioning</strong></p>
<ul>
<li>
<p><strong>分区大小固定，但不一定都是一样大</strong></p>
</li>
<li>
<p>进程分配内存时，分配到<strong>能容纳它的最小分区</strong></p>
</li>
<li>
<p><strong>存在内存浪费的现象</strong></p>
</li>
<li>
<p>采取非固定大小分区可能会更好</p>
</li>
</ul>
<h6 id="variable-sized-partitions">Variable sized partitions</h6>
<ul>
<li>
<p>Allocate exactly the required memory to a process</p>
</li>
<li>
<p>This leads to a hole at the end of memory, too small to use</p>
<ul>
<li>Only one small hole - less waste</li>
</ul>
</li>
<li>
<p><strong>When all processes are blocked, swap out a process and bring in another process，leads to another hole</strong></p>
</li>
<li>
<p><strong>A process is completed and swapped out，new process is swapped in. May leads to a hole</strong></p>
</li>
<li>
<p>Eventually have lots of holes (called fragmentation)</p>
</li>
<li>
<p>Solutions</p>
<ul>
<li>
<p><strong>Coalesce - Join adjacent holes into one large hole</strong></p>
</li>
<li>
<p><strong>Compaction- From time to time go through memory and move all hole into one free block</strong> (like $\rightarrow$ <code>disk de-fragmentation</code>)</p>
</li>
</ul>
</li>
</ul>
<h6 id="effect-of-dynamic-partitioning">Effect of Dynamic Partitioning</h6>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-5.png" title="/img/Computer Organization and Architecture/chapter8-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-5.png" data-sub-html="<h2>Dynamic Partitioning</h2>">
        
    </a><figcaption class="image-caption"><code>Dynamic Partitioning</code></figcaption>
    </figure>
<ul>
<li>
<p>分配进程1~3的时候，按需求分配，剩下$4M$的空间</p>
</li>
<li>
<p>进程2交换出去了，进程4进来了。进程4只有$8M$，在进程4和进程3之间，形成了一个$6M$的空块</p>
</li>
<li>
<p>进程1交换出去了，进程2进来。进程1有$20M$，进程2只有$14M$，在进程2和进程4之间，又形成了一个$6M$的空块</p>
</li>
<li>
<p>有2个$6M$空块和1个$4M$空块</p>
</li>
</ul>
<h6 id="problem-about-relocation">Problem about relocation</h6>
<ul>
<li>
<p>No guarantee that process will load into the same place in memory</p>
</li>
<li>
<p>Instructions contain addresses information</p>
<ul>
<li>
<p>Locations of data</p>
</li>
<li>
<p>Addresses for instructions (e.g. branching)</p>
</li>
</ul>
</li>
<li>
<p><strong>If a fixed address is used, memory address of process changes after the process is swapped out and then swapped in</strong></p>
</li>
<li>
<p><strong>Data and instructions cannot be addressed</strong></p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Using logical address and physical address</p>
<ul>
<li>
<p>Logical address - relative to beginning of program</p>
</li>
<li>
<p>Physical address - actual location in memory (this time)</p>
</li>
</ul>
</li>
<li>
<p>Starting unit address of the current process is set as the base address</p>
</li>
<li>
<p>Addressing data and instructions using logical addresses in programs</p>
</li>
</ul>
<h5 id="paging">Paging</h5>
<ul>
<li>
<p>Partitioning will lead to waste of memory</p>
</li>
<li>
<p><strong>Paging Management</strong></p>
<ul>
<li>
<p><strong>Split memory into equal sized, small chunks -page frames</strong></p>
</li>
<li>
<p><strong>Split programs (processes) into equal sized small chunks – pages</strong></p>
</li>
<li>
<p><strong>Allocate the required number page frames to a process</strong></p>
</li>
</ul>
</li>
<li>
<p>Operating System completes paging management</p>
<ul>
<li>
<p><strong>A process does not require contiguous page frames</strong></p>
</li>
<li>
<p><strong>Use page table to keep track</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p>Each process has its own page table</p>
</li>
<li>
<p><strong>Each page table entry contains the frame number of the corresponding page in main memory</strong></p>
</li>
<li>
<p><strong>Two extra bits are needed to indicate</strong></p>
<ul>
<li>
<p><strong>whether the page is in main memory or not</strong></p>
</li>
<li>
<p><strong>Whether the contents of the page has been altered since it was last loaded</strong></p>
</li>
</ul>
</li>
</ul>
<h6 id="paging-table">Paging table</h6>
<ul>
<li>
<p><strong>寻址的虚拟地址为“页号+偏移量”</strong></p>
</li>
<li>
<p>页表中指明了这个页对应的内存的帧序号</p>
</li>
<li>
<p><strong>通过[页</strong>$\rightarrow$<strong>帧]的转换，以及页内的偏移量，就可以得到逻辑地址在内存中的实际地址</strong></p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-6.png" title="/img/Computer Organization and Architecture/chapter8-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-6.png">
        
    </a>
<h6 id="allocation-of-free-frames">Allocation of free frames</h6>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-7.png" title="/img/Computer Organization and Architecture/chapter8-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-7.png">
        
    </a>
<ul>
<li>
<p>内存中帧13-15是空闲的，分配给了进程A地第1-3页</p>
</li>
<li>
<p>帧16、17其他进程占用</p>
</li>
<li>
<p>帧18分配给进程A的0页</p>
</li>
<li>
<p><strong>分配帧的时候，既不要求是连续的，也不要求前后顺序</strong></p>
</li>
</ul>
<h6 id="real-and-virtual-memory">Real and virtual memory</h6>
<ul>
<li>
<p>On the basis of logical address, expand the memory, which leads to the concept of virtual memory</p>
</li>
<li>
<p><strong>Real memory</strong></p>
<ul>
<li><strong>Main memory, the actual RAM</strong></li>
</ul>
</li>
<li>
<p><strong>Virtual memory</strong></p>
<ul>
<li><strong>Memory on disk</strong></li>
</ul>
</li>
<li>
<p><strong>Allows for effective multiprogramming and relieves the user of tight constraints of main memory</strong></p>
</li>
</ul>
<hr>
<p><strong>Support deeded for virtual memory</strong></p>
<ul>
<li>
<p><strong>Hardware must support paging and segmentation</strong></p>
</li>
<li>
<p><strong>Operating system must be able to manage the movement of pages and/or segments between secondary memory and main memory</strong></p>
</li>
</ul>
<hr>
<p><strong>Virtual memory</strong></p>
<ul>
<li>
<p>Page load-demand paging</p>
<ul>
<li>
<p>Do not require all pages of a process in memory</p>
</li>
<li>
<p>Bring in pages as required</p>
</li>
</ul>
</li>
<li>
<p>Page fault</p>
<ul>
<li>
<p>Required page is not in memory</p>
</li>
<li>
<p>Operating System must swap in required page</p>
</li>
<li>
<p>May need to swap out a page to make space</p>
</li>
<li>
<p>Select page to throw out based on recent history</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Thrashing</strong></p>
<ul>
<li>
<p>Too many processes in too little memory</p>
</li>
<li>
<p><strong>Operating System spends all its time swapping</strong></p>
</li>
<li>
<p>Little or no real work is done</p>
</li>
<li>
<p>Disk light is on all the time</p>
</li>
<li>
<p><strong>Solutions</strong></p>
<ul>
<li>
<p><strong>Good page replacement algorithms</strong></p>
</li>
<li>
<p><strong>Reduce number of processes running</strong></p>
</li>
<li>
<p><strong>Fit more memory</strong></p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Advantage of virtual memory</strong></p>
<ul>
<li>
<p>Do not need all of a process in memory for it to run</p>
</li>
<li>
<p>Swap in pages as required</p>
</li>
<li>
<p><strong>So can now run processes that are bigger than total memory available!</strong></p>
</li>
<li>
<p><strong>Main memory is called real memory</strong></p>
</li>
<li>
<p><strong>User/programmer sees much bigger memory - virtual memory</strong></p>
</li>
</ul>
<hr>
<p><strong>Page tables</strong></p>
<ul>
<li>
<p>Each process must have a page table to convert logical address or virtual address to physical address</p>
</li>
<li>
<p>Some processes are very large, and their page tables themselves are very large</p>
<ul>
<li>
<p><strong>Page tables are also stored in virtual memory</strong></p>
</li>
<li>
<p><strong>When a process is running, part of its page table is in main memory</strong></p>
</li>
<li>
<p><strong>Load the required page table through exchange</strong></p>
</li>
</ul>
</li>
</ul>
<figure><a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-1.png" title="/img/Computer Organization and Architecture/chapter8-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-1.png" data-sub-html="<h2>Two-Level Hierarchical Page Table</h2>">
        
    </a><figcaption class="image-caption"><code>Two-Level Hierarchical Page Table</code></figcaption>
    </figure>
<p><strong>Address Translation for Hierarchical page table</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-9.png" title="/img/Computer Organization and Architecture/chapter8-9.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-9.png">
        
    </a>
<ul>
<li>
<p>虚拟地址包括根页表段、用户页表段和页内偏移量</p>
</li>
<li>
<p>根据根页表指针和根页表段，得到用户页表段的基准地址</p>
</li>
<li>
<p>加上用户页表段地址，得到用户页表地址</p>
</li>
<li>
<p>再加上页内偏移量，得到在实际内存中的地址</p>
</li>
</ul>
<hr>
<p><strong>Problem about page tables</strong></p>
<ul>
<li>
<p>A drawback of the type of page tables is that their size is proportional to that of the virtual address space</p>
<ul>
<li>
<p>Each virtual space page needs a row in the page table</p>
</li>
<li>
<p>If the virtual space of the user program is large, the page table will also be very large</p>
</li>
</ul>
</li>
<li>
<p>An alternative is Inverted Page Tables</p>
</li>
</ul>
<h6 id="inverted-page-table">Inverted page table</h6>
<ul>
<li>
<p>Used on <code>PowerPC</code>, <code>UltraSPARC</code>, and <code>IA-64 architecture</code></p>
</li>
<li>
<p><strong>Page number portion of a virtual address is mapped into a hash value</strong></p>
</li>
<li>
<p><strong>Hash value points to inverted page table</strong></p>
</li>
<li>
<p>Fixed proportion of real memory is required for the tables regardless of the number of processes</p>
</li>
<li>
<p><strong>反向页表的行数是物理内存的帧数，和进程数无关</strong></p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Each entry in the page table includes</p>
<ul>
<li>
<p>Page number</p>
</li>
<li>
<p>Process identifier</p>
<ul>
<li>The process that owns this page</li>
</ul>
</li>
<li>
<p>Control bits</p>
<ul>
<li>includes flags, such as valid, referenced, etc</li>
</ul>
</li>
<li>
<p><strong>Chain pointer</strong></p>
<ul>
<li><strong>the index value of the next entry in the chain</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>Use of inverted page table</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter8-10.png" title="/img/Computer Organization and Architecture/chapter8-10.png" data-thumbnail="/img/Computer Organization and Architecture/chapter8-10.png">
        
    </a>
<ul>
<li>
<p>虚拟地址中的页号通过散列函数，形成一个散列值，映射到反向页表</p>
</li>
<li>
<p>通过页号的散列值和进程ID，确定虚拟地址的页是否在内存中</p>
</li>
<li>
<p>通过链技术来提高查找的速度</p>
</li>
</ul>
<h6 id="translation-lookaside-buffer">Translation lookaside buffer</h6>
<ul>
<li>
<p>Every virtual memory reference causes two physical memory access</p>
<ul>
<li>
<p>Fetch page table entry</p>
</li>
<li>
<p>Fetch data</p>
</li>
</ul>
</li>
<li>
<p>To overcome this problem a high-speed cache is set up for page table entries</p>
<ul>
<li>
<p>Called a Translation Lookaside Buffer (<code>TLB</code>)</p>
</li>
<li>
<p>Contains page table entries that have been most recently used</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong><code>TLB</code> operation</strong></p>
<ul>
<li>
<p>根据虚拟地址中的页地址，去快表中查找是否有页帧地址</p>
</li>
<li>
<p>如果有，接就可以生成物理地址</p>
</li>
<li>
<p>如果没有，就去看内存中的页表中是否有这个页</p>
</li>
<li>
<p>如果在内存中的话，就先更新快表，然后生成物理地址</p>
</li>
<li>
<p>如果也没有，就要去读取I/O，然后更新内存页表</p>
</li>
</ul>
<h5 id="segmentation">Segmentation</h5>
<ul>
<li>
<p>Paging is not (usually) visible to the programmer</p>
</li>
<li>
<p>Segmentation is visible to the programmer</p>
</li>
<li>
<p>Usually different segments allocated to program and data</p>
</li>
<li>
<p>May be a number of program and data segments</p>
</li>
</ul>
<hr>
<p><strong>Advantage of segmentation</strong></p>
<ul>
<li>
<p>Simplified management</p>
<ul>
<li>
<p>Programmers need not know how much space data needs</p>
</li>
<li>
<p>Data can be allocated to its own segment and can be dynamically expanded</p>
</li>
</ul>
</li>
<li>
<p>Allows programs to be altered and recompiled independently</p>
</li>
<li>
<p>The segment can be shared among multiple processes</p>
</li>
<li>
<p>Protections from assigning access privileges</p>
</li>
</ul>
<hr>
<p><strong>Segment tables</strong></p>
<ul>
<li>
<p>Corresponding segment in main memory</p>
</li>
<li>
<p>段需要有段表来实现地址转换</p>
</li>
<li>
<p>虚拟地址中包含段号，从段表中找到该段号对应的段基址，就可以根据偏移量到内存中得到这个虚拟地址对应的物理地址</p>
</li>
</ul>
<hr>
<p><strong>Combined segmentation and paging</strong></p>
<ul>
<li>
<p>程序员将进程分为若干个段</p>
</li>
<li>
<p>系统将每个段分为多个页</p>
</li>
<li>
<p>在进行地址转换的时候，根据段号，到段表中找到段基址，根据页号，到页表中找到对应的帧号，然后段基址和帧号结合，可以得到实际的物理地址</p>
</li>
</ul>
]]></description>
</item>
<item>
    <title>Computer Organization and Architecture Input &amp; Output</title>
    <link>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-input-output/</link>
    <pubDate>Thu, 19 Jan 2023 15:45:36 &#43;0800</pubDate><author>1239946358@qq.com (Jungle)</author><guid>https://Jungle430.github.io/posts/computer-organization-and-architecture/computer-organization-and-architecture-input-output/</guid>
    <description><![CDATA[<h1 id="computer-organization-and-architecture">Computer Organization and Architecture</h1>
<h2 id="input--output">Input &amp; Output</h2>
<h3 id="outline">Outline</h3>
<ul>
<li>
<p>External Devices</p>
</li>
<li>
<p>I/O Modules</p>
</li>
<li>
<p>Programmed I/O</p>
</li>
<li>
<p>Interrupt-Driven I/O</p>
</li>
<li>
<p>Direct Memory Access</p>
</li>
<li>
<p>I/O Channels and Processors</p>
</li>
<li>
<p>The External Interface</p>
</li>
</ul>
<h3 id="external-devices">External Devices</h3>
<h4 id="inputoutput-problems">Input/Output Problems</h4>
<ul>
<li>
<p><strong>Peripherals are used for information exchange between computer and environment</strong></p>
</li>
<li>
<p>Wide variety of peripherals</p>
<ul>
<li>
<p>Delivering different amounts of data</p>
</li>
<li>
<p>In different formats</p>
</li>
<li>
<p>At different speeds</p>
</li>
</ul>
</li>
<li>
<p><strong>Almost all slower than CPU and RAM</strong></p>
</li>
<li>
<p>Need I/O modules</p>
<ul>
<li>
<p><strong>Connection to processor and memory via system bus or central exchanger</strong></p>
</li>
<li>
<p><strong>Connect with one or more peripherals through a dedicated data line</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="function-of-io-modules">Function of I/O modules</h4>
<ul>
<li>
<p><strong>Connecting peripherals with system bus</strong></p>
</li>
<li>
<p><strong>Not only a connector, but also the communication logic between peripheral devices and system bus</strong></p>
<ul>
<li>
<p>many types of peripherals</p>
</li>
<li>
<p>amount of data transmitted varies greatly</p>
</li>
<li>
<p>speed varies greatly</p>
</li>
</ul>
</li>
<li>
<p><strong>I/O modules are required to resolve the differences between peripherals and processors</strong></p>
</li>
</ul>
<p>$System\ Bus=Address\ Lines+Data\ Lines+Control\ Lines\newline$</p>
<div class="mermaid" id="id-1"></div>
<h4 id="types-of-peripherals">Types of peripherals</h4>
<ul>
<li>
<p>Human readable</p>
<ul>
<li>Screen, printer, keyboard</li>
</ul>
</li>
<li>
<p>Machine readable</p>
<ul>
<li>Monitoring and control</li>
</ul>
</li>
<li>
<p>Communication</p>
<ul>
<li>
<p>Modem</p>
</li>
<li>
<p>Network Interface Card (NIC)</p>
</li>
</ul>
</li>
<li>
<p>Can also be categorized as</p>
<ul>
<li>
<p>Input devices</p>
</li>
<li>
<p>Output devices</p>
</li>
<li>
<p>Input/Output devices</p>
</li>
</ul>
</li>
</ul>
<h4 id="interface-of-peripherals">Interface of peripherals</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-1.png" title="/img/Computer Organization and Architecture/chapter7-1.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-1.png">
        
    </a>
<h4 id="usb-interface">USB interface</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-2.png" title="/img/Computer Organization and Architecture/chapter7-2.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-2.png">
        
    </a>
<p><strong>Charismatics of USB interface</strong></p>
<ul>
<li>
<p>Hot plug: Plug and Play</p>
</li>
<li>
<p>Portability: Small equipment, easy to carry</p>
</li>
<li>
<p>Standard unification: Peripherals can be connected to personal computers with the same interface</p>
</li>
<li>
<p>Multiple devices connectivity: More devices can be connected through USB-HUB expansion</p>
</li>
</ul>
<h4 id="external-device-structure">External device structure</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-3.png" title="/img/Computer Organization and Architecture/chapter7-3.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-3.png">
        
    </a>
<h3 id="io-modules">I/O Modules</h3>
<h4 id="function-of-io-module">Function of I/O module</h4>
<ul>
<li>
<p><strong>Control &amp; Timing</strong></p>
<ul>
<li>
<p>Control the operation of peripherals</p>
</li>
<li>
<p>Sequential control</p>
</li>
</ul>
</li>
<li>
<p><strong>CPU Communication</strong></p>
<ul>
<li>
<p>communication between the processor and peripherals</p>
</li>
<li>
<p>Command decoding, data transmission, status report, address identification</p>
</li>
</ul>
</li>
<li>
<p><strong>Device Communication</strong></p>
<ul>
<li>
<p>communication with device</p>
</li>
<li>
<p>Command, data and status</p>
</li>
</ul>
</li>
<li>
<p><strong>Data Buffering</strong></p>
<ul>
<li>
<p><strong>Speed of different peripherals varies greatly</strong></p>
</li>
<li>
<p>Conversion of transmission rate</p>
</li>
</ul>
</li>
<li>
<p><strong>Error Detection</strong></p>
</li>
</ul>
<h4 id="step-of-data-transfer">Step of data transfer</h4>
<ol>
<li>
<p>CPU checks I/O module device status</p>
</li>
<li>
<p>I/O module returns status</p>
</li>
<li>
<p>If ready, CPU requests data transfer</p>
</li>
<li>
<p>I/O module gets data from device</p>
</li>
<li>
<p>I/O module transfers data to CPU</p>
</li>
</ol>
<p><strong>Variations for output, <code>DMA</code></strong></p>
<h4 id="processor-communication">Processor communication</h4>
<ul>
<li>
<p><strong>Command decoding</strong></p>
<ul>
<li>
<p>processor sends instructions to the I/O module</p>
</li>
<li>
<p>I/O module decodes the instructions to determine the operations to be completed</p>
</li>
</ul>
</li>
<li>
<p>Address recognition</p>
<ul>
<li>
<p><strong>Each peripheral has an address, similar to a memory unit</strong></p>
</li>
<li>
<p><strong>Operating instructions include peripheral address</strong></p>
</li>
<li>
<p><strong>I/O module determines which device to operate on according to the address</strong></p>
</li>
</ul>
</li>
<li>
<p>Data transfer</p>
<ul>
<li>
<p>Data transmission is <strong>bidirectional</strong></p>
</li>
<li>
<p>Complete <strong>through data bus</strong></p>
</li>
</ul>
</li>
<li>
<p>Status reporting</p>
<ul>
<li>
<p>Report the status to the CPU to determine whether the current I/O operation is executed</p>
</li>
<li>
<p><strong>Report various error messages</strong></p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-4.png" title="/img/Computer Organization and Architecture/chapter7-4.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-4.png">
        
    </a>
<h4 id="io-module-structure">I/O module structure</h4>
<ul>
<li>
<p><strong>Data registers: data buffer to the I/O device</strong></p>
</li>
<li>
<p><strong>Status/Control registers</strong></p>
<ul>
<li>
<p>Current status</p>
</li>
<li>
<p>or receive control from the processor</p>
</li>
<li>
<p>Connecting to data</p>
</li>
</ul>
</li>
<li>
<p><strong>Bus interface: data, address, control</strong></p>
</li>
<li>
<p><strong>I/O logic</strong></p>
<ul>
<li>
<p><strong>Receive the command sent by the processor</strong></p>
</li>
<li>
<p><strong>Receive address</strong></p>
</li>
<li>
<p><strong>Control peripherals for operation</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>External device interface</strong></p>
<ul>
<li>
<p><strong>Interact with peripherals</strong></p>
</li>
<li>
<p><strong>Including data, status and control</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="three-io-techniques---">Three I/O techniques ! ! !</h4>
<ul>
<li>
<p><strong>Programmed I/O</strong></p>
<ul>
<li>
<p><strong>The processor executes a program to control the I/O operation</strong></p>
</li>
<li>
<p><strong>The processor needs to wait while I/O processing the command</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Interrupt-driven I/O</strong></p>
<ul>
<li><strong>Processor issues an I/O command, and continues to execute other instructions until the interrupt occurs</strong></li>
</ul>
</li>
<li>
<p><strong>Direct memory access (<code>DMA</code>)</strong></p>
<ul>
<li><strong>The data transfer without processor involvement</strong></li>
</ul>
</li>
</ul>
<p><strong>Programmed I/O</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-5.png" title="/img/Computer Organization and Architecture/chapter7-5.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-5.png">
        
    </a>
<p><strong>Interrupt-driven I/O</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-6.png" title="/img/Computer Organization and Architecture/chapter7-6.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-6.png">
        
    </a>
<p><strong>Direct memory access (<code>DMA</code>)</strong></p>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-7.png" title="/img/Computer Organization and Architecture/chapter7-7.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-7.png">
        
    </a>
<h3 id="programmed-io">Programmed I/O</h3>
<ul>
<li>
<p><strong>CPU has direct control over I/O</strong></p>
<ul>
<li>
<p>Sensing status</p>
</li>
<li>
<p>Read/write commands</p>
</li>
<li>
<p>Transferring data</p>
</li>
</ul>
</li>
<li>
<p><strong>CPU waits for I/O module to complete operation</strong></p>
</li>
<li>
<p><strong>Wastes CPU time</strong></p>
</li>
</ul>
<hr>
<ul>
<li>
<p>CPU requests I/O operation</p>
<ul>
<li>
<p>I/O module performs operation</p>
</li>
<li>
<p>I/O module sets status bits</p>
</li>
</ul>
</li>
<li>
<p>CPU checks status bits periodically</p>
<ul>
<li>
<p>I/O module does not inform CPU directly</p>
</li>
<li>
<p>I/O module does not interrupt CPU</p>
</li>
</ul>
</li>
<li>
<p>CPU may wait or come back later CPU</p>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>CPU sends out address</strong></p>
<ul>
<li><strong>Identifies module (&amp; device if &gt;1 per module)</strong></li>
</ul>
</li>
<li>
<p>CPU sends out command</p>
<ul>
<li>
<p>Control - telling module what to do</p>
</li>
<li>
<p>Test - check status</p>
</li>
<li>
<p>Read/Write —transfers data via buffer from/to device</p>
</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>
<p><strong>I/O addressing</strong></p>
<ul>
<li>
<p><strong>Typically, there might be many I/O devices connected through I/O modules</strong></p>
</li>
<li>
<p><strong>Each device is given a unique address</strong></p>
</li>
<li>
<p><strong>The I/O instruction contains the address of the desired device</strong></p>
</li>
<li>
<p><strong>Two types of addressing mode are used</strong></p>
<ul>
<li>
<p><strong>Memory-mapped I/O</strong></p>
</li>
<li>
<p><strong>Isolated I/O</strong></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="memory-mapped-io">Memory mapped I/O</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-8.png" title="/img/Computer Organization and Architecture/chapter7-8.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-8.png">
        
    </a>
<h4 id="io-mapping---isolated-io">I/O mapping - isolated I/O</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-9.png" title="/img/Computer Organization and Architecture/chapter7-9.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-9.png">
        
    </a>
<h3 id="interrupt-driven-io">Interrupt-Driven I/O</h3>
<ul>
<li>
<p>Programmed I/O reduces CPU efficiency</p>
</li>
<li>
<p><strong>Interrupt driven I/O overcomes CPU waiting</strong></p>
</li>
<li>
<p><strong>No repeated CPU checking of device</strong></p>
</li>
<li>
<p><strong>I/O module interrupts when ready</strong></p>
</li>
</ul>
<div class="mermaid" id="id-2"></div>
<h4 id="interrupt-processing">Interrupt processing</h4>
<ul>
<li>
<p>CPU: issues I/O command</p>
</li>
<li>
<p>CPU: continues with other tasks</p>
</li>
<li>
<p>The module: receives the command and works on the task</p>
</li>
<li>
<p>When finished, signals CPU an interrupt</p>
</li>
<li>
<p><strong>CPU: checks the interrupt at the end of each instruction cycle</strong></p>
</li>
<li>
<p><strong>CPU: if interrupt occurs</strong></p>
<ul>
<li>
<p><strong>CPU saves the context</strong></p>
</li>
<li>
<p><strong>Executes interrupt service routine</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>CPU: restores the context</strong></p>
</li>
<li>
<p><strong>CPU: continues on its primary task</strong></p>
</li>
</ul>
<h4 id="interrupt-processing-diagram">Interrupt processing diagram</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-10.png" title="/img/Computer Organization and Architecture/chapter7-10.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-10.png">
        
    </a>
<h4 id="cpu-viewpoint">CPU viewpoint</h4>
<ul>
<li>
<p>Issue read command</p>
</li>
<li>
<p>Do other work</p>
</li>
<li>
<p><strong>Check for interrupt at end of each instruction cycle</strong></p>
</li>
<li>
<p><strong>If interrupted</strong></p>
<ul>
<li>
<p><strong>Save context (registers)</strong></p>
</li>
<li>
<p><strong>Process interrupt</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Restore <code>PSW</code> and <code>PC</code></strong></p>
</li>
</ul>
<h4 id="types-of-device-identification">Types of device identification</h4>
<ul>
<li>
<p><strong>For device identification, there are four general categories of techniques are in use</strong></p>
<ul>
<li>
<p><strong>Multiple interrupt line – each device has a IRQ</strong></p>
</li>
<li>
<p><strong>Software poll</strong></p>
</li>
<li>
<p><strong>Hardware poll (Vectored interrupt)</strong></p>
</li>
<li>
<p><strong>Bus arbitration (Vectored interrupt)</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="software-poll">Software poll</h4>
<ul>
<li>
<p><strong>An interrupt service routine polls each I/O module to determine which module caused the interrupt</strong></p>
<ul>
<li>
<p><strong>TEST I/O command</strong></p>
</li>
<li>
<p><strong>Status register: After an interrupt is issued by the I/O module, a status register is written. The processor polls this status register</strong></p>
</li>
</ul>
</li>
<li>
<p>Once the correct module is identified, the processor branches to a device-service routine specific to that device</p>
</li>
<li>
<p><strong>Disadvantage: time consuming</strong></p>
</li>
</ul>
<h4 id="hardware-poll">Hardware poll</h4>
<ul>
<li>
<p><strong>All I/O modules share a common interrupt request line</strong></p>
</li>
<li>
<p><strong>When the processor senses an interrupt, it sends out an interrupt acknowledge</strong></p>
<ul>
<li>
<p><strong>This signal propagates through a series of I/O modules until it gets to a requesting module</strong></p>
</li>
<li>
<p><strong>The requesting module typically responds by placing a word (vector) that identifies the device</strong></p>
</li>
<li>
<p><strong>The processor uses the vector as a pointer to the appropriate device-service routine</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Called vectored interrupt</strong></p>
</li>
</ul>
<h4 id="bus-arbitration">Bus arbitration</h4>
<ul>
<li>
<p><strong>An I/O module must first gain control of the bus before it can raise the interrupt request line</strong></p>
</li>
<li>
<p><strong>When the processor detects the interrupt, it responds on the interrupt acknowledge line</strong></p>
</li>
<li>
<p><strong>The requesting module then places its vector on the data line</strong></p>
</li>
</ul>
<h4 id="multiple-interrupts">Multiple interrupts</h4>
<ul>
<li>
<p>FIFO,<strong>no priority</strong></p>
</li>
<li>
<p>Multiple interrupt line: <strong>each interrupt line has a priority</strong></p>
</li>
<li>
<p>Hardware poll or software poll: <strong>order of polling determines the priority</strong></p>
</li>
<li>
<p>Bus arbitration: <strong>Arbitration can be conducted in priority mode</strong></p>
</li>
</ul>
<h3 id="direct-memory-accessdma">Direct Memory Access(<code>DMA</code>)</h3>
<p><strong>Why use <code>DMA</code></strong></p>
<ul>
<li>
<p>Interrupt driven and programmed I/O require active CPU intervention</p>
<ul>
<li>
<p>I/O-&gt;processor-&gt;memory</p>
</li>
<li>
<p>Transfer rate is limited</p>
</li>
<li>
<p>CPU is tied up</p>
</li>
</ul>
</li>
<li>
<p><code>DMA</code> is the answer</p>
</li>
<li>
<p><code>DMA</code>: <strong>Direct Memory Access</strong></p>
<ul>
<li>
<p><strong>a module on system bus</strong></p>
</li>
<li>
<p><strong>take over the system control work from the processor</strong></p>
</li>
<li>
<p><strong>transfers data between memory and I/O module</strong></p>
</li>
</ul>
</li>
<li>
<p>Both interrupt driven and programmed I/O require the continued involvement of the CPU in the I/O operation</p>
<ul>
<li>
<p>$I/O\ device \rightarrow CPU \rightarrow Memory\newline$</p>
</li>
<li>
<p>$I/O\ device \leftarrow CPU \leftarrow Memory\newline$</p>
</li>
</ul>
</li>
<li>
<p><code>DMA</code> takes the CPU out of the task</p>
<ul>
<li>$I/O\ device \rightarrow Memory\newline$</li>
<li>$I/O\ device \leftarrow Memory\newline$</li>
</ul>
</li>
</ul>
<h4 id="dma-function"><code>DMA</code> function</h4>
<ul>
<li>
<p><strong>Additional Module (hardware) on bus</strong></p>
</li>
<li>
<p><strong><code>DMA</code> controller takes over from CPU for I/O</strong></p>
<ul>
<li>
<p><strong><code>DMA</code> need system bus to complete data transmission</strong></p>
</li>
<li>
<p><strong>It must use the bus only when the processor does not need it</strong></p>
</li>
<li>
<p><strong>Or it must force the CPU to suspend operation temporarily –referred to as <code>cycle stealing</code>!  !  !</strong></p>
</li>
</ul>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-11.png" title="/img/Computer Organization and Architecture/chapter7-11.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-11.png">
        
    </a>
<h4 id="dma-operation---"><code>DMA</code> operation ! ! !</h4>
<ul>
<li>
<p>CPU tells <code>DMA</code> controller</p>
<ul>
<li>
<p>Read/Write</p>
</li>
<li>
<p>Device address</p>
</li>
<li>
<p>Starting address of memory block for data</p>
</li>
<li>
<p>Amount of data to be transferred</p>
</li>
</ul>
</li>
<li>
<p>CPU carries on with other work</p>
</li>
<li>
<p><code>DMA</code> controller deals with transfer</p>
</li>
<li>
<p><code>DMA</code> controller sends interrupt when finished</p>
</li>
<li>
<p>CPU, <code>DMA</code> controller, I/O device exchange the handshake signals</p>
</li>
<li>
<p><code>DMA</code> controller deals with the data transfer</p>
<ul>
<li>
<p>I/O device to memory, memory to I/O device</p>
</li>
<li>
<p>Multiple data may be transmitted at one time</p>
</li>
</ul>
</li>
<li>
<p>CPU only involved at the beginning and end of the transfer</p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-12.png" title="/img/Computer Organization and Architecture/chapter7-12.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-12.png">
        
    </a>
<h4 id="dma-transfer-cycle-stealing---"><code>DMA</code> transfer cycle-stealing ! ! !</h4>
<ul>
<li>
<p><strong>Cycle-stealing: <code>DMA</code> controller takes over bus for a cycle</strong></p>
<ul>
<li>
<p>Transfer of one word of data in this cycle</p>
</li>
<li>
<p><strong>Cycle-stealing is not an interrupt</strong></p>
</li>
<li>
<p><strong>CPU does not switch context</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>CPU suspended just before it accesses bus</strong></p>
<ul>
<li><strong>i.e. before an operand or data fetch or a data write</strong></li>
</ul>
</li>
<li>
<p><strong>Slows down CPU but not as much as CPU doing transfer</strong></p>
</li>
</ul>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-13.png" title="/img/Computer Organization and Architecture/chapter7-13.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-13.png">
        
    </a>
<h4 id="alternative-dma-configurations">Alternative <code>DMA</code> configurations</h4>
<div class="mermaid" id="id-3"></div>
<ul>
<li>
<p>单总线分离的<code>DMA</code>，<code>DMA</code>、I/O模块和内存都挂在总线上</p>
</li>
<li>
<p><code>DMA</code>是CPU的代理，采用类似于编程式I/O的方式，在内存和I/O之间传送数据</p>
</li>
<li>
<p><strong>每次传送需要消耗2个总线时钟周期。一个周期用于和I/O交换数据，一个周期用于和存储器交换数据</strong></p>
</li>
<li>
<p><strong>配置简单，效率比较低</strong></p>
</li>
</ul>
<hr>
<div class="mermaid" id="id-4"></div>
<ul>
<li>
<p><strong>单总线集成式<code>DMA</code>-I/O结构，I/O模块通过<code>DMA</code>和总线互连</strong></p>
</li>
<li>
<p><code>DMA</code>可能是I/O的一部分，也可能一个<code>DMA</code>控制一个或几个I/O模块</p>
</li>
<li>
<p><strong><code>DMA</code>与I/O之间的数据交换不需要系统总线，只有<code>DMA</code>和存储器交换数据到时候才会用到系统总线，减少了系统总线的开销</strong></p>
</li>
</ul>
<hr>
<div class="mermaid" id="id-5"></div>
<ul>
<li>
<p>I/O总线方式，从第二种方式扩充而来</p>
</li>
<li>
<p><strong>在<code>DMA</code>和I/O设备之间配置一条专门的I/O总线</strong></p>
</li>
<li>
<p><strong>可以减少<code>DMA</code>模块的接口数量</strong></p>
</li>
<li>
<p><strong><code>DMA</code>与存储器交换数据的时候才会用到系统总线</strong></p>
</li>
</ul>
<h4 id="fly-by--1">Fly-by -1</h4>
<ul>
<li>
<p><strong><code>DMA</code> and CPU use the bus alternately</strong></p>
</li>
<li>
<p><strong>Data does not pass through and is not stored in <code>DMA</code> chip</strong></p>
<ul>
<li>
<p>8237 <code>DMA</code> is known as fly-by <code>DMA</code> controller</p>
</li>
<li>
<p><strong><code>DMA</code> only between I/O port and memory</strong></p>
</li>
<li>
<p><strong>Not between two I/O ports or two memory locations</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>Can perform memory to memory transfer via <code>register</code></strong></p>
</li>
</ul>
<h3 id="summary">Summary</h3>
<table>
<thead>
<tr>
<th></th>
<th>Programmed I/O</th>
<th>Interrupt driven I/O</th>
<th><code>DMA</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Operation</td>
<td>CPU checks I/O status repeatedly</td>
<td>I/O device sends request when ready</td>
<td>Data transfer without CPU</td>
</tr>
<tr>
<td>Advantage</td>
<td>Simple Polling sequence can be changed by program</td>
<td>Save time</td>
<td>More faster</td>
</tr>
<tr>
<td>Disadvantage</td>
<td>Time consuming</td>
<td>Complex</td>
<td>More complex</td>
</tr>
</tbody>
</table>
<h3 id="io-channels-and-processors">I/O Channels and Processors</h3>
<h4 id="evolution-of-io-function">Evolution of I/O function</h4>
<blockquote>
<p><strong>Peripherals are more and more complex, and I/O functions are also developing</strong></p>
</blockquote>
<ul>
<li>
<p><strong>I/O channel</strong></p>
<ul>
<li>
<p><strong>I/O module is enhanced to become a processor(no memory)</strong></p>
</li>
<li>
<p><strong>with a specialized instruction set tailored for I/O</strong></p>
</li>
<li>
<p><strong>The CPU instructs the I/O processor to execute I/O programs in memory</strong></p>
</li>
<li>
<p><strong>Interrupt will not occur until I/O program execution is completed</strong></p>
</li>
</ul>
</li>
<li>
<p><strong>I/O processor</strong></p>
<ul>
<li>
<p><strong>has a local memory of its own and is, in fact, a computer in its own right</strong></p>
</li>
<li>
<p><strong>Control a large number of I/O devices with minimal CPU participation</strong></p>
</li>
<li>
<p><strong>Controls communication with interactive terminals. The I/O processor handles most of the tasks</strong></p>
</li>
</ul>
</li>
</ul>
<p><strong>Generally, I/O channel and I/O processor are not distinguished. Called as I/O channel</strong></p>
<h4 id="io-channels-operation">I/O channels operation</h4>
<ul>
<li>
<p><strong>CPU initiates an I/O instruction that instructing the I/O channel to execute a program in memory</strong></p>
</li>
<li>
<p><strong>The program will specify the device, the area of memory for storage, priority, error handling</strong></p>
</li>
<li>
<p><strong>The I/O channel follows these instructions and controls the data transfer</strong></p>
</li>
<li>
<p><strong>I/O channel has two types</strong></p>
<ul>
<li>
<p><strong>Selector channel</strong></p>
</li>
<li>
<p><strong>Multiplexor</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="selector-channel">Selector channel</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-14.png" title="/img/Computer Organization and Architecture/chapter7-14.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-14.png">
        
    </a>
<h4 id="multiplexor">Multiplexor</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-15.png" title="/img/Computer Organization and Architecture/chapter7-15.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-15.png">
        
    </a>
<h3 id="the-external-interface">The External Interface</h3>
<h4 id="types-of-interface">Types of interface</h4>
<a class="lightgallery" href="/img/Computer%20Organization%20and%20Architecture/chapter7-16.png" title="/img/Computer Organization and Architecture/chapter7-16.png" data-thumbnail="/img/Computer Organization and Architecture/chapter7-16.png">
        
    </a>
<h4 id="interaction-between-io-module--peripherals">Interaction between I/O module &amp; peripherals</h4>
<ul>
<li>
<p>I/O module sends a control signal and requests to send data</p>
</li>
<li>
<p>Peripheral responds to the request</p>
</li>
<li>
<p>I/O module sends data</p>
</li>
<li>
<p>Peripherals acknowledge receipt of data</p>
</li>
<li>
<p>Connection type</p>
<ul>
<li>one to one</li>
<li>one to many: I/O bus</li>
</ul>
</li>
<li>
<p>Two typical I/O buses: 1394, InfiniBand</p>
</li>
</ul>
<hr>
<p><strong>IEEE 1394 FireWire</strong></p>
<ul>
<li>
<p>High performance serial bus</p>
</li>
<li>
<p>Fast</p>
</li>
<li>
<p>Low cost</p>
</li>
<li>
<p>Easy to implement</p>
</li>
<li>
<p>Also being used in digital cameras, VCD and TV</p>
</li>
</ul>
<hr>
<ul>
<li>
<p>Fair arbitration</p>
<ul>
<li>
<p>Bus time is divided into equal time intervals</p>
</li>
<li>
<p>During the time interval, each node can request the bus</p>
</li>
<li>
<p>After obtaining bus access, it is not allowed to request the bus again</p>
</li>
<li>
<p>Avoid high priority device exclusive bus</p>
</li>
</ul>
</li>
<li>
<p>Urgent arbitration</p>
<ul>
<li>
<p>Specific equipment has emergency priority</p>
</li>
<li>
<p>Bus control can be obtained multiple times in the interval</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><strong>InfiniBand</strong></p>
<ul>
<li>
<p>Increased capacity, expandability, flexibility</p>
</li>
<li>
<p>Attach servers, remote storage, network devices to central fabric of switches and links</p>
<ul>
<li>
<p>Greater server density</p>
</li>
<li>
<p>Scalable data center</p>
</li>
<li>
<p>Independent nodes added as required</p>
</li>
</ul>
</li>
</ul>
]]></description>
</item>
</channel>
</rss>
